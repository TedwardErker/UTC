#    -*- mode: org -*-


Archived entries from file /ssh:erker@kang:/home/erker/mydata2/Pjt_UTC/code/utc.org


* Visualize classified rasters
  :PROPERTIES:
  :ARCHIVE_TIME: 2016-05-18 Wed 08:58
  :ARCHIVE_FILE: /ssh:erker@kang:/home/erker/mydata2/Pjt_UTC/code/utc.org
  :ARCHIVE_OLPATH: Workflow/Determine how to make best classifier for Madison : image, segmentation, model, n.classes, target, and def truth/Testing/Accuracy
  :ARCHIVE_CATEGORY: utc
  :END:
#+BEGIN_SRC R
error.df %>%
ungroup() %>%
arrange(desc(overall.error)) %>%
head()
#+END_SRC

#+RESULTS:
#+begin_example

 overall.error pct.grass.classified.as.other
1             1                             1
2             1                             1
3             1                             1
4             1                             1
5             1                             1
6             1                             1
  pct.impervious.classified.as.other pct.tree.classified.as.other       grid
1                                NaN                            1 mad-100m-1
2                                NaN                            1 mad-100m-1
3                                NaN                            1 mad-100m-1
4                                NaN                            1 mad-100m-1
5                                NaN                            1 mad-100m-1
6                                NaN                            1 mad-100m-1
        image target.cover    model seg.params
1 madisonNAIP   impervious  rf_prob N-105_C-32
2 madisonNAIP   impervious  rf_resp N-105_C-32
3 madisonNAIP   impervious svm_resp N-105_C-32
4 madisonNAIP   impervious  rf_prob  N-30_C-15
5 madisonNAIP   impervious  rf_resp  N-30_C-15
6 madisonNAIP   impervious svm_resp  N-30_C-15
#+end_example


#+BEGIN_SRC R :exports results :results graphics :file ./figs/classifiedRasters.png

  grid.100m.1.paths <- list.files(str_c(dd.accuracy.dir, "/",ClassifiedTilesDirName), full.names = T) %>%
      str_extract(., ".*mad-100m-1.*.tif$") %>%
      na.omit()

  grid.100m.1.stacks <- lapply(grid.100m.1.paths, stack)


  r <- grid.100m.1.stacks[[2]]
  plot(r, main = names(r))

  (grid.100m.1.stacks[[2]])

#+END_SRC




* Poster PLots
  :PROPERTIES:
  :ARCHIVE_TIME: 2016-05-18 Wed 09:08
  :ARCHIVE_FILE: /ssh:erker@kang:/home/erker/mydata2/Pjt_UTC/code/utc.org
  :ARCHIVE_OLPATH: Workflow/Determine how to make best classifier for Madison : image, segmentation, model, n.classes, target, and def truth
  :ARCHIVE_CATEGORY: utc
  :END:
#+BEGIN_SRC R
  grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer, stringsAsFactors = F)

  xy <- coordinates(grd)
  grd@data$x <- xy[,1]
  grd@data$y <- xy[,2]


  classified.tile.paths <- list.files(str_c(dd.accuracy.classified.dir), full.names = T) %>%
      str_extract(., pattern = ".*.tif$") %>%
      str_extract(., pattern = str_c(".*",grid.pattern, ".*")) %>%
      str_extract(., pattern = str_c(".*","150m-[56]", ".*","N-105.*all_svm.*")) %>%
      na.omit()

  grid.names <- list.files(str_c(dd.accuracy.classified.dir), full.names = T) %>%
      str_extract(., pattern = ".*.tif$") %>%
      str_extract(., pattern = grid.pattern) %>%
      str_sub(.,1,-2) %>%
      unique() %>%
      na.omit()


  grid.names = str_extract(grid.names, ".*150m-[56].*") %>% na.omit()

  mad.grid.id.pattern = "mad-[0-9]+m-[0-9]+"
  grid.pattern = "[a-zA-Z]{3}-[0-9]+m-[0-9]+_"
  image.pattern = "[a-zA-Z]{5}[a-zA-Z]+"
  target.pattern = "all|grass|impervious|tree"
  model.pattern = "rf_prob|rf_resp|svm_resp"
  seg.prms = "N-[0-9]+_C-[0-9]+|Pixel"



  grid.name <- grid.names[1]

  pts <- grd[grd@data$unq__ID== grid.name,]

  classified.tile.paths.at.grid <- str_extract(classified.tile.paths, str_c(".*",grid.name,"_.*")) %>%
      na.omit()

  classified.tile.name.at.grid <- basename(classified.tile.paths.at.grid)
  classified.tile <- raster(classified.tile.paths.at.grid)

  pts.on.classified.tile.plot.poster <- function(pts, classified.tile) {
      pts@data <- pts@data %>%
          filter(cvr_typ == "g" |
                 cvr_typ == "i" |
                 cvr_typ == "t" |
                 cvr_typ == "o") %>%
          mutate(cvr_typ = mapvalues(cvr_typ, from = c("g","i","t","o"), to = c("grass","impervious","tree","other")))

      pts.plot.back <- geom_point(data = pts@data, aes(x = x, y = y), size = 1.4, color = "black")

      pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ), size = 1.1)

      r.df <- as.data.frame(classified.tile, xy = T)
      names(r.df) <- c("x","y","cvr_typ")
      r.df <- r.df %>%
          mutate(cvr_typ = mapvalues(cvr_typ, from = c(1,2,3,4), to = c("grass","impervious","tree","other")))
      pxls.plot <- ggplot() + geom_raster(data = r.df, aes(x = x, y = y, fill = cvr_typ))

      UTC_pal <- c(grass = "#ffff99", impervious = "#f0027f", tree = "#7fc97f", other = "#666666")
      UTC_pal <- c(grass = "#ffff33", impervious = "#e41a1c", tree = "#4daf4a", other = "#666666")

      x1 = min(pts@data$x)
      y1 = min(pts@data$y)
      x2 = x1 + 50
      y2 = y1

      scale.df <- data.frame(x1,x2,y1,y2)
      scale_segment <- geom_segment(data = scale.df, aes(x = x1, y = y1, xend = x2, yend = y2))



      pxls.plot + pts.plot.back + pts.plot + scale_fill_manual(values = UTC_pal)+ scale_color_manual(values = UTC_pal) +
          coord_equal() +
          theme_bw(base_size=15) +
          labs(fill = "Cover",
               x = "Easting",
               y = "Northing") +
          theme(axis.text=element_blank(),
                axis.ticks=element_blank()) +
          scale_segment +
          annotate("text",x = x1, y = y1, label = "50 m", vjust = 1.2, hjust = -.6)

  }




  p1 <- pts.on.classified.tile.plot.poster(pts, classified.tile) +
      theme(legend.position = "none") +
      ggtitle("Homogenous, less edge \n lower error")

  png("../../Posters/homogenous_lower_error.png", height = 4, width = 4, res = 1000, units = "in")
#  p1
  dev.off()

  ggsave("figs/homogenous_lower_error.png",
         p1,
         height = 4,
         width = 4,
         dpi = 100)

  grid.name <- grid.names[2]

  pts <- grd[grd@data$unq__ID== grid.name,]

  classified.tile.paths.at.grid <- str_extract(classified.tile.paths, str_c(".*",grid.name,"_.*")) %>%
      na.omit()


  classified.tile.name.at.grid <- basename(classified.tile.paths.at.grid)
  classified.tile <- raster(classified.tile.paths.at.grid)

  tgt <- str_extract(classified.tile.name.at.grid, "tree|grass|impervious|all")
  tgt <- mapvalues(tgt, c("tree","grass","impervious","all"), c("t","g","i","a"))

  p2 <- pts.on.classified.tile.plot.poster(pts, classified.tile) +
      ggtitle("Heterogeneous, more edge \n higher error")
  p2

  png("figs/heterogeneous_higher_error_wLegend.png", height = 4, width = 4, res = 1000, units = "in")
#  p2
  dev.off()



  p2 <- pts.on.classified.tile.plot.poster(pts, classified.tile) +
      ggtitle("Heterogeneous, more edge \n higher error") +
   theme(legend.position = "none")

  png("../../Posters/heterogeneous_higher_error.png", height = 4, width = 4, res = 1000, units = "in")
  p2
  dev.off()


  grid.arrange(p1,p2, ncol = 2)

#+END_SRC



#+BEGIN_SRC R
    library(rgeos)
    library(maptools)

    s.dsn <- "../DD/Accuracy/madisonNAIP_mad-100m-10"
    s30 <- readOGR(dsn = s.dsn, layer = "madisonNAIP_mad-100m-10_N-30_C-15")
    s60 <- readOGR(dsn = s.dsn, layer = "madisonNAIP_mad-100m-10_N-60_C-30")
    s105 <- readOGR(dsn = s.dsn, layer = "madisonNAIP_mad-100m-10_N-105_C-32")

    poly30 <-  s30 %>%
          fortify(region= "DN") %>%
          mutate(x = long,
                 y = lat)

    poly60 <-  s60 %>%
          fortify(region= "DN") %>%
          mutate(x = long,
                 y = lat)

    poly105 <-  s105 %>%
          fortify(region= "DN") %>%
          mutate(x = long,
                 y = lat)


    ggplot(data = poly30, aes(x = x, y = y, group = id)) + geom_polygon(color = "black",fill = NA)
    ggplot(data = poly60, aes(x = x, y = y, group = id)) + geom_polygon(color = "black",fill = NA)
    ggplot(data = poly105, aes(x = x, y = y, group = id)) + geom_polygon(color = "black",fill = NA)

    p30.plt <- geom_polygon(data = poly30, aes(x = x, y = y, group = id), color = "black",fill = NA)
    p60.plt <- geom_polygon(data = poly60, aes(x = x, y = y, group = id), color = "black",fill = NA)
    p105.plt <- geom_polygon(data = poly105, aes(x = x, y = y, group = id), color = "black",fill = NA)


    pca <- stack("../DD/Accuracy/madisonNAIP_mad-100m-10_pca.tif")
    pca.df <- as.data.frame(pca, xy= T)

    colnames(pca.df) <- c("x","y","p1","p2","p3")

    pca.df <- pca.df %>%
        mutate(p1 = p1/255,
               p2 = p2/255,
               p3 = p3/255) %>%
        na.omit() %>%
        mutate(col = rgb(p1,p2,p3))


    pca.plot <- ggplot(pca.df, aes(x = x, y = y, fill = col)) + geom_raster() +
        scale_fill_identity()


    pca.plot +    p30.plt
    pca.plot +    p60.plt
    pca.plot +    p105.plt

  xmin <-  min(pca.df$x)
  ymax <- max(pca.df$y)


  p30.pca <- pca.plot + p30.plt +
      annotate("text", x =xmin, y = ymax, label =  "B", size = 20, color = "white", hjust = -.5, vjust = 1.5) +
      coord_equal() +
      labs(x = "Easting",
           y = "Northing") +
      theme_bw(base_size=16) +
      theme(axis.text=element_blank(),
            axis.ticks=element_blank())

  p30.pca

    png("../../Posters/seg30_overpca.png", height = 4, width = 4, res = 1000, units = "in")
  p30.pca
    dev.off()



  p60.pca <- pca.plot + p60.plt +
      annotate("text", x =xmin, y = ymax, label =  "C", size = 20, color = "white", hjust = -.5, vjust = 1.5) +
      coord_equal() +
      labs(x = "Easting",
           y = "Northing") +
      theme_bw(base_size=16) +
      theme(axis.text=element_blank(),
            axis.ticks=element_blank())

  p60.pca

    png("../../Posters/seg60_overpca.png", height = 4, width = 4, res = 1000, units = "in")
  p60.pca
    dev.off()



  p105.pca <- pca.plot + p105.plt +
      annotate("text", x =xmin, y = ymax, label =  "D", size = 20, color = "white", hjust = -.5, vjust = 1.5) +
      coord_equal() +
      labs(x = "Easting",
           y = "Northing") +
      theme_bw(base_size=16) +
      theme(axis.text=element_blank(),
            axis.ticks=element_blank())

  p105.pca

    png("../../Posters/seg105_overpca.png", height = 4, width = 4, res = 1000, units = "in")
  p105.pca
    dev.off()






    tru.col <- stack("../DD/Accuracy/madisonNAIP_mad-100m-10.tif")
    tru.col.df <- as.data.frame(tru.col, xy= T)

    colnames(tru.col.df) <- c("x","y","b1","b2","b3","b4")

    tru.col.df <- tru.col.df %>%
        mutate(b1 = b1/255,
               b2 = b2/255,
               b3 = b3/255) %>%
        na.omit() %>%
        mutate(col = rgb(b1,b2,b3))


        x1 = min(tru.col.df$x) + 10
        y1 = min(tru.col.df$y) + 10
        x2 = x1 + 50 + 10
        y2 = y1


        scale_segment <- geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), color = "white")


  tru.col.plot <- ggplot(tru.col.df, aes(x = x, y = y, fill = col)) +
        coord_equal() +
        geom_raster() +
        scale_fill_identity() +
      annotate("text",x = x1, y = y1, label = "50 m", vjust = 1.2, hjust = -.6, size = 7, color = "white") +
      annotate("text", x =xmin, y = ymax, label =  "A", size = 20, color = "white", hjust = -.5, vjust = 1.5) +
      scale_segment +
        labs(x = "Easting",
             y = "Northing") +
        theme_bw(base_size=16)+
        theme(axis.text=element_blank(),
              axis.ticks=element_blank())

  tru.col.plot

    png("../../Posters/tru.col.mad-100m-10.png", height = 4, width = 4, res = 1000, units = "in")
    tru.col.plot
    dev.off()


  grid.arrange(p30.pca,p60.pca,p105.pca, tru.col.plot, ncol = 2, nrow = 2)




#+END_SRC








#+BEGIN_SRC R :results graphics :file figs/grid.errors2.newtraining.png :height 800 :width 600
  ggplot(error.df, aes(y = overall.error, x = grid, color = target.cover)) + geom_point() +
      facet_grid(image~seg.params)
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors2.newtraining.png]]
#+BEGIN_SRC R :results graphics :file figs/grid.errors4.newtraining.png :height 800 :width 600
  ggplot(error.df, aes(y = overall.error, x = grid, color = target.cover)) + geom_point() +
      facet_grid(image~segment.size)
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors4.newtraining.png]]


#+BEGIN_SRC R :results graphics :file figs/grid.errors5.newtraining.png :height 800 :width 600
  ggplot(error.df, aes(y = overall.error, x = segment.size)) +
      geom_point(data = error.df, aes(color = target.cover), position = position_dodge(width = 20)) +
      facet_grid(model~image)
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors5.newtraining.png]]

#+BEGIN_SRC R :results graphics :file figs/grid.errors6.newtraining.png :height 800 :width 800
  error.df.ssfac <- mutate(error.df, segment.size = factor(segment.size))

      ggplot(error.df.ssfac, aes(y = overall.error, x = segment.size)) +
          geom_boxplot(data = error.df.ssfac, aes(color = target.cover, group = interaction(target.cover,segment.size))) +
          facet_grid(model~image)
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors6.newtraining.png]]

#+BEGIN_SRC R :results graphics :file figs/grid.errors10.newtraining.png :height 800 :width 800
  error.df.ssfac <- mutate(error.df, segment.size = factor(segment.size)) %>%
filter(target.cover == "all")

      ggplot(error.df.ssfac, aes(y = overall.error, x = segment.size)) +
          geom_line(data = error.df.ssfac, aes(color = target.cover, group = interaction(grid,target.cover))) +
          facet_grid(model~image)
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors10.newtraining.png]]
#+BEGIN_SRC R :results graphics :file figs/grid.errors11.newtraining.png :height 800 :width 800
  error.df.ssfac <- mutate(error.df, segment.size = factor(segment.size)) %>%
filter(target.cover == "all")
#, overall.error > .4)

      ggplot(error.df.ssfac, aes(y = overall.error, x = segment.size)) +
          geom_line(data = error.df.ssfac, aes(color = grid, group = grid)) +
          facet_grid(model~image)
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors11.newtraining.png]]




#+BEGIN_SRC R :results graphics :file figs/grid.errors.tree.newtraining.png :height 800 :width 800
  error.df.ssfac.tree <- filter(error.df.ssfac, target.cover == "all" | target.cover == "tree")

      ggplot(error.df.ssfac.tree, aes(y = pct.tree.classified.as.other, x = segment.size)) +
          geom_boxplot(data = error.df.ssfac.tree, aes(color = target.cover, group = interaction(target.cover,segment.size))) +
          facet_grid(model~image)
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors.tree.newtraining.png]]


#+BEGIN_SRC R :results graphics :file figs/grid.errors.grass.png :height 800 :width 800
  error.df.ssfac.grass <- filter(error.df.ssfac, target.cover == "all" | target.cover == "grass")

      ggplot(error.df.ssfac.grass, aes(y = pct.grass.classified.as.other, x = segment.size)) +
          geom_boxplot(data = error.df.ssfac.grass, aes(color = target.cover, group = interaction(target.cover,segment.size))) +
          facet_grid(model~image)
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors.grass.png]]

#+BEGIN_SRC R :results raw
  error.mod <- lm(overall.error ~ image * (target.cover + model + segment.size), data = error.df)
  tidy(error.mod) %>% ascii()
#+END_SRC

#+RESULTS:
|    | term                                   | estimate | std.error | statistic | p.value |
|----+----------------------------------------+----------+-----------+-----------+---------|
|  1 | (Intercept)                            |     0.26 |      0.01 |     27.44 |    0.00 |
|  2 | imagepanshpSPOT                        |     0.17 |      0.02 |     11.35 |    0.00 |
|  3 | target.covergrass                      |    -0.08 |      0.01 |     -8.45 |    0.00 |
|  4 | target.coverimpervious                 |    -0.14 |      0.01 |    -14.17 |    0.00 |
|  5 | target.covertree                       |    -0.06 |      0.01 |     -6.31 |    0.00 |
|  6 | modelrf_resp                           |     0.00 |      0.01 |      0.02 |    0.99 |
|  7 | modelsvm_resp                          |    -0.01 |      0.01 |     -1.46 |    0.14 |
|  8 | segment.size                           |    -0.00 |      0.00 |     -1.62 |    0.11 |
|  9 | imagepanshpSPOT:target.covergrass      |    -0.10 |      0.02 |     -5.90 |    0.00 |
| 10 | imagepanshpSPOT:target.coverimpervious |     0.10 |      0.02 |      6.29 |    0.00 |
| 11 | imagepanshpSPOT:target.covertree       |    -0.13 |      0.02 |     -8.34 |    0.00 |
| 12 | imagepanshpSPOT:modelrf_resp           |     0.00 |      0.01 |      0.03 |    0.97 |
| 13 | imagepanshpSPOT:modelsvm_resp          |     0.13 |      0.01 |      9.42 |    0.00 |
| 14 | imagepanshpSPOT:segment.size           |    -0.00 |      0.00 |     -5.62 |    0.00 |

                                    term      estimate    std.error
1                             (Intercept)  0.2594736239 9.457737e-03
2                         imagepanshpSPOT  0.1727955729 1.522839e-02
3                       target.covergrass -0.0818909914 9.689578e-03
4                  target.coverimpervious -0.1373055644 9.689578e-03
5                        target.covertree -0.0611569996 9.689578e-03
6                            modelrf_resp  0.0001428180 8.391421e-03
7                           modelsvm_resp -0.0122835115 8.391421e-03
8                            segment.size -0.0001441090 8.903396e-05
9       imagepanshpSPOT:target.covergrass -0.0950710892 1.612641e-02
10 imagepanshpSPOT:target.coverimpervious  0.1013795711 1.612641e-02
11       imagepanshpSPOT:target.covertree -0.1345326137 1.612641e-02
12           imagepanshpSPOT:modelrf_resp  0.0004778158 1.396589e-02
13          imagepanshpSPOT:modelsvm_resp  0.1315548935 1.396589e-02
14           imagepanshpSPOT:segment.size -0.0008378628 1.489573e-04
      statistic       p.value
1   27.43506508 3.802666e-151
2   11.34693391  2.306554e-29
3   -8.45145037  4.066308e-17
4  -14.17043735  1.931840e-44
5   -6.31162645  3.083836e-10
6    0.01701953  9.864219e-01
7   -1.46381779  1.433277e-01
8   -1.61858472  1.056209e-01
9   -5.89536419  4.069309e-09
10   6.28655355  3.619056e-10
11  -8.34237580  1.011573e-16
12   0.03421307  9.727091e-01
13   9.41973196  7.679367e-21
14  -5.62485092  1.992621e-08

#+BEGIN_SRC R :results raw
options(asciiType = "org")
options(warn = -1)
  error.df %>%
      group_by(image, target.cover, model, seg.params) %>%
      summarize(overall.error = mean(overall.error)) %>%
      ungroup() %>%
      arrange(overall.error) %>%
      head(n=40) %>%
      ascii()
#+END_SRC

#+RESULTS:
 |    | image       | target.cover | model    | seg.params | overall.error |
 |----+-------------+--------------+----------+------------+---------------|
 |  1 | madisonNAIP | impervious   | rf_prob  | Pixel      |          0.10 |
 |  2 | madisonNAIP | impervious   | rf_resp  | Pixel      |          0.10 |
 |  3 | madisonNAIP | impervious   | svm_resp | Pixel      |          0.11 |
 |  4 | madisonNAIP | impervious   | rf_resp  | N-30_C-15  |          0.11 |
 |  5 | madisonNAIP | impervious   | rf_prob  | N-30_C-15  |          0.11 |
 |  6 | madisonNAIP | impervious   | rf_resp  | N-60_C-30  |          0.11 |
 |  7 | madisonNAIP | impervious   | rf_prob  | N-60_C-30  |          0.11 |
 |  8 | madisonNAIP | impervious   | rf_prob  | N-105_C-32 |          0.11 |
 |  9 | madisonNAIP | impervious   | rf_resp  | N-105_C-32 |          0.11 |
 | 10 | madisonNAIP | impervious   | svm_resp | N-60_C-30  |          0.12 |
 | 11 | madisonNAIP | impervious   | svm_resp | N-30_C-15  |          0.12 |
 | 12 | madisonNAIP | impervious   | svm_resp | N-105_C-32 |          0.13 |
 | 13 | madisonNAIP | grass        | svm_resp | N-60_C-30  |          0.14 |
 | 14 | madisonNAIP | grass        | svm_resp | N-30_C-15  |          0.14 |
 | 15 | madisonNAIP | grass        | svm_resp | N-105_C-32 |          0.14 |
 | 16 | madisonNAIP | tree         | svm_resp | N-60_C-30  |          0.16 |
 | 17 | madisonNAIP | grass        | rf_resp  | N-60_C-30  |          0.16 |
 | 18 | madisonNAIP | grass        | rf_prob  | N-105_C-32 |          0.16 |
 | 19 | madisonNAIP | grass        | rf_resp  | N-105_C-32 |          0.16 |
 | 20 | madisonNAIP | grass        | rf_prob  | N-60_C-30  |          0.16 |
 | 21 | madisonNAIP | grass        | rf_resp  | N-30_C-15  |          0.17 |
 | 22 | madisonNAIP | tree         | svm_resp | N-30_C-15  |          0.17 |
 | 23 | madisonNAIP | grass        | rf_prob  | N-30_C-15  |          0.17 |
 | 24 | madisonNAIP | tree         | svm_resp | N-105_C-32 |          0.17 |
 | 25 | madisonNAIP | grass        | svm_resp | Pixel      |          0.18 |
 | 26 | madisonNAIP | tree         | svm_resp | Pixel      |          0.18 |
 | 27 | madisonNAIP | tree         | rf_prob  | N-105_C-32 |          0.19 |
 | 28 | madisonNAIP | tree         | rf_resp  | N-105_C-32 |          0.19 |
 | 29 | madisonNAIP | tree         | rf_prob  | N-30_C-15  |          0.19 |
 | 30 | madisonNAIP | tree         | rf_resp  | N-60_C-30  |          0.19 |
 | 31 | madisonNAIP | tree         | rf_resp  | N-30_C-15  |          0.19 |
 | 32 | madisonNAIP | tree         | rf_prob  | N-60_C-30  |          0.19 |
 | 33 | madisonNAIP | grass        | rf_prob  | Pixel      |          0.21 |
 | 34 | madisonNAIP | grass        | rf_resp  | Pixel      |          0.21 |
 | 35 | madisonNAIP | tree         | rf_prob  | Pixel      |          0.22 |
 | 36 | madisonNAIP | tree         | rf_resp  | Pixel      |          0.22 |
 | 37 | panshpSPOT  | tree         | rf_resp  | Pixel      |          0.22 |
 | 38 | panshpSPOT  | tree         | rf_prob  | Pixel      |          0.23 |
 | 39 | madisonNAIP | all          | svm_resp | N-60_C-30  |          0.23 |
 | 40 | madisonNAIP | all          | rf_resp  | N-60_C-30  |          0.24 |



#+BEGIN_SRC R :results raw
  options(asciiType = "org")
  options(warn = -1)
    error.df %>%
        filter(target.cover == "all") %>%
        group_by(image, target.cover, model, seg.params) %>%
        summarize(overall.error = mean(overall.error)) %>%
        ungroup() %>%
        arrange(overall.error) %>%
        head(n=40) %>%
        ascii()
#+END_SRC

#+RESULTS:
 |    | image       | target.cover | model    | seg.params | overall.error |
 |----+-------------+--------------+----------+------------+---------------|
 |  1 | madisonNAIP | all          | svm_resp | N-60_C-30  |          0.23 |
 |  2 | madisonNAIP | all          | rf_resp  | N-60_C-30  |          0.24 |
 |  3 | madisonNAIP | all          | rf_prob  | N-60_C-30  |          0.24 |
 |  4 | madisonNAIP | all          | rf_resp  | N-105_C-32 |          0.24 |
 |  5 | madisonNAIP | all          | rf_prob  | N-105_C-32 |          0.24 |
 |  6 | madisonNAIP | all          | svm_resp | N-30_C-15  |          0.24 |
 |  7 | madisonNAIP | all          | rf_prob  | N-30_C-15  |          0.24 |
 |  8 | madisonNAIP | all          | rf_resp  | N-30_C-15  |          0.25 |
 |  9 | madisonNAIP | all          | svm_resp | Pixel      |          0.25 |
 | 10 | madisonNAIP | all          | svm_resp | N-105_C-32 |          0.25 |
 | 11 | madisonNAIP | all          | rf_resp  | Pixel      |          0.28 |
 | 12 | madisonNAIP | all          | rf_prob  | Pixel      |          0.28 |
 | 13 | panshpSPOT  | all          | rf_resp  | Pixel      |          0.42 |
 | 14 | panshpSPOT  | all          | rf_prob  | Pixel      |          0.43 |
 | 15 | panshpSPOT  | all          | svm_resp | Pixel      |          0.57 |
 | 16 | panshpSPOT  | all          | rf_prob  | N-20_C-10  |               |
 | 17 | panshpSPOT  | all          | rf_prob  | N-40_C-20  |               |
 | 18 | panshpSPOT  | all          | rf_prob  | N-70_C-21  |               |
 | 19 | panshpSPOT  | all          | rf_resp  | N-20_C-10  |               |
 | 20 | panshpSPOT  | all          | rf_resp  | N-40_C-20  |               |
 | 21 | panshpSPOT  | all          | rf_resp  | N-70_C-21  |               |
 | 22 | panshpSPOT  | all          | svm_resp | N-20_C-10  |               |
 | 23 | panshpSPOT  | all          | svm_resp | N-40_C-20  |               |
 | 24 | panshpSPOT  | all          | svm_resp | N-70_C-21  |               |



#+BEGIN_SRC R :results raw
  options(asciiType = "org")
  options(warn = -1)
    error.df %>%
        filter(target.cover == "all") %>%
        group_by(image, target.cover, model, seg.params) %>%
        summarize(pct.tree.classified.as.other = mean(pct.tree.classified.as.other)) %>%
        ungroup() %>%
        arrange(pct.tree.classified.as.other) %>%
        head(n=40) %>%
        ascii()

#+END_SRC

#+RESULTS:
 |    | image       | target.cover | model    | seg.params | pct.tree.classified.as.other |
 |----+-------------+--------------+----------+------------+------------------------------|
 |  1 | panshpSPOT  | all          | rf_prob  | N-20_C-10  |                              |
 |  2 | panshpSPOT  | all          | rf_prob  | N-40_C-20  |                              |
 |  3 | panshpSPOT  | all          | rf_prob  | N-70_C-21  |                              |
 |  4 | panshpSPOT  | all          | rf_resp  | N-20_C-10  |                              |
 |  5 | panshpSPOT  | all          | rf_resp  | N-40_C-20  |                              |
 |  6 | panshpSPOT  | all          | rf_resp  | N-70_C-21  |                              |
 |  7 | panshpSPOT  | all          | svm_resp | N-20_C-10  |                              |
 |  8 | panshpSPOT  | all          | svm_resp | N-40_C-20  |                              |
 |  9 | panshpSPOT  | all          | svm_resp | N-70_C-21  |                              |
 | 10 | madisonNAIP | all          | rf_prob  | N-105_C-32 |                              |
 | 11 | madisonNAIP | all          | rf_prob  | N-30_C-15  |                              |
 | 12 | madisonNAIP | all          | rf_prob  | N-60_C-30  |                              |
 | 13 | madisonNAIP | all          | rf_prob  | Pixel      |                              |
 | 14 | madisonNAIP | all          | rf_resp  | N-105_C-32 |                              |
 | 15 | madisonNAIP | all          | rf_resp  | N-30_C-15  |                              |
 | 16 | madisonNAIP | all          | rf_resp  | N-60_C-30  |                              |
 | 17 | madisonNAIP | all          | rf_resp  | Pixel      |                              |
 | 18 | madisonNAIP | all          | svm_resp | N-105_C-32 |                              |
 | 19 | madisonNAIP | all          | svm_resp | N-30_C-15  |                              |
 | 20 | madisonNAIP | all          | svm_resp | N-60_C-30  |                              |
 | 21 | madisonNAIP | all          | svm_resp | Pixel      |                              |
 | 22 | panshpSPOT  | all          | rf_prob  | Pixel      |                              |
 | 23 | panshpSPOT  | all          | rf_resp  | Pixel      |                              |
 | 24 | panshpSPOT  | all          | svm_resp | Pixel      |                              |


** Calc RMSEs Grid.

*** Before Added Points Combine google earth grid estimates of cover with classified tile estimates of cover

Create dataframe with structure:

| %t.img | %g.img | %i.img | %o.img | image      | segmentation | target.cover        | target.type         | model                   | tile                   | cropped.to.n.pts | %t.goog | %g.goog | %i.goog | %o.goog |   |   |   |   |   |   |   |   |
|--------+--------+--------+--------+------------+--------------+---------------------+---------------------+-------------------------+------------------------+------------------+---------+---------+---------+---------+---+---+---+---+---+---+---+---|
|    0-1 |    0-1 |    0-1 |    0-1 | NAIP       | Pixel        | grass               | binomial (two)      | random forest prob      | mad-size-id (up to 50) |                4 |     0-1 |     0-1 |     0-1 |     0-1 |   |   |   |   |   |   |   |   |
|        |        |        |        | panshpSPOT | 30 m2        | tree                | multinomial (three) | random forest resp      |                        |                9 |         |         |         |         |   |   |   |   |   |   |   |   |
|        |        |        |        |            | 60 m2        | impervious          |                     | support vector machines |                        |               16 |         |         |         |         |   |   |   |   |   |   |   |   |
|        |        |        |        |            |              | NA (if multinomial) |                     |                         |                        |               25 |         |         |         |         |   |   |   |   |   |   |   |   |
|        |        |        |        |            | 105 m2       |                     |                     |                         |                        |              ... |         |         |         |         |   |   |   |   |   |   |   |   |



**** OLD Create DF of % cover from grids cropped to different extents
 #+BEGIN_SRC R
          grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer)
          grd.df <- grd@data

     n.rows.and.columns.for.subset = c(2,3,4,5,10,13,15,20,22,24,26,28,29)
   n.rows.and.columns.for.subset = c(4,9,14,19,24,29)

   out <- foreach(n.rows.and.columns.for.sub = n.rows.and.columns.for.subset) %do% {
              calc.pct.cvr.for.grid.subset(grd.df, n.rows.and.columns.for.sub)
          }

          Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets <- bind_rows(out)

     Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets <- Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets %>%
         rename(grid = unq__ID)

       saveRDS(Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets, str_c(derived.dir,"/","Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets.dataframe",".rds"))
 #+END_SRC

 #+RESULTS:
 #+begin_example
 OGR data source with driver: ESRI Shapefile
 Source: "../RD_Accuracy/Grids", layer: "All_Grids_Accuracy_Assessment_pts"
 with 18365 features
 It has 10 fields
  Joining by: "unq__ID"
 Joining by: "unq__ID"
 Joining by: "unq__ID"
 Joining by: "unq__ID"
 Joining by: "unq__ID"
 Joining by: "unq__ID"
 Error in { : task 1 failed - "object 'column' not found"
  Error: Unknown variables: unq__ID.
#+end_example

**** Create DF of % cover from grids cropped to different extents
#+BEGIN_SRC R
             grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer)
             grd.df <- grd@data


      n.rows.and.columns.for.subset = c(2, 3, 5)
      mods = c(.25, .5, 1)

   # must use madison.  Wausau won't work because of NA's, we haven't identifited all the points in that area
   # and the spread function doesn't like NA's as column names.
   mad.grd.df <- filter(grd.df, city == "mad")

      out <- foreach(i = 1:3) %do% {
                 calc.pct.cvr.for.grid.subset(mad.grd.df, n.rows.and.columns.for.subset[i], mod = mods[i])
             }

             Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets <- bind_rows(out)

        Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets <- Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets %>%
            rename(grid = unq__ID)

          saveRDS(Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets, str_c(derived.dir,"/","Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets.dataframe",".rds"))
 #+END_SRC

 #+RESULTS:
 #+begin_example
 OGR data source with driver: ESRI Shapefile
 Source: "../RD_Accuracy/Grids", layer: "All_Grids_Accuracy_Assessment_Added_pts"
 with 21305 features
 It has 15 fields
  Joining by: "unq__ID"
 Joining by: "unq__ID"
 Joining by: "unq__ID"
 Joining by: "unq__ID"
 Joining by: "unq__ID"
 Joining by: "unq__ID"
#+end_example

**** Create DF of % cover from classified rasters cropped to different extents
#+BEGIN_SRC R

          grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer)

  mad.grid.pattern <- "mad-[0-9]+m-[0-9]+_"

          # get path of grid tiles (not interested in fieldplot classified tiles)
              classified.tile.paths <- list.files(str_c(dd.accuracy.classified.dir), full.names = T) %>%
                  str_extract(., pattern = ".*.tif$") %>%
                  str_extract(., pattern = str_c(".*",mad.grid.pattern, ".*")) %>%
                    na.omit()


              classified.tile.paths <- list.files(str_c(dd.accuracy.classified.dir), full.names = T) %>%
                  str_extract(., pattern = ".*.tif$") %>%
                  str_extract(., pattern = str_c(".*",grid.pattern, ".*")) %>%
    #              str_extract(., pattern = str_c(".*","N-30_C-15", ".*")) %>%
    #              str_extract(., pattern = str_c(".*","_all_", ".*")) %>%
    #              str_extract(., pattern = str_c(".*","_rf_prob", ".*")) %>%
                  na.omit()


      #  n.rows.and.columns.for.subset = c(2,3,4,5,10,13,15,20,22,24,26,28,29)
       n.rows.and.columns.for.subset = c(4,9,14,19,24,29)
        n.rows.and.columns.for.subset = c(2,3,5)
        #n.rows.and.columns.for.subset = c(15)



        cl <- makeCluster(cores)
        registerDoParallel(cl)


            out <- foreach(n.rows.and.columns.for.sub = n.rows.and.columns.for.subset) %do% {
                   pct.class.cover <- foreach(tile.path = classified.tile.paths, .packages = c("sp","rgdal","rgeos","raster","dplyr","stringr")) %dopar% {
                     calculate.percent.cover.in.classified.tile(pts = grd,
                                                                 tile.pth = tile.path,
                                                                n.rows.and.columns.subset = n.rows.and.columns.for.sub)
                  }
                      saveRDS(pct.class.cover, str_c(derived.dir,"/","mad.Percent.Cover.Classified.Tiles.nPoints",n.rows.and.columns.for.sub, ".rds"))
            }

            ## out <- foreach(i = 1:3) %do% {
            ##        pct.class.cover <- foreach(tile.path = classified.tile.paths, .packages = c("raster","dplyr","stringr")) %dopar% {
            ##          calculate.percent.cover.in.classified.tile(pts = grd,
            ##                                                      tile.pth = tile.path,
            ##                                                     n.rows.and.columns.subset = n.rows.and.columns.for.subset[i],
            ##                                                     mod = mod[i])
            ##       }
            ##           saveRDS(pct.class.cover, str_c(derived.dir,"/","mad.Percent.Cover.Classified.Tiles.nPoints",n.rows.and.columns.for.sub, ".rds"))
            ## }


      # Read in these Percent Cover dataframes and bind into one
        class.cover.files <- list.files(derived.dir, pattern = "mad.Percent.Cover.Classified.Tiles.nPoints*", full.names = T)

        class.cover.dfs <- lapply(class.cover.files, readRDS)

        out <- unlist(class.cover.dfs,recursive = F)

             Percent.Cover.Classified.Tiles.dataframe <- bind_rows(out)





        # delete this line if I run it again.
        ## Percent.Cover.Classified.Tiles.dataframe <-rename(Percent.Cover.Classified.Tiles.dataframe,
        ##                                                   image = tile,
        ##                                                   pct_g_pred = pct_g,
        ##                                                   pct_i_pred = pct_i,
        ##                                                   pct_t_pred = pct_t,
        ##                                                   pct_o_pred = pct_o)

          ## saveRDS(Percent.Cover.Classified.Tiles.dataframe, str_c(derived.dir,"/","Percent.Cover.Classified.Tiles.dataframe",".rds"))

#+END_SRC

#+RESULTS:
: OGR data source with driver: ESRI Shapefile
: Source: "../RD_Accuracy/Grids", layer: "All_Grids_Accuracy_Assessment_Added_pts"
: with 21305 features
: It has 15 fields
:  Error in { :
:   task 1 failed - "task 1 failed - "argument "y_coord_name" is missing, with no default""



**** Join Cover from Grids with predicted Cover from images
#+BEGIN_SRC R
    Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets <- readRDS(str_c(derived.dir,"/","Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets.dataframe",".rds"))

    str(Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets)

  Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets %>%
      data.frame %>%
      arrange(grid) %>%
      head(n=20)


  str(Percent.Cover.Classified.Tiles.dataframe)

  Percent.Cover.Classified.Tiles.dataframe <- Percent.Cover.Classified.Tiles.dataframe %>%
      filter(n.points == 4 | n.points == 9 | n.points == 25)

  Percent.Cover.Classified.Tiles.dataframe <- Percent.Cover.Classified.Tiles.dataframe %>%
      filter(complete.cases(area))


  str(Percent.Cover.Classified.Tiles.dataframe)
  summary(Percent.Cover.Classified.Tiles.dataframe)
  head(data.frame(Percent.Cover.Classified.Tiles.dataframe), n = 20)


  Percent.Cover.Classified.Tiles.dataframe <- Percent.Cover.Classified.Tiles.dataframe %>%
      mutate(area = round(area))

  Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets <- Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets %>%
      mutate(area = round(area))



  #Percent.Cover.Classified.Tiles.dataframe <- Percent.Cover.Classified.Tiles.dataframe %>%
  #    rename(pct_g_pred = pct_g, pct_t_pred = pct_t, pct_i_pred = pct_i, pct_o_pred = pct_o)


    grid.master.df <- left_join(Percent.Cover.Classified.Tiles.dataframe, Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets, by = c("grid", "target.cover", "area", "target.type"))

    # Should join by Joining by: c("grid", "target.cover", "area", "target.type")

    str(grid.master.df)

    grid.master.df %>%
  #      filter(n.points == 400) %>%
        data.frame() %>%
        head(n=40)




#+END_SRC


*** Combine google earth grid estimates of cover with classified tile estimates of cover Added Points


*** Make RMSE plots

#+BEGIN_SRC R :results graphics :file figs/better.SPOT.RMSE_plot.png :height 800 :width 600

    sub.for.rmse.plot <- grid.master.df %>%
        filter(target.type == "multinomial",
               image == "panshpSPOT")



    ggplot(sub.for.rmse.plot, aes( x = pct.t.googleEarth, y = pct_t_pred, color = seg.params)) +
  geom_point() + geom_smooth() + theme_classic() +
  geom_line(data = data.frame(pct.t.googleEarth = c(0,1), pct_t_pred = c(0,1), seg.params = "1:1"),
  color = "black", size = 1) +
  ggtitle("SPOT, n.pts: 225")

#+END_SRC

#+RESULTS:
[[file:figs/better.SPOT.RMSE_plot.png]]

#+BEGIN_SRC R :results graphics :file figs/NAIP.200m.RMSE_plot.png :height 800 :width 600

    sub.for.rmse.plot <- grid.master.df %>%
        filter(target.type == "multinomial",
               image == "madisonNAIP",
               n.points == 196,
               model == "rf_prob",
               seg.params == "N-30_C-15")




  ggplot(sub.for.rmse.plot, aes( x = pct.t.googleEarth, y = pct_t_pred, color = seg.params)) +
  geom_point() + geom_smooth() + theme_classic() +
  geom_line(data = data.frame(pct.t.googleEarth = c(0,1), pct_t_pred = c(0,1), seg.params = "1:1"),
  color = "black", size = 1) + geom_text(data = sub.for.rmse.plot, aes(label = grid), vjust = .05)


  qplot(pct.t.googleEarth, pct_t_pred, label = grid, data = sub.for.rmse.plot)

  ggplotly()

#+END_SRC


**** Make interactive RMSE plot
#+BEGIN_SRC R

  sub.for.rmse.plot <-  sub.for.rmse.plot %>%
      filter(model == "rf_prob",


    options(prompt = "> ")


  dat <- sub.for.rmse.plot %>%
      select(grid, pct_t_pred, pct.t.googleEarth)



  dat <- dat %>%
      filter(complete.cases(pct.t.googleEarth))

  library(rCharts)


    r1 <- rPlot(pct_t_pred ~ pct.t.googleEarth, data = dat, type = 'point')

  r1$publish("rmseplot", host = 'gist')


    n1$set(width = 1200, height = 600)
    n1$show('inline', include_assets = TRUE)



#+END_SRC




*** Calc RMSE table

Create dataframe with structure:

| RMSE | image | segmentation | target | model | cropped.to.n.pts | cover_type |   |   |   |   |   |   |   |
|------+-------+--------------+--------+-------+------------------+------------+---+---+---+---+---+---+---|
|      |       |              |        |       |                  |            |   |   |   |   |   |   |   |


**** Calc Error Column, Find Grids with huge error

#+BEGIN_SRC R
  error_tree <- grid.master.df %>%
      filter(target.cover == "tree" | target.cover == "all") %>%
  #    select(-target.cover) %>%
  #    group_by(image, model, n.points, seg.params, target.type, grid) %>%
      mutate(t_error = (pct_t_pred - pct.t.googleEarth))

  error_tree %>%
  #    select(image, model, n.points, seg.params, target.type, grid, pct_t_pred, pct.t.googleEarth, t_error) %>%
      filter(target.type == "multinomial",
             model == "rf_prob",
             image == "madisonNAIP") %>%
      arrange(desc(abs(t_error))) %>%
      data.frame() %>%
      head(n=50)


  grid.master.df %>%
      filter(grid == "mad-100m-3") %>%
      select(pct_t_pred, pct.t.googleEarth) %>%
      mutate(t_error = (pct_t_pred - pct.t.googleEarth))

  error_tree %>%
      filter(grid == "mad-100m-3") %>%
      select(pct_t_pred, pct.t.googleEarth, t_error) %>%
      arrange((abs(t_error))) %>%
         data.frame() %>%
      head(n=50)



  %>%
      mutate(t_error = (pct_t_pred - pct.t.googleEarth))
#+END_SRC


#+BEGIN_SRC R :results graphics :file figs/error.tree.png :height 800 :width 600

#+END_SRC


#+BEGIN_SRC R

    RMSE_tree <- grid.master.df %>%
        filter(target.cover == "tree" | target.cover == "all") %>%
        select(-target.cover) %>%
        group_by(image, model, area, seg.params, target.type) %>%
        summarize(RMSE_t = sqrt( mean( (pct_t_pred - pct.t.googleEarth)^2, na.rm =T ) ) )

  RMSE_tree <- RMSE_tree %>%
      mutate(segment.size = ifelse(!is.na(str_extract(seg.params, ".*105.*")), 105,
                            ifelse(!is.na(str_extract(seg.params, ".*60.*")), 60,
                            ifelse(!is.na(str_extract(seg.params, ".*30.*")), 30,
                            ifelse(!is.na(str_extract(seg.params, ".*70.*")), 105,
                            ifelse(!is.na(str_extract(seg.params, ".*40.*")), 60,
                            ifelse(!is.na(str_extract(seg.params, ".*20.*")), 30,1)))))))
#+END_SRC

#+RESULTS:

*** RMSE analysis

Which combination of image, segmentation, target, model and n.pts
(spatial scale) minimize error for each cover_type?

#+BEGIN_SRC R :results raw
options(asciiType = "org")
options(warn = -1)
  RMSE_tree %>%
      ungroup() %>%
      arrange(RMSE_t) %>%
      head(n = 30) %>%
      ascii()
#+END_SRC

#+RESULTS:
 |    | image       | model    |   area | seg.params | target.type | RMSE_t | segment.size |
 |----+-------------+----------+--------+------------+-------------+--------+--------------|
 |  1 | madisonNAIP | svm_resp | 801.00 | N-30_C-15  | multinomial |   0.18 |        30.00 |
 |  2 | madisonNAIP | svm_resp | 801.00 | N-60_C-30  | multinomial |   0.19 |        60.00 |
 |  3 | madisonNAIP | svm_resp | 801.00 | N-105_C-32 | multinomial |   0.19 |       105.00 |
 |  4 | madisonNAIP | rf_prob  | 801.00 | N-105_C-32 | multinomial |   0.22 |       105.00 |
 |  5 | madisonNAIP | rf_resp  | 801.00 | N-105_C-32 | multinomial |   0.22 |       105.00 |
 |  6 | madisonNAIP | rf_prob  | 801.00 | N-60_C-30  | multinomial |   0.22 |        60.00 |
 |  7 | madisonNAIP | rf_resp  | 801.00 | N-60_C-30  | multinomial |   0.22 |        60.00 |
 |  8 | madisonNAIP | svm_resp | 200.00 | N-30_C-15  | multinomial |   0.24 |        30.00 |
 |  9 | madisonNAIP | svm_resp | 200.00 | N-60_C-30  | multinomial |   0.24 |        60.00 |
 | 10 | madisonNAIP | rf_prob  | 801.00 | N-30_C-15  | multinomial |   0.24 |        30.00 |
 | 11 | madisonNAIP | rf_resp  | 801.00 | N-30_C-15  | multinomial |   0.24 |        30.00 |
 | 12 | panshpSPOT  | rf_prob  | 801.00 | Pixel      | multinomial |   0.24 |         1.00 |
 | 13 | madisonNAIP | rf_resp  | 200.00 | N-105_C-32 | multinomial |   0.24 |       105.00 |
 | 14 | madisonNAIP | rf_prob  | 200.00 | N-105_C-32 | multinomial |   0.24 |       105.00 |
 | 15 | panshpSPOT  | rf_resp  | 801.00 | Pixel      | multinomial |   0.24 |         1.00 |
 | 16 | madisonNAIP | rf_prob  | 200.00 | N-60_C-30  | multinomial |   0.25 |        60.00 |
 | 17 | madisonNAIP | rf_resp  | 200.00 | N-30_C-15  | multinomial |   0.26 |        30.00 |
 | 18 | madisonNAIP | svm_resp | 200.00 | N-105_C-32 | multinomial |   0.26 |       105.00 |
 | 19 | madisonNAIP | rf_prob  | 200.00 | N-30_C-15  | multinomial |   0.26 |        30.00 |
 | 20 | madisonNAIP | rf_resp  | 200.00 | N-60_C-30  | multinomial |   0.26 |        60.00 |
 | 21 | panshpSPOT  | rf_prob  | 801.00 | N-20_C-10  | multinomial |   0.27 |        30.00 |
 | 22 | madisonNAIP | svm_resp |  50.00 | N-30_C-15  | multinomial |   0.28 |        30.00 |
 | 23 | panshpSPOT  | rf_prob  | 200.00 | Pixel      | multinomial |   0.28 |         1.00 |
 | 24 | panshpSPOT  | rf_resp  | 200.00 | Pixel      | multinomial |   0.28 |         1.00 |
 | 25 | panshpSPOT  | rf_prob  | 801.00 | N-40_C-20  | multinomial |   0.29 |        60.00 |
 | 26 | panshpSPOT  | rf_prob  | 200.00 | N-20_C-10  | multinomial |   0.30 |        30.00 |
 | 27 | madisonNAIP | rf_prob  |  50.00 | N-105_C-32 | multinomial |   0.31 |       105.00 |
 | 28 | madisonNAIP | rf_prob  |  50.00 | N-30_C-15  | multinomial |   0.31 |        30.00 |
 | 29 | panshpSPOT  | rf_prob  |  50.00 | Pixel      | multinomial |   0.31 |         1.00 |
 | 30 | panshpSPOT  | rf_resp  |  50.00 | Pixel      | multinomial |   0.31 |         1.00 |



Plot:
x = cropped.to.n.pts
y = RMSE
color = model
facet(segmentation~cover_type)

#+BEGIN_SRC R
  RMSE_tree <- RMSE_tree %>%
    ungroup() %>%
    mutate(model = mapvalues(model, from = c("rf_prob", "rf_resp", "svm_resp"), to = c("Random Forests", "Random Forests 2", "Support Vector Machines")),
           image = mapvalues(image, from = c("madisonNAIP", "panshpSPOT"), to = c("NAIP", "Pansharpened SPOT"))) %>%
    rename(RMSE = RMSE_t, area_m2 = area) %>%
    filter(model != "Random Forests 2")


  head(RMSE_tree)
#+END_SRC

#+RESULTS:
#+begin_example
Source: local data frame [6 x 7]

  image          model area_m2 seg.params target.type      RMSE segment.size
  (chr)          (chr)   (dbl)      (chr)       (chr)     (dbl)        (dbl)
1  NAIP Random Forests      50 N-105_C-32    binomial        NA          105
2  NAIP Random Forests      50 N-105_C-32 multinomial 0.3086706          105
3  NAIP Random Forests      50  N-30_C-15    binomial       NaN           30
4  NAIP Random Forests      50  N-30_C-15 multinomial 0.3089917           30
5  NAIP Random Forests      50  N-60_C-30    binomial       NaN           60
6  NAIP Random Forests      50  N-60_C-30 multinomial 0.3252199           60
#+end_example

#+BEGIN_SRC R :results graphics :file figs/RMSE_tree_compare_n.ptsXRMSE.png
  library(RColorBrewer)

  RMSE_tree <- na.omit(RMSE_tree)

  p <-   ggplot(RMSE_tree, aes(x = area_m2, y = RMSE, color = segment.size)) + geom_point() +
        facet_grid(model~image, labeller = label_both)

  p2 <-   ggplot(RMSE_tree, aes(x = area_m2, y = RMSE, color = model, size =segment.size)) + geom_point() +
        facet_grid(~image, labeller = label_both)

  png("figs/RMSE_tree_compare_n.ptsXRMSE_poster.png", width = 7, height = 8, units = "in", res = 720)
  print(p2)
  dev.off()

  myPalette <- colorRampPalette(rev(brewer.pal(11, "YlOrRd")))

  sc <- scale_colour_gradientn(colours = myPalette(100), limits=c(1, 105), breaks = c(1,30,60,105))

  p3 <-   ggplot(RMSE_tree, aes(x = area_m2, y = RMSE, color = segment.size, group = segment.size))  +
      geom_line(size = 1) +
     geom_point(size = 3) +
      facet_grid(model~image, labeller = label_both) +
      sc +
      labs(color = expression(paste("Segment Size ", m^{2})),
           x = expression(paste("Area ", m^{2})),
           size = 18) +
      scale_x_continuous(breaks = c(50, 200, 800), limits = c(40,840)) +
      theme_grey(base_size = 15) +
      theme(axis.text = element_text(size = 18))

  p3

  png("../../Posters/RMSE_tree_compare_n.ptsXRMSE_poster.png", width = 9, height = 7, units = "in", res = 1020)
  print(p3)
  dev.off()




  png("figs/RMSE_tree_compare_n.ptsXRMSE_poster.png", width = 7, height = 7, units = "in", res = 1020)
  print(p3)
  dev.off()





  RMSE_tree.naip.svm <- RMSE_tree %>%
      filter(image == "NAIP",
             model == "Support Vector Machines")

  p4 <-   ggplot(RMSE_tree.naip.svm, aes(x = area_m2, y = RMSE, color = segment.size, group = segment.size))  +
      geom_line(size = 1) +
     geom_point(size = 3) +
      sc +
      labs(color = expression(paste("Segment Size ", m^{2})),
           x = expression(paste("Area ", m^{2})),
           y = "Error  (RMSE)",
           size = 22) +
      scale_x_continuous(breaks = c(50, 200, 800), limits = c(40,840)) +
      theme_grey(base_size = 18) +
     theme(axis.text = element_text(size = 18),
           legend.text = element_text(size = 18),
           legend.title = element_text(size = 22))

  p4

  png("../../Posters/RMSE_tree_NAIP_svmXRMSE_poster.png", width = 9, height = 7, units = "in", res = 1020)
  print(p4)
  dev.off()


#+END_SRC

#+RESULTS:
[[file:figs/RMSE_tree_compare_n.ptsXRMSE.png]]


#+BEGIN_SRC R :results graphics :file figs/RMSE_tree_compare_AreaXRMSE_NAIP_seg60.png
  RMSE_tree.sub <- RMSE_tree%>%
      filter(segment.size == 60, image == "madisonNAIP", target.type == "binomial", model == "svm_resp") %>%
      mutate(area_meters_squared = ((sqrt(n.points) - 1) * 7)^2)


  ggplot(RMSE_tree.sub, aes(x = area_meters_squared, y = RMSE_t), color = "blue") + geom_point() +
      labs(y = "Root Mean Squared Prediction Error \n for Percent Tree Cover") +
      theme_classic() +
      theme(axis.title = element_text(size = 24),
            axis.text =  element_text(size = 22)) +
      xlim(0,45000)

#+END_SRC

#+RESULTS:
[[file:figs/RMSE_tree_compare_AreaXRMSE_NAIP_seg60.png]]


#+BEGIN_SRC R :results graphics :file figs/RMSE_tree_compare_seg.sizeXRMSE.png :height 800 :width 600

  ggplot(RMSE_tree, aes(x = segment.size, y = RMSE_t, color = n.points, group = interaction(n.points,target.type))) + geom_line() +
      facet_grid(model~image)

#+END_SRC

#+RESULTS:
[[file:figs/RMSE_tree_compare_seg.sizeXRMSE.png]]


#+BEGIN_SRC R :results raw

  m1 <-lm(RMSE_t*100 ~ image * (model +  target.type + n.points * segment.size), data = RMSE_tree)
  tidy(m1, digits = 2) %>%
ascii()
#+END_SRC

#+RESULTS:
#+begin_example
|    | term                                   | estimate | std.error | statistic | p.value |
|----+----------------------------------------+----------+-----------+-----------+---------|
| 1  | (Intercept)                            | 42.29    | 1.85      | 22.89     | 0.00    |
| 2  | imagepanshpSPOT                        | -5.24    | 2.61      | -2.01     | 0.05    |
| 3  | modelrf_resp                           | 0.05     | 1.56      | 0.03      | 0.97    |
| 4  | modelsvm_resp                          | -4.90    | 1.56      | -3.14     | 0.00    |
| 5  | target.typemultinomial                 | -0.76    | 1.28      | -0.59     | 0.55    |
| 6  | n.points                               | -0.04    | 0.01      | -5.20     | 0.00    |
| 7  | segment.size                           | -0.17    | 0.02      | -7.10     | 0.00    |
| 8  | n.points:segment.size                  | -0.00    | 0.00      | -0.82     | 0.41    |
| 9  | imagepanshpSPOT:modelrf_resp           | -0.88    | 2.21      | -0.40     | 0.69    |
| 10 | imagepanshpSPOT:modelsvm_resp          | 9.12     | 2.21      | 4.13      | 0.00    |
| 11 | imagepanshpSPOT:target.typemultinomial | -3.40    | 1.80      | -1.88     | 0.06    |
| 12 | imagepanshpSPOT:n.points               | 0.01     | 0.01      | 0.66      | 0.51    |
| 13 | imagepanshpSPOT:segment.size           | 0.20     | 0.03      | 6.02      | 0.00    |
| 14 | imagepanshpSPOT:n.points:segment.size  | 0.00     | 0.00      | 0.02      | 0.99    |
#+end_example


** Field Plot
*** Combine google earth grid estimates of cover with classified tile estimates of cover
Create dataframe with structure:

| %t.img | %g.img | %i.img | %o.img | image      | segmentation | target              | model                   | tile                   | defintion.tree | %t.field | %g.field | %i.field | %o.field |   |   |   |   |   |   |   |   |
|--------+--------+--------+--------+------------+--------------+---------------------+-------------------------+------------------------+----------------+----------+----------+----------+----------+---+---+---+---+---+---+---+---|
|    0-1 |    0-1 |    0-1 |    0-1 | NAIP       | Pixel        | binomial (two)      | random forest prob      | mad-size-id (up to 50) |                |      0-1 |      0-1 |      0-1 |      0-1 |   |   |   |   |   |   |   |   |
|        |        |        |        | panshpSPOT | 30 m2        | multinomial (three) | random forest resp      |                        |                |          |          |          |          |   |   |   |   |   |   |   |   |
|        |        |        |        |            | 60 m2        |                     | support vector machines |                        |                |          |          |          |          |   |   |   |   |   |   |   |   |
|        |        |        |        |            |              |                     |                         |                        |                |          |          |          |          |   |   |   |   |   |   |   |   |
|        |        |        |        |            | 105 m2       |                     |                         |                        |                |          |          |          |          |   |   |   |   |   |   |   |   |


*** Calc RMSE table

Create dataframe with structure:

| RMSE | image | segmentation | target | model | tile | definition.tree | cover_type |   |   |   |   |   |   |   |
|------+-------+--------------+--------+-------+------+-----------------+------------+---+---+---+---+---+---+---|
|      |       |              |        |       |      |                 |            |   |   |   |   |   |   |   |







* subset smaller urban areas
:PROPERTIES:
:ARCHIVE_TIME: 2016-06-07 Tue 06:52
:ARCHIVE_FILE: /ssh:erker@kang:/home/erker/mydata2/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Classify Every Urban Area in the State/Load NAIP tifs/For every urban area in the state
:ARCHIVE_CATEGORY: utc
:END:
#+begin_src R
  areas <- foreach(i = 1:length(urb.polys), .combine = "rbind") %do% gArea(urb.polys[i])
  quant.85 <- quantile(areas[,1],probs = .85)
  i_areas_less_85quant <- which(areas[,1] < quant.85)
#+end_src

#+results:


* Workflow
:PROPERTIES:
:ARCHIVE_TIME: 2016-06-07 Tue 11:11
:ARCHIVE_FILE: /ssh:kang:/home/erker/mydata2/Pjt_UTC/code/utc.org
:ARCHIVE_CATEGORY: utc
:END:
** Libraries
#+BEGIN_SRC R
  library(ascii)
  library(rgeos)
  library(mlr)
  library(broom)
  library(rgdal)
  library(raster)
  library(plyr)
  library(ggplot2)
  library(dplyr)
  library(tidyr)
  library(stringr)
  library(foreach)
  library(doParallel)
#+END_SRC

#+RESULTS:
#+begin_example
rgeos version: 0.3-11, (SVN revision 479)
 GEOS runtime version: 3.4.2-CAPI-1.8.2 r3921
 Linking to sp version: 1.1-1
 Polygon checking: TRUE
Loading required package: BBmisc

Attaching package: BBmisc

The following object is masked from package:rgeos:

    symdiff

Loading required package: ggplot2
Loading required package: ParamHelpers
Loading required package: sp
rgdal: version: 1.0-4, (SVN revision 548)
 Geospatial Data Abstraction Library extensions to R successfully loaded
 Loaded GDAL runtime: GDAL 1.10.0, released 2013/04/24
 Path to GDAL shared files: /usr/share/gdal/1.10
 Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
 Path to PROJ.4 shared files: (autodetected)
 Linking to sp version: 1.1-1

Attaching package: raster

The following object is masked from package:mlr:

    resample

The following object is masked from package:ParamHelpers:

    getValues

Warning message:
no function found corresponding to methods exports from raster for: overlay

Attaching package: dplyr

The following objects are masked from package:plyr:

    arrange, count, desc, failwith, id, mutate, rename, summarise,
    summarize

The following objects are masked from package:raster:

    intersect, select, union

The following object is masked from package:BBmisc:

    collapse

The following objects are masked from package:rgeos:

    intersect, setdiff, union

The following objects are masked from package:stats:

    filter, lag

The following objects are masked from package:base:

    intersect, setdiff, setequal, union

Attaching package: tidyr

The following object is masked from package:raster:

    extract

The following object is masked from package:ascii:

    expand
foreach: simple, scalable parallel programming from Revolution Analytics
Use Revolution R for scalability, fault tolerance and more.
http://www.revolutionanalytics.com
Loading required package: iterators
Loading required package: parallel
#+end_example

** set figure Cairo
#+begin_src R :exports none :results silent
  library(Cairo)
  mainfont <- "Garamond"
  CairoFonts(regular = paste(mainfont,"style=Regular",sep=":"),
             bold = paste(mainfont,"style=Bold",sep=":"),
             italic = paste(mainfont,"style=Italic",sep=":"),
             bolditalic = paste(mainfont,"style=Bold Italic,BoldItalic",sep=":"))
  pdf <- CairoPDF
  png <- CairoPNG
#+end_src
** Inputs
**** Input Directories
#+BEGIN_SRC R
  image.dirs <- c("../RD_NAIP","../RD_SPOT")
  pca.dir <- "../RD_PCA_Regions"
  training.dir <- "../RD_Training_Regions"
  accuracy.dir <- "../RD_Accuracy"
  grids.accuracy.dir <- str_c(accuracy.dir, "/Grids")
  fieldplots.accuracy.dir<- str_c(accuracy.dir, "/FieldData")
  crop.dir <- "../RD_CroplandDataLayer"
  water.dir <- "../RD_WI-waterbody-24k"
  urban.dir <- "../RD_US_UrbanAreasShapefile"
  urban.and.incorporated.dir <- "../RD_merged_WIurbanAreas_and_incorporatedAreas"
#+END_SRC

#+RESULTS:

**** Variable Names and Paths
#+BEGIN_SRC R
  image.names <- c("madisonNAIP","panshpSPOT")
  image.paths <- paste0(image.dirs, "/", image.names, ".tif")

  ratio.tile.name.append <- "_ratio"
  pca.tile.name.append <- "_pca"

  segment.params <- list(list(area = c(105,60,30), compactness = c(32,30,15)),
                         list(area = c(105,60,30), compactness = c(21,20,10)))
  names(segment.params) <- image.names

  band.names.wRatios <- c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")

  pixel.feature.df.appendage = "_PixelFeatureDF"

  pca.model.name.appendage = "_pca.rds"

  segmentation.layer.pattern = "_N-[0-9]+_C-[0-9]+"

  segmentFeatureDF.appendage = "_SegmentFeatureDF.rds"

  FeatureDF.appendage = "_FeatureDF.rds"
  ModelBuilding.appendage = ".ModelBuilding.rds"
  models.appendage = ".models.rds"

  tile.id.col.nm.for.grid.and.field.accuracy <- c("unq__ID", "Plot")

  grid.pattern = "[a-zA-Z]{3}-[0-9]+m-[0-9]+_"

#+END_SRC

#+RESULTS:

**** Input Shapefile DSNs and Layers
#+BEGIN_SRC R

  pca.region.dsn <- "../RD_PCA_Regions/Madison_PCA_Regions"
  pca.region.layer <- "PCA_regions"

  training.region.dsn <- "../RD_Training_Regions/Madison_TrainingRegions"
  training.region.layer <- "madisonTrainingPolygons"



  grid.accuracy.region.dsn <- "../RD_Accuracy/Grids"
  grid.accuracy.region.layer <- "All_Grids_Accuracy_Assessment_Added_pts"

  field.accuracy.region.dsn <- "../RD_Accuracy/FieldData"
  field.accuracy.region.layer <- "fieldPoints"

  accuracy.region.dsn <- c(grid.accuracy.region.dsn, field.accuracy.region.dsn)
  accuracy.region.layer <- c(grid.accuracy.region.layer, field.accuracy.region.layer)

                                          # grid.accuracy.truthFromAndy.csvpath <- str_c(grid.accuracy.region.dsn,"grid_accuracy_assessment_andy.csv")

#+END_SRC

#+RESULTS:

**** Derived Directories
#+BEGIN_SRC R
                                          # make derived data directory
  derived.dir <- "../DD"

  dd.training.dir <- str_c(derived.dir, "/Madison_Training")

  dd.pca.dir <- str_c(derived.dir, "/Madison_pca")

  dd.accuracy.dir <- str_c(derived.dir, "/Accuracy")

  Models.dir <- paste0(derived.dir,"/","Models")

  ClassifiedTilesDirName <- "ClassifiedTiles"

  dd.accuracy.classified.dir <- str_c(dd.accuracy.dir, "/", ClassifiedTilesDirName)

#+END_SRC

#+RESULTS:

**** Make Derived Directories
#+BEGIN_SRC R
  dir.create(derived.dir)
  dir.create(dd.accuracy.classified.dir)
  lapply(dd.training.dir, FUN = function(x) dir.create(x))
  lapply(dd.pca.dir, FUN = function(x) dir.create(x))
  lapply(dd.accuracy.dir, FUN = function(x) dir.create(x))
  lapply(Models.dir, FUN = function(x) dir.create(x))
#+END_SRC

#+RESULTS:
#+begin_example
Warning message:
In dir.create(derived.dir) : '../DD' already exists
Warning message:
In dir.create(dd.accuracy.classified.dir) :
  '../DD/Accuracy/ClassifiedTiles' already exists
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/Madison_Training' already exists
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/Madison_pca' already exists
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/Accuracy' already exists
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/Models' already exists
#+end_example

**** Define Derived Shapefile DSNs and Layers
#+BEGIN_SRC R
  training.region.imageCRS.dsn <- str_c(derived.dir,"/reprojected.Training_Regions")

  pca.region.imageCRS.dsn <- str_c(derived.dir,"/reprojected.PCA_Regions")

  accuracy.region.imageCRS.dsn <- str_c(derived.dir,"/reprojected.Accuracy.Regions")


  lapply(training.region.imageCRS.dsn, FUN = function(x) dir.create(x))
  lapply(pca.region.imageCRS.dsn, FUN = function(x) dir.create(x))
  lapply(accuracy.region.imageCRS.dsn, FUN = function(x) dir.create(x))
#+END_SRC

#+RESULTS:
#+begin_example
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/reprojected.Training_Regions' already exists
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/reprojected.PCA_Regions' already exists
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/reprojected.Accuracy.Regions' already exists
#+end_example

**** number of cores
#+BEGIN_SRC R
  cores <- 15
#+END_SRC

#+RESULTS:

**** CRS
#+BEGIN_SRC R
  utm16 <- CRS("+init=epsg:32616")
  wtm <- CRS("+init=epsg:3071")
#+END_SRC

#+RESULTS:


** Functions

*** Extract Name from path
#+BEGIN_SRC R
  extract.name.from.path <- function(path) {
      str_extract(basename(path), "[A-Za-z0-9_]*.") %>%
          str_sub(.,1,-2)
  }
#+END_SRC

#+RESULTS:

*** Reproject Shapefile to Image Coordinate Reference System
#+BEGIN_SRC R
  Reproject_Shapefile_to_Image_CRS <- function(shapefile.dsn,
                                               shapefile.layer,
                                               image.path,
                                               shapefile.out.dsn) {
      r <- stack(image.path)
      shapefile <- readOGR(shapefile.dsn, shapefile.layer)
      shapefile.WimageCRS <- spTransform(shapefile, crs(r))
      image.name <- extract.name.from.path(image.path)
      shapefile.layer  <- str_c(image.name,"_",shapefile.layer)
      writeOGR(shapefile.WimageCRS, shapefile.out.dsn, shapefile.layer, driver = "ESRI Shapefile", overwrite =T)
  }
#+END_SRC

#+RESULTS:

*** Crop image to each Shapefile polygon
#+BEGIN_SRC R
  Crop_image_to_each_Shapefile_polygon <- function(shapefile.dsn,
                                                   shapefile.layer,
                                                   image.path,
                                                   cores,
                                                   output.dir)  {
      image.name <- extract.name.from.path(image.path)
      shape <- readOGR(shapefile.dsn, str_c(image.name,"_",shapefile.layer))
      polygons <- as(shape, "SpatialPolygons")

      image <- stack(image.path)

      cl <- makeCluster(cores)
      registerDoParallel(cl)

      foreach (i = seq_along(polygons),
               .packages = c("raster")) %dopar% {
                   r <- image
                   r <- crop(r, polygons[i])
                   writeRaster(r, paste0(output.dir,"/",image.name,"-",i,".tif"),
                               overwrite = T)
               }
  }

#+END_SRC

#+RESULTS:

*** Crop image to regions around shapefile points
#+BEGIN_SRC R

                                          # assign the polygon name to the points.
  give_polygons_attributes_of_first_point_within <- function(points,
                                                             polygons){
      if (length(points@data$row) >1) {
          points <- points[points@data$row ==1 & points@data$col ==1 ,]
      }
      po <- gIntersects(points, polygons, byid=TRUE)
      out <- foreach(polygon.number = seq_along(polygons), .combine = "rbind") %do% {
          first.point.data <- points[po[polygon.number,],]@data %>%
              slice(1)
          pd <- as(polygons[polygon.number], "SpatialPolygonsDataFrame")
          pd@data <- first.point.data
          pd
      }
  }

  Crop_image_to_regions_around_points_nameBygrid<- function(shapefile.dsn,
                                                            shapefile.layer,
                                                            image.path,
                                                            cores,
                                                            output.dir,
                                                            column.name = "unq__ID",
                                                            point.buffer.size = 4,
                                                            polygon.buffer.size = 15)  {
      image.name <- extract.name.from.path(image.path)
      points <- readOGR(shapefile.dsn,str_c(image.name,"_",shapefile.layer))
      box <- gBuffer(points, width = point.buffer.size, byid = F)
      box <- disaggregate(box)

      polygons <- as(box, "SpatialPolygons")

      polygons <- give_polygons_attributes_of_first_point_within(points,polygons)

      image <- stack(image.path)

      image.extent <- as(extent(image), "SpatialPolygons")
      proj4string(image.extent) <- proj4string(image)

      polygons.in.image <- foreach(i = seq_along(polygons),.combine = "c") %do% {
          gIntersects(polygons[i,],image.extent)
      }

      polygons <- polygons[polygons.in.image,]

      cl <- makeCluster(cores)
      registerDoParallel(cl)

      foreach (k = seq_along(polygons),
               .packages = c("raster","rgeos")) %dopar% {
                   r <- image
                   poly <- gBuffer(polygons[k,],width = polygon.buffer.size, byid = T)
                   r <- crop(r, poly)
                   tile.id <- polygons@data[k,column.name]
                   writeRaster(r, paste0(output.dir,"/",image.name,"_",tile.id,".tif"),
                               overwrite = T)
               }
  }

                                          #  shapefile.dsn = grid.accuracy.region.imageCRS.dsn
                                          #  shapefile.layer = grid.accuracy.region.layer,
                                          #  output.dir = image.cropped.to.grid.accuracy.dir


  Crop_image_to_regions_around_points <- function(shapefile.dsn,
                                                  shapefile.layer,
                                                  image.path,
                                                  cores,
                                                  output.dir)  {

      points <- readOGR(shapefile.dsn, shapefile.layer)
      box <- gBuffer(points, width = 8)
      box <- disaggregate(box)

      polygons <- as(box, "SpatialPolygons")

      image <- stack(image.path)

      cl <- makeCluster(cores)
      registerDoParallel(cl)

      foreach (i = seq_along(polygons),
               .packages = c("raster")) %dopar% {
                   r <- image
                   r <- crop(r, polygons[i])
                   writeRaster(r, paste0(output.dir,"/",i,".tif"),
                               overwrite = T)
               }
  }

#+END_SRC

#+RESULTS:

*** Make new ratio bands from image
#+BEGIN_SRC R
  ratio <- function(image_w4bands, numerator_bandNumber) {
      r <- image_w4bands[,,numerator_bandNumber,drop = F] / sum(image_w4bands)
      return(r)
  }

  ndvi_nodrop <- function(image_w4bands,red_bandnumber,nir_bandnumber,...) {
      red_band <- image_w4bands[[red_bandnumber]]
      nir_band <- image_w4bands[[nir_bandnumber]]
      ndvi <- (nir_band - red_band)/(nir_band + red_band)
      return(ndvi)
  }

  add.ratios.ndvi <- function(tile.dir,
                              tile.name,
                              out.tile.name.append = ratio.tile.name.append,
                              band.names = c("blue","green","red","nir"),
                              red.band.number = 3,
                              nir.band.number = 4) {

      in.tile.path <- str_c(tile.dir, "/", tile.name, ".tif")
      tile <- stack(in.tile.path)
      names(tile) <- band.names

                                          # Create a ratio image for each band
      ratio.brick <- ratio(tile)
      ratio.brick <- ratio.brick*200 # rescale ndvi to save as 'INT1U'
      names(ratio.brick) <- paste0(band.names,rep("_ratio",times = 4))
      ndvi <- ndvi_nodrop(tile, red.band.number, nir.band.number)
      ndvi <- (ndvi+1)*100 # rescale ndvi to savep as 'INT1U'

                                          # if tile is not scaled 0-255, do it here
      if (getRasterMax(tile) > 255) {
          min <- getRasterMin(tile)
          max <- getRasterMax(tile)
          tile <- rescale.0.255(tile,min,max)
      }

      ratio.tile <- raster::stack(tile, ratio.brick, ndvi)
      writeRaster(ratio.tile,
                  filename = paste0(tile.dir,"/",tile.name,out.tile.name.append, ".tif"),
                  overwrite = T,
                  datatype = 'INT1U')
  }
#+END_SRC

#+RESULTS:

*** Image PCA
#+BEGIN_SRC R
  getRasterMin <- function(t) {
      return(min(cellStats(t, stat = "min")))
  }

  getRasterMax <- function(t) {
      return(max(cellStats(t, stat = "max")))
  }

  rescale.0.255 <- function(raster,
                            min,
                            max) {
                                (raster - min)/(max-min) * 255
  }

  image.pca <- function(image.name,
                        pca.model.name.append = pca.model.name.appendage,
                        tile.dir,
                        tile.name,
                        in.image.appendage = ratio.tile.name.append,
                        out.image.appendage = pca.tile.name.append,
                        band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi"),
                        comps.to.use = c(1,2,3),
                        pca.dir = dd.pca.dir) {


      out.path <- str_c(tile.dir, "/", tile.name, out.image.appendage, ".tif")

      s <- stack(str_c(tile.dir, "/", tile.name, in.image.appendage,".tif"))
      names(s) <- band.names

      pca.model <- readRDS(str_c(pca.dir,"/",image.name,pca.model.name.append))

      r <- predict(s, pca.model, index = comps.to.use)

      min.r <- getRasterMin(r)
      max.r <- getRasterMax(r)
      rescaled.r <- rescale.0.255(r, min.r, max.r)
      writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')
  }



  make.and.save.pca.transformation <- function(tile.dir,
                                               image.name,
                                               pca.model.name.append = pca.model.name.appendage,
                                               max.sample.size = 10000,
                                               core.num = cores,
                                               band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {

      tile.paths <- list.files(str_c(tile.dir), pattern = str_c(image.name,".*_with_ratios.tif$"), full.names = T)

      tile.names <- basename(tile.paths)

      cl <- makeCluster(core.num)
      registerDoParallel(cl)

      sr <- foreach (i = seq_along(tile.names), .packages = c("raster"), .combine ="rbind") %dopar% {
          tile <- stack(tile.paths[i])
          s <- sampleRandom(tile, ifelse(ncell(tile) > max.sample.size ,max.sample.size, ncell(tile)))
      }

      colnames(sr) <- band.names

                                          # Perform PCA on sample
      pca <- prcomp(sr, scale = T)
      saveRDS(pca,paste0(tile.dir,"/",image.name,pca.model.name.append))
      return(pca)
  }


  image.pca.forWholeState <- function(pca.model.name.append = pca.model.name.appendage,
                                      tile.dir,
                                      tile.name,
                                      in.image.appendage = ratio.tile.name.append,
                                      out.image.appendage = pca.tile.name.append,
                                      band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi"),
                                      comps.to.use = c(1,2,3),
                                      pca.transform) {


      out.path <- str_c(tile.dir, "/", tile.name, out.image.appendage, ".tif")

      s <- stack(str_c(tile.dir, "/", tile.name, in.image.appendage,".tif"))
      names(s) <- band.names

      r <- predict(s, pca.transform, index = comps.to.use)

      min.r <- getRasterMin(r)
      max.r <- getRasterMax(r)
      rescaled.r <- rescale.0.255(r, min.r, max.r)
      writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')
  }



  ## image.dir <- image.cropped.to.training.dir
  ## image.name <- 9
  ##                         in.image.appendage = ratio.tile.name.append
  ##                         out.image.appendage = pca.tile.name.append
  ##                         band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")
  ##                         max.sample.size = 10000
  ##                         comps.to.use = c(1,2,3)

  ##       out.path <- str_c(image.dir, "/", image.name, out.image.appendage, ".tif")

  ##       s <- stack(str_c(image.dir, "/", image.name, in.image.appendage,".tif"))
  ##       names(s) <- band.names

  ##       sr <- sampleRandom(s, ifelse(ncell(s) > max.sample.size, max.sample.size, ncell(s)))
  ##       pca <- prcomp(sr, scale = T)

  ##       r <- predict(s, pca, index = comps.to.use)

  ##       min.r <- getRasterMin(r)
  ##       max.r <- getRasterMax(r)
  ##       rescaled.r <- rescale.0.255(r, min.r, max.r)
  ##       writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')









                                          # Function takes raster stack, samples data, performs pca and returns stack of first n_pcomp bands
  ## predict_pca_wSampling_parallel <- function(stack, sampleNumber, n_pcomp, nCores = detectCores()-1) {
  ##     sr <- sampleRandom(stack,sampleNumber)
  ##     pca <- prcomp(sr, scale=T)
  ##     beginCluster()
  ##     r <- clusterR(stack, predict, args = list(pca, index = 1:n_pcomp))
  ##     endCluster()
  ##     return(r)
  ## }
#+END_SRC

#+RESULTS:

*** polygonize segment raster with gdal and add Class to shapefile

#+BEGIN_SRC R
  gdal_polygonizeR <- function(x, outshape=NULL, gdalformat = 'ESRI Shapefile',
                               pypath=NULL, readpoly=TRUE, quiet=TRUE) {
      if (isTRUE(readpoly)) require(rgdal)
      if (is.null(pypath)) {
          pypath <- Sys.which('gdal_polygonize.py')
      }
      if (!file.exists(pypath)) stop("Can't find gdal_polygonize.py on your system.")
      owd <- getwd()
      on.exit(setwd(owd))
      setwd(dirname(pypath))
      if (!is.null(outshape)) {
          outshape <- sub('\\.shp$', '', outshape)
          f.exists <- file.exists(paste(outshape, c('shp', 'shx', 'dbf'), sep='.'))
          if (any(f.exists))
              stop(sprintf('File already exists: %s',
                           toString(paste(outshape, c('shp', 'shx', 'dbf'),
                                          sep='.')[f.exists])), call.=FALSE)
      } else outshape <- tempfile()
      if (is(x, 'Raster')) {
          require(raster)
          writeRaster(x, {f <- tempfile(fileext='.asc')})
          rastpath <- normalizePath(f)
      } else if (is.character(x)) {
          rastpath <- normalizePath(x)
      } else stop('x must be a file path (character string), or a Raster object.')
      system2('python', args=(sprintf('"%1$s" "%2$s" -f "%3$s" "%4$s.shp"',
                                      pypath, rastpath, gdalformat, outshape)))
      if (isTRUE(readpoly)) {
          shp <- readOGR(dirname(outshape), layer = basename(outshape), verbose=!quiet)
          return(shp)
      }
      return(NULL)
  }


  polygonize.and.add.Class <- function(image.dir,
                                       image.name,
                                       segment.appendage = segment.tile.name.append,
                                       no.class = "N") {
      seg <- raster(paste0(image.dir,"/",image.name,segment.appendage,'.tif'))
      segPoly <- gdal_polygonizeR(seg)
      segPoly$Class <- no.class
      writeOGR(obj = segPoly,
               dsn = paste0(image.dir,"/",image.name),
               layer = paste0(image.name,segment.appendage),
               driver = "ESRI Shapefile",
               overwrite = T)
  }






#+END_SRC

#+RESULTS:

*** other Functions
#+BEGIN_SRC R

  image_to_classified_image <- function()





                                          # contained urban, don't intersect water = as is
                                          # contained urban, intersect water = mask water
                                          # intersect urban, don't intersect water = mask urban
                                          # intersect urban, intersect water = mask urban & water
                                          # if none of the above, don't write the raster



      Mask_water_crops_urban <- function(image.full.path, water, crops, urban) {

      }




  Water_Urban_mask <- function(tile.path, tile.name, urban, water) {
                                          # load image tile
      tile <- stack(tile.path)
                                          # get extent image and make sp object
      et <- as(extent(tile), "SpatialPolygons")
      proj4string(et) <- "+init=epsg:26916"
                                          # Mask out non-urban areas
      if(gContainsProperly(urban,et) & !gIntersects(water,et)){
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      } else if (gContainsProperly(urban,et) & gIntersects(water,et)) {
          tile <- mask(tile, water, inverse = T)
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      } else if (gIntersects(urban, et) & !gIntersects(water,et)) {
          tile <- mask(tile, urban)
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      } else if (gIntersects(urban, et) & gIntersects(water,et)) {
          tile <- mask(tile, urban)
          tile <- mask(tile, water, inverse = T)
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      }
  }

  Crop_mask <- function(tile.path, tile.name, CDL_stack, n_years){

      tile <- stack(tile.path)
      crops <- crop(CDL_stack, tile)

                                          # These are the values in the CDL that correspond to non crop cover types and not water
      NonCroppedValues <- c(0,63:65, 81:83, 87:88, 112, 121:124, 131, 141:143, 152, 176, 190, 195)
                                          # open water is 111

      NonCroppedValues <- c(0,63:65, 81:83, 87:88, 112, 121:124, 131, 141:143, 152, 176, 190, 195)
                                          # open water is 111. I don't include it in the above list so that it gets masked

                                          # I'm going to add 37, Other Hay/Non-alfalfa, to the non crop cover types
      NonCroppedValues <- c(NonCroppedValues, 37)
                                          # I'm going to add 36, Alfalfa, to the non crop cover types
      NonCroppedValues <- c(NonCroppedValues, 36)

                                          # find cells that have been assigned crop all three years
      crops[crops %in% NonCroppedValues] <- 0
      crops[!(crops %in% NonCroppedValues)] <- 1
      cropsum <- overlay(crops, fun = sum)

      dis.cropsum <- disaggregate(cropsum, fact = 20)
      dis.cropsum <- resample(dis.cropsum, tile, "ngb")
      masked_tile <- mask(tile, dis.cropsum, maskvalue = n_years)

                                          #               Save Image
      writeRaster(masked_tile, paste0(crop.masked.tiles.directory, "/", tile.name), overwrite = T)
  }








#+END_SRC

#+RESULTS:

*** Make Pixel Feature DF
#+BEGIN_SRC R
  Create.Pixel.Feature.df <- function(tile.dir,
                                      tile.name,
                                      tile.appendage = ratio.tile.name.append,
                                      Pixel.DF.appendage = pixel.feature.df.appendage,
                                      band.names = band.names.wRatios) {
      r <- stack(paste0(tile.dir,"/",tile.name,tile.appendage,".tif"))
      names(r) <- band.names
      r.df <- as.data.frame(r, xy=T)
      saveRDS(r.df, file = paste0(tile.dir,"/", tile.name, Pixel.DF.appendage, ".rds"))
  }



  ## Create.Pixel.Feature.df<- function(raster.list,
  ##                                    band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {
  ##     r.df.list <- lapply(raster.list, function(r) {
  ##                             names(r) <- band.names
  ##                             as.data.frame(r, xy=T)
  ##            })
  ##     bind_rows(r.df.list)
  ## }

  Create.Pixel.Feature.df.noRowbind<- function(raster.list,
                                               band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {
      r.df.list <- lapply(raster.list, function(r) {
          names(r) <- band.names
          as.data.frame(r, xy=T)
      })
      r.df.list
  }


  Create.Pixel.Feature.df.foreachTile <- function(dir = image.cropped.to.grid.accuracy.dir[i],
                                                  base_pattern = "mad-[0-9]+m-[0-9]+_with_ratios.tif",
                                                  band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {

      file.list <- list.files(dir, full.names = T) %>%
          str_extract(., paste0(".*",base_pattern)) %>%
          na.omit() %>%
          unique()

      r.df.list <- lapply(file.list, function(r) {
          ras <- stack(r)
          names(ras) <- band.names
          ras.df <- as.data.frame(r, xy=T)

          r <- str_extract(r, base_pattern) %>%
              str_sub(., 1, -17)

          saveRDS(ras.df, file = str_c(dir,"/",r,"PixelFeatureDF",".rds"))
      })
  }

#+END_SRC

#+RESULTS:

*** Make Segment Feature DF
#+BEGIN_SRC R
  fitXYlm <- function(x,y,z) {
      if(is.na(sum(z))) {
          z <- rep(0, length(z))
      }
      dat <- data.frame(x,y,z)
      mod <- lm(z ~ x * y, data = dat)
      coefs <-tidy(mod) %>%
          dplyr::select(term,estimate) %>%
          spread(key = term, value = estimate)

      error <- glance(mod) %>%
          select(sigma)

      bind_cols(coefs,error)
  }

                                          #foreach(seg.param.set = seg.param) %do% {}

  image.dir = image.cropped.to.training.dir[2]
  tile.name = tile.names[1]
  ratio.tile.name.append


  Create.Segment.Feature.df <- function(tile.dir,
                                        tile.name,
                                        ratio.appendage = ratio.tile.name.append,
                                        band.names = band.names.wRatios){

                                          #tile.name.stem everything before segmentation parameters
      tile.name.stem = str_replace(tile.name, pattern = segmentation.layer.pattern, "")

      ratio.tile.path <- str_c(tile.dir, "/", tile.name.stem, ratio.tile.name.append, ".tif")
      r.tile <- stack(ratio.tile.path)

      names(r.tile) <- band.names


      seg.tile.path <-  str_c(tile.dir, "/", tile.name,".tif")
      s.tile <- raster(seg.tile.path)

                                          # Create a data_frame where mean and variances are calculated by zone
      x <- as.data.frame(r.tile, xy = T)
      s <- as.data.frame(s.tile)
      colnames(s) <- "segment"
      r <- bind_cols(x,s)
      r2 <- r %>%
          group_by(segment) %>%
          mutate(x.center = x - quantile(x = x, probs = .5),
                 y.center = y - quantile(x = y, probs = .5))

      spatial.model.coef <- r2 %>%
          do(fitXYlm(x = .$x.center, y = .$y.center, z = .$n_ratio))

      mean.and.sd <- r2 %>%
          summarize(mean(blue),
                    mean(green),
                    mean(red),
                    mean(nir),
                    mean(b_ratio),
                    mean(g_ratio),
                    mean(r_ratio),
                    mean(n_ratio),
                    mean(ndvi),
                    sd(blue),
                    sd(green),
                    sd(red),
                    sd(nir),
                    sd(b_ratio),
                    sd(g_ratio),
                    sd(r_ratio),
                    sd(n_ratio),
                    sd(ndvi))

      tile.name = data.frame(tile.name = rep(tile.name.stem, nrow(mean.and.sd)))

      out <- left_join(spatial.model.coef, mean.and.sd) %>%
          bind_cols(., tile.name)

      names <- colnames(out)
      names <- str_replace(names, "\\(",".")
      names <- str_replace(names, "\\)",".")
      names <- str_replace(names, "\\:",".")
      colnames(out) <- names
      out
  }

  Create.Segment.Feature.df.noLM <- function(tile.dir,
                                             tile.name,
                                             ratio.appendage = ratio.tile.name.append,
                                             band.names = band.names.wRatios){

                                          #tile.name.stem everything before segmentation parameters
      tile.name.stem = str_replace(tile.name, pattern = segmentation.layer.pattern, "")

      ratio.tile.path <- str_c(tile.dir, "/", tile.name.stem, ratio.tile.name.append, ".tif")
      r.tile <- stack(ratio.tile.path)

      names(r.tile) <- band.names


      seg.tile.path <-  str_c(tile.dir, "/", tile.name,".tif")
      s.tile <- raster(seg.tile.path)

                                          # Create a data_frame where mean and variances are calculated by zone
      x <- as.data.frame(r.tile, xy = T)
      s <- as.data.frame(s.tile)
      colnames(s) <- "segment"
      r <- bind_cols(x,s)
      r2 <- r %>%
          group_by(segment)

      mean.and.sd <- r2 %>%
          summarize(mean(blue),
                    mean(green),
                    mean(red),
                    mean(nir),
                    mean(b_ratio),
                    mean(g_ratio),
                    mean(r_ratio),
                    mean(n_ratio),
                    mean(ndvi),
                    sd(blue),
                    sd(green),
                    sd(red),
                    sd(nir),
                    sd(b_ratio),
                    sd(g_ratio),
                    sd(r_ratio),
                    sd(n_ratio),
                    sd(ndvi))

      tile.name = data.frame(tile.name = rep(tile.name.stem, nrow(mean.and.sd)))

      out <- bind_cols(mean.and.sd, tile.name)

      names <- colnames(out)
      names <- str_replace(names, "\\(",".")
      names <- str_replace(names, "\\)",".")
      names <- str_replace(names, "\\:",".")
      colnames(out) <- names
      out
  }

#+END_SRC

#+RESULTS:
: Error: object 'image.cropped.to.training.dir' not found
: Error: object 'tile.names' not found
: [1] "_ratio"

*** Create ModelBuilding dataframe
#+BEGIN_SRC R
  getSegment.class.and.features.Within.Polygon <- function(SegmentFeatureDF,
                                                           training.sp,
                                                           seg.tiles.dir,
                                                           seg.params){
      seg.files <- list.files(seg.tiles.dir, pattern = str_c(seg.params,".tif$"), full.names = T)
                                          # find number of pixels in each segment
      n.pixels.per.seg <- foreach(seg.file = seg.files, .combine = "rbind") %do% {
          seg <- stack(seg.file)
          s.df <- as.data.frame(seg) %>%
              gather(key = tile.name, value = segment.id) %>%
              group_by(segment.id, tile.name) %>%
              summarize(n.pixels.per.seg = n())
      }
                                          # find number of pixels in each segment are in a polygon
      n.pixels.per.seg.in.polygon <- foreach(seg.file = seg.files, .combine = "rbind") %do% {
          seg <- stack(seg.file)
          a <- raster::extract(seg, as(training.sp,"SpatialPolygons"), df = T)
          if(length(a) > 1) {
              a <- a %>%
                  gather(key = tile.name, value = segment.id, -ID) %>%
                  rename(polygon.id = ID) %>%
                  group_by(polygon.id, tile.name, segment.id) %>%
                  summarize(n.pixels.per.seg.in.polygon = n())
          }
      }
                                          # get pct of segment in a polygon,
                                          # filter segments that have more than 50%,
                                          #join Class information from polygons
      if(!is.null(n.pixels.per.seg.in.polygon)) {
          n.pixels <- left_join(n.pixels.per.seg.in.polygon,n.pixels.per.seg) %>%
              mutate(pct.seg.in.polygon = n.pixels.per.seg.in.polygon/n.pixels.per.seg) %>%
              filter(pct.seg.in.polygon >= .5) %>%
              left_join(.,training.sp@data, by = c("polygon.id" = "id")) %>%
              ungroup() %>%
              mutate(tile.name = str_extract(tile.name, "X[0-9]+_"),
                     tile.name = str_sub(tile.name,2,-2)) %>%
              mutate(segment = segment.id)

          left_join(n.pixels, SegmentFeatureDF) %>%
              dplyr::select(-segment,
                            -segment.id,
                            -tile.name,
                            -polygon.id,
                            -n.pixels.per.seg,
                            -n.pixels.per.seg.in.polygon,
                            -pct.seg.in.polygon) %>%
              filter(complete.cases(.))
      }
  }

                                          # returns dataframe of values of pixels within polygon
  getPixel.Class.and.Coords.Within.Polygon <- function(PixelFeatureDF,
                                                       training.sp) {
      xy <- select(PixelFeatureDF,x,y) %>% data.frame
      PixelFeatureDF <- data.frame(PixelFeatureDF)
      coordinates(PixelFeatureDF) <- xy
      proj4string(PixelFeatureDF) <- utm16

      training.sp <- spTransform(training.sp,utm16)

      pts.in.poly <- over(PixelFeatureDF,training.sp)
      PixelFeatureDF@data <- cbind(PixelFeatureDF@data, pts.in.poly)
      PixelFeatureDF <- PixelFeatureDF[which(complete.cases(pts.in.poly)),]
      PixelFeatureDF@data
  }

                                          # this is an old way
  create.df.toBuildModel.fromTrainingPolygons.and.SegmentFeatureDFs <- function(manuallyClassifiedPolygondir,
                                                                                image.dir,
                                                                                segment.feature.df.appendage = segment.feature.df.name.append,
                                                                                modelBuildingData.name = "modelBuildingData.rds") {

      segment.feature.df.appendage = segment.feature.df.name.append

                                          # list shapefiles with manually classified polygons
      trainingShapefiles <- list.files(manuallyClassifiedPolygondir) %>%
          str_sub(.,end = nchar(.)-4) %>%
          unique()

                                          # load training data from shapefiles into memory
      shapelist.data <- lapply(trainingShapefiles, function(shp) {
          readOGR(dsn = manuallyClassifiedPolygondir, layer = shp)@data %>%
                                                                     na.omit() %>%
                                                                     rename(zone = DN) %>%
                                                                     filter(Class != "N")
      })

      names(shapelist.data) <- trainingShapefiles


                                          # list .rds segment feature dataframe files
      segmentFeatureDF.rds.files <- list.files(image.dir, full.names = T) %>%
          str_extract(pattern = str_c(".*",segment.feature.df.appendage,".rds")) %>%
          na.omit()

      trainingData <- list()

      foreach(j = seq_along(shapelist.data)) %do% {
          d <- readRDS(segmentFeatureDF.rds.files[j])
          trainingData[[j]] <- left_join(shapelist.data[[j]],d, by = c("zone" = "segment"))
      }

      trainingData <- bind_rows(trainingData) %>%
          filter(Class != "N")

      saveRDS(trainingData, file = str_c(image.dir, "/",modelBuildingData.name))

  }

#+END_SRC
#+RESULTS:

*** Build and Save Models
#+BEGIN_SRC R
  Build.and.Save.models <- function(
                                    dir = dd.training.dir,
                                    modelBuildingData = ModelBuildingRDS,
                                    models.dir = Models.dir,
                                    image.name){

      dat <- readRDS(paste0(dir,"/",modelBuildingData)) %>%
          as.data.frame()

      image.and.segmentation.stem = str_replace(modelBuildingData, ModelBuilding.appendage,"")

      names <- colnames(dat)
      names <- str_replace(names, "\\(",".")
      names <- str_replace(names, "\\)",".")
      names <- str_replace(names, "\\:",".")
      colnames(dat) <- names

      dat_G <- dat %>%
          mutate(Class = as.character(Class),
                 Class = ifelse(Class == "g", Class, "o"))

      dat_I <- dat %>%
          mutate(Class = as.character(Class),
                 Class = ifelse(Class == "i", Class, "o"))

      dat_T <- dat %>%
          mutate(Class = as.character(Class),
                 Class = ifelse(Class == "t", Class, "o"))

                                          # Create Tasks
      all.task <- makeClassifTask(id = paste0(image.name,"_all"), data = dat, target = "Class")
      grass.task <- makeClassifTask(id = paste0(image.name,"_grass"), data = dat_G, target = "Class")
      impervious.task <- makeClassifTask(id = paste0(image.name,"_impervious"), data = dat_I, target = "Class")
      tree.task <- makeClassifTask(id = paste0(image.name,"_tree"), data = dat_T, target = "Class",positive = "t")

      task.list <- list(all = all.task, grass = grass.task, impervious = impervious.task, tree = tree.task)

                                          # Make Learners
      RF_prob <- makeLearner(id = "rf_prob","classif.randomForest", predict.type = "prob", fix.factors.prediction = TRUE)
      RF_response <- makeLearner(id = "rf_resp", "classif.randomForest", predict.type = "response", fix.factors.prediction = TRUE)
      SVM_response <- makeLearner(id = "svm_resp", "classif.svm", predict.type = "response", fix.factors.prediction = TRUE)

      learner.list <- list(RF_prob = RF_prob, RF_response = RF_response, SVM_response = SVM_response)

                                          # Train Learners on Tasks, Make models
                                          #         cl<-makeCluster(cores)
                                          #         registerDoParallel(cl)

      models <- foreach(tsk = task.list, .packages = "mlr") %do% {
          foreach(lnr = learner.list) %do% {
              mod <- train(lnr, tsk)
              mod
          }
      }
      saveRDS(models, file = paste0(models.dir,"/",image.and.segmentation.stem, models.appendage))
  }

#+END_SRC

#+RESULTS:

*** Classify Raster
#+BEGIN_SRC R

  classify.segmented.raster <- function(segment.feature.df.dir,
                                        segment.dir,
                                        model.dir,
                                        model.name.rds = "models",
                                        segment.feature.appendage = segment.feature.df.name.append,
                                        segmentation.appendage = segment.tile.name.append,
                                        segmentation.prms,
                                        classify.out.dir,
                                        tile.name = i) {
      df <- readRDS(paste0(segment.feature.df.dir,"/",tile.name,segment.feature.appendage))
      models <-readRDS(paste0(model.dir,"/",model.name.rds))
      umod <- unlist(models, recursive = F)
      seg.path <- paste0(segment.dir,"/",tile.name,segment.tile.name.append)
      seg <- raster(seg.path)
                                          #       dfRowsWithNA <- which(is.na(df[,2]))
      complete.df <- df[complete.cases(df),] # svm can't predict with NAs
      lapply(umod, function(mod) {
          pred <- predict(mod, newdata = complete.df)
          response <- factor(as.character(pred$data$response), levels = c("g","i","t","o"))
          m <- cbind(zone = complete.df$segment, response)
          m <- left_join(as.data.frame(df["segment"]), as.data.frame(m), by = c("segment" = "zone"))
          r <- reclassify(seg, m)
                                          #        x <- data.frame(ID = 1:4, LandCover = c("G","I","T","O")) %>%
                                          #            filter(LandCover %in% levels(factor(response)))
                                          #        levels(r) <- x
          if (ncol(pred$data) > 2) {
              prob <- (pred$data[,grep("prob.*", x = colnames(pred$data))]) # get columns that contain probabilities
              ProbOfClass <- apply(prob, MARGIN = 1, FUN = max)
              m <- cbind(segment = df$segment, ProbOfClass)
              m <- left_join(as.data.frame(df["segment"]), as.data.frame(m))
              p <- reclassify(seg, m)
              r <- stack(r,p)
          }
          path <- paste0(segment.dir,"/",ClassifiedTilesDirName,"/",tile.name,"_",segmentation.prms,"_",mod$task.desc$id,"_",mod$learner$id,".tif")
          writeRaster(r, path, overwrite=TRUE)
          print(path)
      })
  }


  classify.pixel.raster <- function(tile.dir = dd.accuracy.dir,
                                    tile.name,
                                    pixelFeatureDF.appendage = pixel.feature.df.appendage,
                                    model.dir = Models.dir,
                                    model.rds,
                                    seg.prms = "Pixel") {
      ras <- stack(str_c(tile.dir,"/",tile.name,".tif"))
      pix.mods <- readRDS(str_c(model.dir,"/",model.rds))
      pix.umods <- unlist(pix.mods, recursive = F)

      pix.feature.df <- readRDS(str_c(tile.dir,"/",tile.name,pixelFeatureDF.appendage,".rds"))

      if(!is.null(pix.feature.df$y)) {
          pix.feature.df <- dplyr::select(pix.feature.df, -x, -y)
      }

                                          # I set NA's to 0 here.  Not the best choice.  Not sure why they exist.
                                          # imputing to mean would probably be better

      pix.feature.df <- as.matrix(pix.feature.df)

      pix.feature.df[which(is.na(pix.feature.df))] <- 0

      pix.feature.df <- as.data.frame(pix.feature.df)


      lapply(pix.umods, function(pix.mod) {
          pred <- predict(pix.mod, newdata = pix.feature.df)
          a <- ras[[1]]
          values(a) <- pred$data$response
          path <- paste0(tile.dir,"/",ClassifiedTilesDirName,"/",tile.name,"_",seg.prms,"_",pix.mod$task.desc$id,"_",pix.mod$learner$id,".tif")
          writeRaster(a, path, overwrite = T)
          print(path)
      })
  }








#+END_SRC

#+RESULTS:

#+BEGIN_SRC R :results graphics :file figs/pixClss.png
                                          #plot(a)
#+END_SRC

#+RESULTS:
[[file:figs/pixClss.png]]

*** Calculate Percent Cover in Classified Tiles
#+BEGIN_SRC R

  get.prcnt.class <- function(points,r) {
      r <- crop(r,points)  # should I do a mask instead??
      g <- cellStats(r == 1, stat = sum)
      im <- cellStats(r == 2, stat = sum)
      tr <- cellStats(r == 3, stat = sum)
      o <-  cellStats(r == 4, stat = sum)
      totC <- ncell(r)
      return(c(pct_g_pred = g/totC, pct_i_pred = im/totC, pct_t_pred = tr/totC, pct_o_pred = o/totC))
  }


  get_area_convexHull <- function(points) {
      ch <- chull(coordinates(points))
      coords <- coordinates(points)[c(ch,ch[1]),]
      poly <- SpatialPolygons(list(Polygons(list(Polygon(coords)),ID = 1)))
      gArea(poly)
  }



  calculate.percent.cover.in.classified.tile <- function(pts,
                                                         tile.dir = dd.accuracy.classified.dir,
                                                         tile.pth,
                                                         n.rows.and.columns.subset,
                                                         mod = 1,
                                                         mad.grid.id.pattern = "mad-[0-9]+m-[0-9]+",
                                                         grid.pattern = "[a-zA-Z]{3}-[0-9]+m-[0-9]+_",
                                                         image.pattern = "[a-zA-Z]{5}[a-zA-Z]+",
                                                         target.pattern = "all|grass|impervious|tree",
                                                         model.pattern = "rf_prob|rf_resp|svm_resp",
                                                         seg.prms = "N-[0-9]+_C-[0-9]+|Pixel"
                                                         ) {
      tile.nm <- basename(tile.pth)


      pts.sub <- pts@data  %>%
          filter.by.row.and.col(.,n.rows.and.columns.subset, mod = mod)

      coordinates(pts.sub) <- ~ crds_x1 + crds_x2

      proj4string(pts.sub) <- utm16
      tile.unique.name <- str_extract(tile.pth, mad.grid.id.pattern)
      pts.at.grid <- pts.sub[which(pts.sub@data$unq__ID == tile.unique.name),]
      tile <- raster(tile.pth, proj4string = "+init:epsg=32616")

      area.pts <- get_area_convexHull(pts.at.grid)

      if(!is.null(raster::intersect(extent(tile),bbox(pts.at.grid)))) {

          get.prcnt.class(pts.at.grid,tile) %>%
              t() %>%
              as.data.frame() %>%
              mutate(grid.tile.target.model = tile.nm,
                     grid = str_sub(str_extract(grid.tile.target.model, grid.pattern),1,-2),
                     image =  str_extract(grid.tile.target.model, image.pattern),
                     target.cover = str_extract(grid.tile.target.model, target.pattern),
                     model =  str_extract(grid.tile.target.model, model.pattern),
                     n.points = n.rows.and.columns.subset * n.rows.and.columns.subset,
                     area = area.pts,
                     seg.params = str_extract(grid.tile.target.model, seg.prms),
                     target.type = ifelse(target.cover == "all", "multinomial", "binomial"))
      }
  }

#+END_SRC

#+RESULTS:

*** Calculate Percent Cover of Grids, subsetted
#+BEGIN_SRC R
  filter.by.row.and.col <- function(df,nrow.and.col, mod) {
      nrow <-df %>%
          group_by(unq__ID) %>%
          summarize(nrow = max(row))

      df <- left_join(df,nrow)

      df %>%
          filter(nrow >= nrow.and.col,   # remove grids that have fewer than the number of rows & columns
                 row <= nrow.and.col,    # remove rows greater than the number we are interested in
                 col <=nrow.and.col,   # same for columns as rows
                 row %% mod == 0,
                 col %% mod == 0)
  }

  add.n.pts.per.grid <- function(df){
      n.pts<-df %>%
          group_by(unq__ID) %>%
          summarize(n.points = n())

      left_join(df,n.pts)
  }


  get.pct.cvr.typ <- function(df) {
      df %>%
          group_by(unq__ID, cvr_typ,n.points, area) %>%
          summarize(number = n()) %>%
          ungroup() %>%
          mutate(google.truth.pct.cover = number/n.points) %>%
          dplyr::select(-number)
  }

  combine.classes.to.g.i.t.o <- function(df) {

      df %>%
          mutate(cvr_typ = as.character(cvr_typ),
                 cvr_typ = ifelse(cvr_typ == "s",
                                  "i",
                                  cvr_typ),
                 cvr_typ = ifelse(cvr_typ != "g" &
                                  cvr_typ != "i" &
                                  cvr_typ != "t", "o", cvr_typ)) %>%
          group_by(unq__ID, cvr_typ, n.points, area) %>%
          summarize(google.truth.pct.cover = sum(google.truth.pct.cover))

  }


  calc.binomial.pct.cvrs <- function(df) {

      out <- foreach(target.cvr.type = c("g","i","t")) %do%{
          df %>%
              mutate(cvr_typ = ifelse(cvr_typ == target.cvr.type, cvr_typ, "o")) %>%
              group_by(unq__ID, n.points, cvr_typ) %>%
              summarize(pct.cover = sum(pct.cover)) %>%
              mutate(target.type = "binomial",
                     target.cover = target.cvr.type,
                     target.cover = ifelse(target.cover == "g", "grass",
                                    ifelse(target.cover == "t", "tree",
                                           "impervious"))) %>%
              spread(key = cvr_typ, value = pct.cover)
      }
      out <- bind_rows(out)
      out %>%
          rename(pct.g.googleEarth = g, pct.i.googleEarth = i, pct.t.googleEarth = t, pct.o.googleEarth = o)
  }



  get.area.convexHull <- function(x_coord, y_coord) {
      m <- matrix(c(x_coord, y_coord), ncol = 2)
      ch <- chull(m)
      coords <- m[c(ch,ch[1]),]
      poly <- SpatialPolygons(list(Polygons(list(Polygon(coords)),ID = 1)))
      gArea(poly)
  }



  calc.pct.cvr.for.grid.subset <- function(df,
                                           n.rows.and.columns.for.subset=20,
                                           mod,
                                           gridID = "unq__ID") {


      df <- filter.by.row.and.col(df, n.rows.and.columns.for.subset, mod) %>%
          add.n.pts.per.grid() %>%
          group_by_(gridID)


      area.df <- df %>%
          summarize(area = get.area.convexHull(crds_x1, crds_x2))

      df <- left_join(df, area.df)


      df <- df %>%
          get.pct.cvr.typ() %>%
          combine.classes.to.g.i.t.o() %>%
                                          #               ungroup() %>%
                                          #               dplyr::select(-n.points) %>%
          spread(., key = cvr_typ, value = google.truth.pct.cover, fill = 0)

                                          #         df[is.na(df)] <- 0

      df.multnm <- df %>%
          mutate(target.type = "multinomial") %>%
          rename(pct.g.googleEarth = g, pct.i.googleEarth = i, pct.t.googleEarth = t) %>%
          mutate(target.cover = "all")

      if(!is.null(df.multnm$o)) { df.multnm <- rename(df.multnm, pct.o.googleEarth = o)}

      df <- df %>%
          gather(key = cvr_typ, value = pct.cover, -unq__ID, -n.points)

      df.binm <- df %>%
          calc.binomial.pct.cvrs()


      df.out <- bind_rows(df.binm, df.multnm)
      return(df.out)
  }



#+END_SRC

#+RESULTS:

*** Point-wise error functions
#+BEGIN_SRC R
  calcErrorAllMultinomial <-  function(pts, tile, Pixel = F) {
      classification <- raster::extract(classified.tile, pts)
      if(Pixel == T) {
          lvls <- levels(classified.tile)[[1]]
          classification <- mapvalues(classification, from = lvls[,1], to = as.character(lvls[,2]))
      } else {
          classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
      }
      google = pts@data$cvr_typ
      overall.error <- 1 - mean(classification == google)
      pct.grass.classified.as.other <- 1 - mean(classification[which(google == "g")] == google[which(google == "g")])
      pct.impervious.classified.as.other <- 1 - mean(classification[which(google == "i")] == google[which(google == "i")])
      pct.tree.classified.as.other <- 1 - mean(classification[which(google == "t")] == google[which(google == "t")])
      error <- c(overall.error = overall.error,
                 pct.grass.classified.as.other = pct.grass.classified.as.other,
                 pct.impervious.classified.as.other = pct.impervious.classified.as.other,
                 pct.tree.classified.as.other = pct.tree.classified.as.other)
      return(error)
  }

  calcErrorBinomial <-  function(pts, tile, target, Pixel = F) {
      classification <- raster::extract(classified.tile, pts)
      if(Pixel == T) {
          lvls <- levels(classified.tile)[[1]]
          classification <- mapvalues(classification, from = lvls[,1], to = as.character(lvls[,2]))
      } else {
          classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
      }
      classification <- ifelse(classification == target, classification, "o")
      google <- pts@data$cvr_typ
      google <- ifelse(google == target, google, "o")
      overall.error <- 1 - mean(classification == google)
      pct.grass.classified.as.other <- 1 - mean(classification[which(google == "g")] == google[which(google == "g")])
      pct.impervious.classified.as.other <- 1 - mean(classification[which(google == "i")] == google[which(google == "i")])
      pct.tree.classified.as.other <- 1 - mean(classification[which(google == "t")] == google[which(google == "t")])
      error <- c(overall.error = overall.error,
                 pct.grass.classified.as.other = pct.grass.classified.as.other,
                 pct.impervious.classified.as.other = pct.impervious.classified.as.other,
                 pct.tree.classified.as.other = pct.tree.classified.as.other)
      return(error)
  }




  calcConfusionMat <- function(pts, tile) {
      classification <- raster::extract(classified.tile, pts)
      classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
      table(classification, google = pts@data$cvr_typ)
  }


#+END_SRC
#+RESULTS:

*** Plot points on classifed tile
#+BEGIN_SRC R
      pts.on.classified.tile.plot <- function(pts, classified.tile, target = NULL) {
          if(target == "a") {
              pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
              pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, fill = cvr_typ), shape = 21, color = "black", size =2, stroke = .2)
          } else {
              pts@data <- pts@data %>%
                  mutate(cvr_typ = ifelse(cvr_typ == target, cvr_typ, "o"))
                  pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
          }
          r.df <- as.data.frame(classified.tile, xy = T)
          names(r.df) <- c("x","y","cvr_typ")
          r.df <- r.df %>%
              mutate(cvr_typ = mapvalues(cvr_typ, from = c(1,2,3,4), to = c("g","i","t","o")))
          pxls.plot <- ggplot() + geom_raster(data = r.df, aes(x = x, y = y, fill = cvr_typ))
          title <- ggtitle(label = names(classified.tile))
          UTC_pal <- c(g = "#ffff99", i = "#f0027f", t = "#7fc97f", o = "#666666")
          pxls.plot + pts.plot + title + scale_fill_manual(values = UTC_pal)+ scale_color_manual(values = UTC_pal) +
  coord_equal()
      }



#+END_SRC
#+RESULTS:


** Determine how to make best classifier for Madison : image, segmentation, model, n.classes, target, and def truth
*** Training
**** Make Training Tiles
  1) Input
     - Training Region Shapefile
     - Image.path
  2) Operation
     - Reproject Shapefiles to that of image
     - Crop image to each polygon in the shapefile
  3) Output
#+BEGIN_SRC R

  foreach(img.pth = image.paths) %do% {

  Reproject_Shapefile_to_Image_CRS(training.region.dsn,
                                         training.region.layer,
                                         img.pth,
                                         training.region.imageCRS.dsn)

  Crop_image_to_each_Shapefile_polygon(training.region.imageCRS.dsn,
                                       training.region.layer,
                                       img.pth,
                                       cores = cores,
                                       output.dir = dd.training.dir)
#+END_SRC

**** make pca transformation/rotation for slic segmentation algorithm.
***** read in pca model if it exists
#+BEGIN_SRC R :eval no
#pca <- foreach(i = seq_along(image.names)) %do% {
#   readRDS(str_c(dd.pca.dir,"/pca.rds"))
#}
 #+END_SRC
***** Reproject PCA Region Shapefile to Image
#+BEGIN_SRC R
         Reproject_Shapefile_to_Image_CRS(pca.region.dsn,
                                         pca.region.layer,
                                         img.pth,
                                         pca.region.imageCRS.dsn)
#+END_SRC

***** Crop image to create a smaller image around each of the polygons
#+BEGIN_SRC R :results none
       Crop_image_to_each_Shapefile_polygon(pca.region.imageCRS.dsn,
                                        pca.region.layer,
                                        img.pth,
                                        cores = cores,
                                        output.dir = dd.pca.dir)
     }
#+END_SRC

***** Add Ratios
#+BEGIN_SRC R
     cl <- makeCluster(cores)
     registerDoParallel(cl)

      tile.names <- list.files(dd.pca.dir) %>%
          str_extract(., pattern = ".*[0-9]+.tif") %>%
              str_extract(., pattern = ".*[0-9]+") %>%
                  na.omit()

     ratios <- foreach (j = tile.names,
              .packages = c("raster","stringr")) %dopar% {
                  add.ratios.ndvi(tile.dir = dd.pca.dir,
                                  tile.name = j)
              }

  stopCluster(cl)
 #+END_SRC

#+RESULTS:
:  Error in { : task 9 failed - "could not find function "rescale.0.255""

***** Create and Save PCA model/rotation
#+BEGIN_SRC R :results none
  pca <- foreach(img.nm = image.names) %do% {
              make.and.save.pca.transformation(tile.dir = dd.pca.dir,
                                               image.name = img.nm,
                                               band.names = band.names.wRatios
                                               )
  }
 #+END_SRC


**** For Each Training Tile
***** Make PixelFeatureDFs and SegmentationFeatureDFs for Training Regions
  1) Input
     - Testing Region Shapefiles
     - image
  2) Operation
     - Reproject Shapefiles to that of image
     - Crop image to each polygon in the shapefile
     - Derive PixelfeatureDFs and SegmentationFeatureDF from each tile of the image in region of each polygon
  3) Output
     - SegmentationFeatureDFs for every training polygon
     - PixelFeatureDFs for every pixel

****** Start R Loop, for every smaller image, do in parallel, :
#+BEGIN_SRC R

  cl <- makeCluster(cores)
  registerDoParallel(cl)

  pixel.added.features.raster.list <- foreach(img.nm = image.names) %do% {

      tile.names <- list.files(dd.training.dir) %>%
           str_extract(., pattern = str_c(img.nm,"-[0-9]+.tif")) %>%
           str_extract(., pattern = str_c(img.nm,"-[0-9]+")) %>%
           na.omit()

       foreach (i = tile.names,
                .packages = c("raster","stringr")) %dopar% {
   #+END_SRC

****** Add Ratios
#+BEGIN_SRC R
   add.ratios.ndvi(tile.dir = dd.training.dir,
                   tile.name = i)


 #+END_SRC

 #+RESULTS:
****** Save Pixel Feature Dataframe
 #+BEGIN_SRC R

          pixel.feature.df <- Create.Pixel.Feature.df(tile.dir = dd.training.dir,
						      tile.name = i)




#+END_SRC

#+RESULTS:

****** Perform PCA
#+BEGIN_SRC R :results none
	      image.pca(image.name = img.nm,
                        tile.dir = dd.training.dir,
                        tile.name = i,
                        pca.di = dd.pca.dir)
      }
}
   #+END_SRC
****** Segmentation

#+NAME: training.dir.NAIP
#+BEGIN_SRC R
message(dd.training.dir)
#+END_SRC

#+RESULTS: training.dir.NAIP
: ../DD/Madison_Training


#+BEGIN_SRC sh :var dir=training.dir.NAIP
   cd $dir
   # pixel size
   # desired area for superpixel/segments
   # compactness value
   # imagename
   python ../../code/fia_segment_cmdArgs.py 1 30 15 madisonNAIP &
   python ../../code/fia_segment_cmdArgs.py 1 60 30 madisonNAIP &
   python ../../code/fia_segment_cmdArgs.py 1 105 32 madisonNAIP &
   python ../../code/fia_segment_cmdArgs.py 1.5 30 10 panshpSPOT &
   python ../../code/fia_segment_cmdArgs.py 1.5 60 20 panshpSPOT &
   python ../../code/fia_segment_cmdArgs.py 1.5 105 21 panshpSPOT &

#+END_SRC

#+RESULTS:

#+END_SRC

#+RESULTS:

****** Create Segment Feature Dataframe
#+BEGIN_SRC R :results none
    ## # with LM
    ##   cl <- makeCluster(cores)
    ##   registerDoParallel(cl)

    ##   seg.feature.dfs <- foreach(img.nm = image.names) %do% {

    ##       tile.names <- list.files(dd.training.dir) %>%
    ##           str_extract(., pattern = str_c(img.nm,"-[0-9]+",segmentation.layer.pattern)) %>%
    ##               na.omit()

    ##       seg.params <- unique(str_extract(tile.names, segmentation.layer.pattern))

    ##       foreach(seg.param.set = seg.params) %do% {

    ##           tile.names.sub <- tile.names[which(complete.cases(str_extract(tile.names,seg.param.set)))]

    ##           out <- foreach (i = tile.names.sub,
    ##                           .packages = c("raster","stringr","dplyr","broom","tidyr")) %dopar% {
    ##                               seg.df <- Create.Segment.Feature.df(tile.dir = dd.training.dir,
    ##                                                         tile.name = i,)
    ##                               saveRDS(seg.df, file = paste0(dd.training.dir,"/", i,segmentFeatureDF.appendage))
    ##                           }
    ##           out
    ##       }
    ##   }

  # without LM
      cl <- makeCluster(cores)
      registerDoParallel(cl)

      seg.feature.dfs <- foreach(img.nm = image.names) %do% {

          tile.names <- list.files(dd.training.dir) %>%
              str_extract(., pattern = str_c(img.nm,"-[0-9]+",segmentation.layer.pattern)) %>%
                  na.omit()

          seg.params <- unique(str_extract(tile.names, segmentation.layer.pattern))

          foreach(seg.param.set = seg.params) %do% {

              tile.names.sub <- tile.names[which(complete.cases(str_extract(tile.names,seg.param.set)))]

              out <- foreach (i = tile.names.sub,
                              .packages = c("raster","stringr","dplyr","broom","tidyr")) %dopar% {
                                  seg.df <- Create.Segment.Feature.df.noLM(tile.dir = dd.training.dir,
                                                            tile.name = i,)
                                  saveRDS(seg.df, file = paste0(dd.training.dir,"/", i,segmentFeatureDF.appendage))
                              }
              out
          }
      }


    #+END_SRC


***** Combine Feature Dataframes
Pattern is image.name-Segmentation
#+BEGIN_SRC R :results none
  tile.dir <- dd.training.dir
  segmentation.layer.pattern
  segmentFeatureDF.appendage
  pixel.feature.df.appendage


  feature.dfs <- list.files(tile.dir, full.names = T) %>%
      str_extract(.,".*FeatureDF.rds") %>%
      na.omit()

  foreach(img.nm = image.names) %do% {
      img.feature.dfs <- str_extract(feature.dfs, str_c(".*",img.nm,".*")) %>%
          na.omit()
      SegParams <- unique(str_extract(img.feature.dfs, segmentation.layer.pattern)) %>%
          na.omit()
      SegParams <- c("_Pixel", SegParams)

      foreach(seg.param.set = SegParams) %do% {
          img.seg.feature.dfs = str_extract(img.feature.dfs, str_c(".*",seg.param.set,".*")) %>%
              na.omit()
          dfs <- lapply(img.seg.feature.dfs, readRDS)
          combined.dfs <- bind_rows(dfs)
          saveRDS(combined.dfs, file = str_c(tile.dir, "/", img.nm, seg.param.set, FeatureDF.appendage))
      }
  }
#+END_SRC

***** Create Model Building Dataframes, assign Class to feature dfs
  1) Input
     - Segmentation Layer from the Training Regions
     - Classified Training Polygons for each image (NAIP and panSPOT)
  2) Operation
     - For Pixels, extract coordinates of pixels that are inside training polygons
       - columns: x,y,class
       - join to pixel feature df
     - For Segments
       - Determine which segments fall majority within training polygons
       - Assign segments the class of the training polygon
       - columns: segment id, class
       - join to segment df

  3) Output
     - Model Building Dataframes, 1 for each image and segmentation combination
#+BEGIN_SRC R :results none

  ## i <- 1
  ## feature.df.rds <- featureDF.files[1]
  ## SegmentFeatureDF = feature.df
  ## training.sp = training.polygons
  ## seg.tiles.dir = image.cropped.to.training.dir
  ## feature.df.rds <- featureDF.files[6]
  ## seg.params <- segment.params[1]
  ## seg.file <- seg.files[6]
  ## PixelFeatureDF = feature.df
  ## training.sp = training.polygons

  getSegment.class.and.features.Within.Polygon<-function(SegmentFeatureDF,
                                                         training.sp,
                                                         seg.tiles.dir,
                                                         seg.params){
      seg.files <- list.files(seg.tiles.dir, pattern = str_c(seg.params,".tif$"), full.names = T)
                                          # find number of pixels in each segment
      n.pixels.per.seg <- foreach(seg.file = seg.files, .combine = "rbind") %do% {
          seg <- stack(seg.file)
          s.df <- as.data.frame(seg) %>%
              gather(key = tile.name, value = segment.id) %>%
              group_by(segment.id, tile.name) %>%
              summarize(n.pixels.per.seg = n())
      }
                                          # find number of pixels in each segment are in a polygon
      n.pixels.per.seg.in.polygon <- foreach(seg.file = seg.files, .combine = "rbind") %do% {

          seg <- stack(seg.file)
          ei <- as(extent(seg), "SpatialPolygons")

          if(gIntersects(ei, as(training.sp,"SpatialPolygons"))) {

              a <- raster::extract(seg, as(training.sp,"SpatialPolygons"), df = T)

              a <- a %>%
                  gather(key = tile.name, value = segment.id, -ID) %>%
                  rename(polygon.id = ID) %>%
                  group_by(polygon.id, tile.name, segment.id) %>%
                  summarize(n.pixels.per.seg.in.polygon = n())
          }
      }
                                          # get pct of segment in a polygon,
                                          # filter segments that have more than 50%,
                                          #join Class information from polygons
      if(!is.null(n.pixels.per.seg.in.polygon)) {

          n.pixels <- left_join(n.pixels.per.seg.in.polygon,n.pixels.per.seg) %>%
              mutate(pct.seg.in.polygon = n.pixels.per.seg.in.polygon/n.pixels.per.seg) %>%
              filter(pct.seg.in.polygon >= .5) %>%
              left_join(.,training.sp@data, by = c("polygon.id" = "id")) %>%
              ungroup() %>%
              mutate(tile.name = str_replace(tile.name, "\\.", "-"),
                     tile.name =  str_extract(tile.name, ".*-[0-9]+_"),
                     tile.name = str_sub(tile.name,1,-2)) %>%
              mutate(segment = segment.id)

          left_join(n.pixels, SegmentFeatureDF) %>%
              dplyr::select(-segment,
                            -segment.id,
                            -tile.name,
                            -polygon.id,
                            -n.pixels.per.seg,
                            -n.pixels.per.seg.in.polygon,
                            -pct.seg.in.polygon)        %>%
              filter(complete.cases(.))
      }
  }

  cl <- makeCluster(cores)
  registerDoParallel(cl)


  model.building.dfs <-  foreach(img.nm = image.names) %do% {

      featureDF.files <- list.files(dd.training.dir) %>%
          str_extract(., str_c(img.nm,".*", FeatureDF.appendage,"$")) %>%
          na.omit()

      training.polygon.layer <- list.files(training.region.dsn) %>%
          str_extract(.,str_c(".*",img.nm, ".*")) %>%
          na.omit() %>%
          extract.name.from.path() %>%
          unique()

      training.polygons <- readOGR(dsn = training.region.dsn, layer = training.polygon.layer)

      foreach(feature.df.rds = featureDF.files, .packages = c("mlr","foreach","doParallel", "stringr", "dplyr","sp")) %do% {

          feature.df <- readRDS(file = str_c(dd.training.dir,"/",feature.df.rds))

          if(complete.cases(str_extract(feature.df.rds, "Pixel"))) {
              model.building.df <- getPixel.Class.and.Coords.Within.Polygon(PixelFeatureDF = feature.df,
                                                                            training.sp = training.polygons)
              model.building.df <- model.building.df %>%
                  dplyr::select(-x, -y, -id)
              saveRDS(object = model.building.df, file = paste0(dd.training.dir,"/",img.nm,"_Pixel",ModelBuilding.appendage))
          }

          if(complete.cases(str_extract(feature.df.rds,   segmentation.layer.pattern))) {
              segment.params <- str_extract(feature.df.rds, segmentation.layer.pattern)
              model.building.df <- getSegment.class.and.features.Within.Polygon(SegmentFeatureDF = feature.df,
                  training.sp = training.polygons,
                  seg.tiles.dir = dd.training.dir,
                  seg.params = segment.params)
              saveRDS(model.building.df, file = str_c(dd.training.dir,"/",img.nm,segment.params,ModelBuilding.appendage))
          }
      }
  }

 #+END_SRC


**** Create and SaveModels
#+BEGIN_SRC R :results none
       cl <- makeCluster(cores)
       registerDoParallel(cl)

  foreach(img.nm = image.names,
              .packages = c("mlr","stringr","dplyr","foreach","doParallel")) %dopar% {

      ModelBuildingRDSs <- list.files(dd.training.dir) %>%
          str_extract(., str_c(img.nm,".*",ModelBuilding.appendage)) %>%
          na.omit()

      foreach(ModelBuildingRDS = ModelBuildingRDSs) %do% {
          Build.and.Save.models(dir = dd.training.dir,
                                modelBuildingData = ModelBuildingRDS,
                                models.dir = Models.dir,
                                image.name = img.nm)

      }
  }

  Build.and.Save.models <- function(
                dir = dd.training.dir,
                modelBuildingData = ModelBuildingRDS,
                models.dir = Models.dir,
                image.name){

  dat <- readRDS(paste0(dir,"/",modelBuildingData)) %>%
      as.data.frame()

        image.and.segmentation.stem = str_replace(modelBuildingData, ModelBuilding.appendage,"")

        names <- colnames(dat)
        names <- str_replace(names, "\\(",".")
        names <- str_replace(names, "\\)",".")
        names <- str_replace(names, "\\:",".")
        colnames(dat) <- names

              dat_G <- dat %>%
                  mutate(Class = as.character(Class),
                         Class = ifelse(Class == "g", Class, "o"))

              dat_I <- dat %>%
                  mutate(Class = as.character(Class),
                         Class = ifelse(Class == "i", Class, "o"))

              dat_T <- dat %>%
                  mutate(Class = as.character(Class),
                         Class = ifelse(Class == "t", Class, "o"))

            # Create Tasks
        all.task <- makeClassifTask(id = paste0(image.name,"_all"), data = dat, target = "Class")
        grass.task <- makeClassifTask(id = paste0(image.name,"_grass"), data = dat_G, target = "Class")
        impervious.task <- makeClassifTask(id = paste0(image.name,"_impervious"), data = dat_I, target = "Class")
        tree.task <- makeClassifTask(id = paste0(image.name,"_tree"), data = dat_T, target = "Class",positive = "t")

        task.list <- list(all = all.task, grass = grass.task, impervious = impervious.task, tree = tree.task)

                                                   # Make Learners
           RF_prob <- makeLearner(id = "rf_prob","classif.randomForest", predict.type = "prob", fix.factors.prediction = TRUE)
           RF_response <- makeLearner(id = "rf_resp", "classif.randomForest", predict.type = "response", fix.factors.prediction = TRUE)
           SVM_response <- makeLearner(id = "svm_resp", "classif.svm", predict.type = "response", fix.factors.prediction = TRUE)

           learner.list <- list(RF_prob = RF_prob, RF_response = RF_response, SVM_response = SVM_response)

                                                   # Train Learners on Tasks, Make models
  #         cl<-makeCluster(cores)
  #         registerDoParallel(cl)

  models <- foreach(tsk = task.list, .packages = "mlr") %do% {
      foreach(lnr = learner.list) %do% {
          mod <- train(lnr, tsk)
          mod
      }
  }
         saveRDS(models, file = paste0(models.dir,"/",image.and.segmentation.stem, models.appendage))
    }
 #+END_SRC

*** Testing/Accuracy
**** Make tiles at accuracy regions
#+BEGIN_SRC R :results none

    foreach(i = 1:2) %do% {

      foreach(img.pth = image.paths) %do% {

          Reproject_Shapefile_to_Image_CRS(accuracy.region.dsn[i],
                                           accuracy.region.layer[i],
                                           img.pth,
                                           accuracy.region.imageCRS.dsn)

          Crop_image_to_regions_around_points_nameBygrid(shapefile.dsn = accuracy.region.imageCRS.dsn,
                                                         shapefile.layer = accuracy.region.layer[i],
                                                         image.path = img.pth,
                                                         cores = cores,
                                                         output.dir = dd.accuracy.dir,
                                                         column.name = tile.id.col.nm.for.grid.and.field.accuracy[i])

      }
  }


#+END_SRC
**** Make PixelFeatureDFs and SegmentationFeatureDFs for Accuracy Regions
  1) Input
     - Testing Region Shapefiles
     - image
  2) Operation
     - Reproject Shapefiles to that of image
     - Crop image to each polygon in the shapefile
     - Derive PixelfeatureDFs and SegmentationFeatureDF from each tile of the image in region of each polygon
  3) Output
     - SegmentationFeatureDFs for every training polygon
     - PixelFeatureDFs for every pixel

****** Start R Loop, for every smaller image, do in parallel, :
#+BEGIN_SRC R
  cl <- makeCluster(cores)
  registerDoParallel(cl)

  pixel.added.features.raster.list <- foreach(img.nm = image.names) %do% {

      tile.names <- list.files(dd.accuracy.dir) %>%
           str_extract(., pattern = str_c(img.nm,".*-[0-9]+.tif$")) %>%
           str_extract(., pattern = str_c(img.nm,".*-[0-9]+")) %>%
           na.omit()

       foreach (i = tile.names,
                .packages = c("raster","stringr")) %dopar% {
   #+END_SRC

****** Add Ratios
#+BEGIN_SRC R
   add.ratios.ndvi(tile.dir = dd.accuracy.dir,
                   tile.name = i)


 #+END_SRC

 #+RESULTS:
****** Save Pixel Feature Dataframe
 #+BEGIN_SRC R

          pixel.feature.df <- Create.Pixel.Feature.df(tile.dir = dd.accuracy.dir,
						      tile.name = i)




#+END_SRC

#+RESULTS:

****** Perform PCA
#+BEGIN_SRC R :results none
	      image.pca(image.name = img.nm,
                        tile.dir = dd.accuracy.dir,
                        tile.name = i,
                        pca.dir = dd.pca.dir)
      }
}
   #+END_SRC
****** Segmentation

#+NAME: accuracy.dir
#+BEGIN_SRC R
message(dd.accuracy.dir)
#+END_SRC

#+RESULTS: accuracy.dir
: ../DD/Accuracy


#+BEGIN_SRC sh :var dir=accuracy.dir
   cd $dir
   # pixel size
   # desired area for superpixel/segments
   # compactness value
   # imagename
   python ../../code/fia_segment_cmdArgs.py 1 30 15 madisonNAIP &
   python ../../code/fia_segment_cmdArgs.py 1 60 30 madisonNAIP &
   python ../../code/fia_segment_cmdArgs.py 1 105 32 madisonNAIP &
   python ../../code/fia_segment_cmdArgs.py 1.5 30 10 panshpSPOT &
   python ../../code/fia_segment_cmdArgs.py 1.5 60 20 panshpSPOT &
   python ../../code/fia_segment_cmdArgs.py 1.5 105 21 panshpSPOT &

#+END_SRC

#+END_SRC

#+RESULTS:

****** Create Segment Feature Dataframe
 #+BEGIN_SRC R :results none
   cl <- makeCluster(cores)
   registerDoParallel(cl)

   seg.feature.dfs <- foreach(img.nm = image.names) %do% {

       tile.names <- list.files(dd.accuracy.dir) %>%
           str_extract(., pattern = str_c(img.nm,".*-[0-9]+",segmentation.layer.pattern,".tif$")) %>%
               na.omit()

       seg.params <- unique(str_extract(tile.names, segmentation.layer.pattern))

       foreach(seg.param.set = seg.params) %do% {

           tile.names.sub <- tile.names[which(complete.cases(str_extract(tile.names,seg.param.set)))]
           tile.names.sub <- str_replace(tile.names.sub, ".tif","")

           out <- foreach (i = tile.names.sub,
                           .packages = c("raster","stringr","dplyr","broom","tidyr")) %dopar% {
                               seg.df <- Create.Segment.Feature.df(tile.dir = dd.accuracy.dir,
                                                         tile.name = i)
                               saveRDS(seg.df, file = paste0(dd.accuracy.dir,"/", i, segmentFeatureDF.appendage))
                           }
           out
       }
   }

    #+END_SRC

**** Classify Tiles at accuracy regions

#+BEGIN_SRC R
   cl <- makeCluster(cores)
   registerDoParallel(cl)


   classified.grid.tiles <-
       foreach(img.nm = image.names) %do% {

           models <- list.files(Models.dir) %>%
               str_extract(., str_c(".*",img.nm,".*")) %>%
               na.omit()

           tile.names <- list.files(dd.accuracy.dir) %>%
               str_extract(., pattern = str_c(img.nm,".*[0-9]+.tif$")) %>%
               str_replace(., segmentation.layer.pattern, "") %>%
               str_replace(., ".tif", "") %>%
                       na.omit() %>%
                           unique()

           foreach(tile.nm = tile.names,
                   .packages = c("dplyr","raster","stringr","mlr","foreach","doParallel")) %dopar% {

               foreach(model = models) %do% {

                   segmentation.params <- str_extract(model, "N-[0-9]+_C-[0-9]+|Pixel")

                   if(grepl("N-[0-9]+_C-[0-9]+",segmentation.params)) {
                          segment.tile.name.append <- paste0("_",segmentation.params,".tif")
                          segment.feature.df.name.append <- paste0("_",segmentation.params,segmentFeatureDF.appendage)

                          classify.segmented.raster(segment.feature.df.dir = dd.accuracy.dir,
                                          model.dir = Models.dir,
                                          segment.dir = dd.accuracy.dir,
                                          classify.out.dir = dd.accuracy.dir,
                                          tile.name = tile.nm,
                                          segmentation.appendage = segment.tile.name.append,
                                          model.name.rds = model,
                                          segment.feature.appendage = segment.feature.df.name.append,
                                          segmentation.prms = segmentation.params)

                   } else {
                       classify.pixel.raster(tile.dir = dd.accuracy.dir,
                                             tile.name = tile.nm,
                                             pixelFeatureDF.appendage = pixel.feature.df.appendage,
                                             model.dir = Models.dir,
                                             model.rds = model,
                                             seg.prms = segmentation.params)
                   }
               }
           }
       }


  stopCluster(cl)
#+END_SRC







**** Point-wise accuracy.  regular confusion matrix thing.  I should do this for the grids and the field plot data
#+BEGIN_SRC R
      pts.on.classified.tile.plot <- function(pts, classified.tile, target = NULL) {
          if(target == "a") {
              pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
              pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, fill = cvr_typ), shape = 21, color = "black", size =2, stroke = .2)
          } else {
              pts@data <- pts@data %>%
                  mutate(cvr_typ = ifelse(cvr_typ == target, cvr_typ, "o"))
                  pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
          }
          r.df <- as.data.frame(classified.tile, xy = T)
          names(r.df) <- c("x","y","cvr_typ")
          r.df <- r.df %>%
              mutate(cvr_typ = mapvalues(cvr_typ, from = c(1,2,3,4), to = c("g","i","t","o")))
          pxls.plot <- ggplot() + geom_raster(data = r.df, aes(x = x, y = y, fill = cvr_typ))
          title <- ggtitle(label = names(classified.tile))
          UTC_pal <- c(g = "#ffff99", i = "#f0027f", t = "#7fc97f", o = "#666666")
          pxls.plot + pts.plot + title + scale_fill_manual(values = UTC_pal)+ scale_color_manual(values = UTC_pal) +
  coord_equal()
      }




      calcErrorAllMultinomial <-  function(pts, tile, Pixel = F) {
          classification <- raster::extract(classified.tile, pts)
          if(Pixel == T) {
              lvls <- levels(classified.tile)[[1]]
              classification <- mapvalues(classification, from = lvls[,1], to = as.character(lvls[,2]))
          } else {
              classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
          }
          google = pts@data$cvr_typ
          overall.error <- 1 - mean(classification == google)
          pct.grass.classified.as.other <- 1 - mean(classification[which(google == "g")] == google[which(google == "g")])
          pct.impervious.classified.as.other <- 1 - mean(classification[which(google == "i")] == google[which(google == "i")])
          pct.tree.classified.as.other <- 1 - mean(classification[which(google == "t")] == google[which(google == "t")])
          error <- c(overall.error = overall.error,
                     pct.grass.classified.as.other = pct.grass.classified.as.other,
                     pct.impervious.classified.as.other = pct.impervious.classified.as.other,
                     pct.tree.classified.as.other = pct.tree.classified.as.other)
          return(error)
      }

      calcErrorBinomial <-  function(pts, tile, target, Pixel = F) {
          classification <- raster::extract(classified.tile, pts)
          if(Pixel == T) {
              lvls <- levels(classified.tile)[[1]]
              classification <- mapvalues(classification, from = lvls[,1], to = as.character(lvls[,2]))
          } else {
              classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
          }
          classification <- ifelse(classification == target, classification, "o")
          google <- pts@data$cvr_typ
          google <- ifelse(google == target, google, "o")
          overall.error <- 1 - mean(classification == google)
          pct.grass.classified.as.other <- 1 - mean(classification[which(google == "g")] == google[which(google == "g")])
          pct.impervious.classified.as.other <- 1 - mean(classification[which(google == "i")] == google[which(google == "i")])
          pct.tree.classified.as.other <- 1 - mean(classification[which(google == "t")] == google[which(google == "t")])
          error <- c(overall.error = overall.error,
                     pct.grass.classified.as.other = pct.grass.classified.as.other,
                     pct.impervious.classified.as.other = pct.impervious.classified.as.other,
                     pct.tree.classified.as.other = pct.tree.classified.as.other)
          return(error)
      }




      calcConfusionMat <- function(pts, tile) {
          classification <- raster::extract(classified.tile, pts)
          classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
          table(classification, google = pts@data$cvr_typ)
      }


      grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer, stringsAsFactors = F)

      xy <- coordinates(grd)
      grd@data$x <- xy[,1]
      grd@data$y <- xy[,2]




      classified.tile.paths <- list.files(str_c(dd.accuracy.classified.dir), full.names = T) %>%
          str_extract(., pattern = ".*.tif$") %>%
          str_extract(., pattern = str_c(".*",grid.pattern, ".*")) %>%
          na.omit()

      grid.names <- list.files(str_c(dd.accuracy.classified.dir), full.names = T) %>%
          str_extract(., pattern = ".*.tif$") %>%
          str_extract(., pattern = grid.pattern) %>%
          str_sub(.,1,-2) %>%
          unique() %>%
          na.omit()


      grid.name = grid.names[3]

  grid.name = str_extract(grid.names, ".*150m-[56].*") %>% na.omit()

      mad.grid.id.pattern = "mad-[0-9]+m-[0-9]+"
      grid.pattern = "[a-zA-Z]{3}-[0-9]+m-[0-9]+_"
      image.pattern = "[a-zA-Z]{5}[a-zA-Z]+"
      target.pattern = "all|grass|impervious|tree"
      model.pattern = "rf_prob|rf_resp|svm_resp"
      seg.prms = "N-[0-9]+_C-[0-9]+|Pixel"


      cl <- makeCluster(cores)
      registerDoParallel(cl)


      error.df <- foreach(grid.name = grid.names, .combine = "rbind") %do% {

          pts <- grd[grd@data$unq__ID== grid.name,]

          classified.tile.paths.at.grid <- str_extract(classified.tile.paths, str_c(".*",grid.name,"_.*")) %>%
              na.omit()

          classified.tile.paths.at.grid2 = classified.tile.paths.at.grid %>%
               str_extract(., ".*madisonNAIP.*N-105.*svm_.*") %>%
               na.omit()

          ## classified.tile.path.at.grid = classified.tile.paths.at.grid[4]



          foreach(classified.tile.path.at.grid = classified.tile.paths.at.grid,
                  .combine = "rbind",
                  .packages = c("plyr","raster","dplyr", "stringr","ggplot2")) %dopar% {

                      classified.tile.name.at.grid <- basename(classified.tile.path.at.grid)
                      classified.tile <- raster(classified.tile.path.at.grid)

                      tgt <- str_extract(classified.tile.name.at.grid, "tree|grass|impervious|all")
                      tgt <- mapvalues(tgt, c("tree","grass","impervious","all"), c("t","g","i","a"))

                     ##  png(str_c("figs/","ClassifiedVersusGrid","/",names(classified.tile),".png"))
                     ## print(pts.on.classified.tile.plot(pts, classified.tile, target = tgt))
                     ## dev.off()

                      PixBool <- !is.na((str_extract(classified.tile.path.at.grid, "_Pixel_")))

                      if(!is.na(str_extract(classified.tile.path.at.grid, "_all_"))) {
                          error <- calcErrorAllMultinomial(pts, classified.tile, Pixel = PixBool)
                          error <- error %>%
                              t() %>%
                              data.frame() %>%
                              mutate(grid = grid.name,
                                     image =  str_extract(classified.tile.name.at.grid, image.pattern),
                                     target.cover = str_extract(classified.tile.name.at.grid, target.pattern),
                                     model =  str_extract(classified.tile.name.at.grid, model.pattern),
                                     seg.params = str_extract(classified.tile.name.at.grid, seg.prms))
                          error
                      } else {
                          target = str_extract(classified.tile.name.at.grid, "tree|grass|impervious")
                          target <- mapvalues(target, c("tree","grass","impervious"), c("t","g","i"))
                          error <- calcErrorBinomial(pts, classified.tile, target, Pixel = PixBool)
                          error <- error %>%
                              t() %>%
                              data.frame() %>%
                              mutate(grid = grid.name,
                                     image =  str_extract(classified.tile.name.at.grid, image.pattern),
                                     target.cover = str_extract(classified.tile.name.at.grid, target.pattern),
                                     model =  str_extract(classified.tile.name.at.grid, model.pattern),
                                     seg.params = str_extract(classified.tile.name.at.grid, seg.prms))

                          error
                      }
                  }
      }



      saveRDS(error.df, str_c(derived.dir, "point2pixel.error.df.rds"))
      readRDS(error.df, str_c(derived.dir, "point2pixel.error.df.rds"))


      error.df %>%
          arrange(overall.error) %>%
          head()

      error.df %>%
          arrange(desc(overall.error)) %>%
          head()

      error.df %>%
          filter(seg.params != "Pixel") %>%
          arrange(desc(overall.error)) %>%
          head()

    error.df <- error.df %>%
          mutate(segment.size = ifelse(!is.na(str_extract(seg.params, ".*105.*")), 105,
                                ifelse(!is.na(str_extract(seg.params, ".*60.*")), 60,
                                ifelse(!is.na(str_extract(seg.params, ".*30.*")), 30,
                                ifelse(!is.na(str_extract(seg.params, ".*70.*")), 105,
                                ifelse(!is.na(str_extract(seg.params, ".*40.*")), 60,
                                ifelse(!is.na(str_extract(seg.params, ".*20.*")), 30,1)))))))


#+END_SRC


*** Summarize Accuracy Assessment Results

** Test How Madison Model performs for Wausau
*** Classify Wausau Accuracy Regions
**** Make tiles at accuracy regions
#+BEGIN_SRC R :results none


  image.names <- "wausauNAIP"
  image.paths <- str_c("../RD_NAIP/",image.names,".tif")

      foreach(i = 1:2) %do% {

        foreach(img.pth = image.paths) %do% {

            Reproject_Shapefile_to_Image_CRS(accuracy.region.dsn[i],
                                             accuracy.region.layer[i],
                                             img.pth,
                                             accuracy.region.imageCRS.dsn)

            Crop_image_to_regions_around_points_nameBygrid(shapefile.dsn = accuracy.region.imageCRS.dsn,
                                                           shapefile.layer = accuracy.region.layer[i],
                                                           image.path = img.pth,
                                                           cores = cores,
                                                           output.dir = dd.accuracy.dir,
                                                           column.name = "unq__ID")

        }
    }


#+END_SRC
**** Make PixelFeatureDFs and SegmentationFeatureDFs for Accuracy Regions
  1) Input
     - Testing Region Shapefiles
     - image
  2) Operation
     - Reproject Shapefiles to that of image
     - Crop image to each polygon in the shapefile
     - Derive PixelfeatureDFs and SegmentationFeatureDF from each tile of the image in region of each polygon
  3) Output
     - SegmentationFeatureDFs for every training polygon
     - PixelFeatureDFs for every pixel

****** Start R Loop, for every smaller image, do in parallel, :
#+BEGIN_SRC R
  cl <- makeCluster(cores)
  registerDoParallel(cl)

  pixel.added.features.raster.list <- foreach(img.nm = image.names) %do% {

      tile.names <- list.files(dd.accuracy.dir) %>%
           str_extract(., pattern = str_c(img.nm,".*-[0-9]+.tif$")) %>%
           str_extract(., pattern = str_c(img.nm,".*-[0-9]+")) %>%
           na.omit()

       foreach (i = tile.names,
                .packages = c("raster","stringr")) %dopar% {
   #+END_SRC

****** Add Ratios
#+BEGIN_SRC R
  add.ratios.ndvi(tile.dir = dd.accuracy.dir,
                  tile.name = i)


 #+END_SRC

 #+RESULTS:
****** Save Pixel Feature Dataframe
 #+BEGIN_SRC R

   pixel.feature.df <- Create.Pixel.Feature.df(tile.dir = dd.accuracy.dir,
                                               tile.name = i)




#+END_SRC

#+RESULTS:

****** Perform PCA
#+BEGIN_SRC R :results none

# note, I copied madisonNAIP_pca to wausauNAIP_pca because we want to test if the madison pca will work for wausau

                image.pca(image.name = img.nm,
                          tile.dir = dd.accuracy.dir,
                          tile.name = i,
                          pca.dir = dd.pca.dir)
        }
  }
   #+END_SRC
****** Segmentation

#+NAME: accuracy.dir
#+BEGIN_SRC R
message(dd.accuracy.dir)
#+END_SRC

#+RESULTS: accuracy.dir
: ../DD/Accuracy


#+BEGIN_SRC sh :var dir=accuracy.dir
   cd $dir
   # pixel size
   # desired area for superpixel/segments
   # compactness value
   # imagename
   python ../../code/fia_segment_cmdArgs.py 1 60 30 wausauNAIP


#+END_SRC

#+END_SRC

#+RESULTS:
| average                           | number                           | of                               | pixels                           | per                              | segment                          | is                               |                             60.0 |                                  |                                   |
| compactness                       | parameter                        | is                               | 30                               |                                  |                                  |                                  |                                  |                                  |                                   |
| ['wausauNAIP_wau-100m-4_pca.tif', | 'wausauNAIP_wau-100m-6_pca.tif', | 'wausauNAIP_wau-100m-8_pca.tif', | 'wausauNAIP_wau-100m-9_pca.tif', | 'wausauNAIP_wau-100m-1_pca.tif', | 'wausauNAIP_wau-100m-2_pca.tif', | 'wausauNAIP_wau-100m-3_pca.tif', | 'wausauNAIP_wau-100m-7_pca.tif', | 'wausauNAIP_wau-100m-5_pca.tif', | 'wausauNAIP_wau-100m-10_pca.tif'] |

****** Create Segment Feature Dataframe
 #+BEGIN_SRC R :results none
   cl <- makeCluster(cores)
   registerDoParallel(cl)

   seg.feature.dfs <- foreach(img.nm = image.names) %do% {

       tile.names <- list.files(dd.accuracy.dir) %>%
           str_extract(., pattern = str_c(img.nm,".*-[0-9]+",segmentation.layer.pattern,".tif$")) %>%
               na.omit()

       seg.params <- unique(str_extract(tile.names, segmentation.layer.pattern))

       foreach(seg.param.set = seg.params) %do% {

           tile.names.sub <- tile.names[which(complete.cases(str_extract(tile.names,seg.param.set)))]
           tile.names.sub <- str_replace(tile.names.sub, ".tif","")

           out <- foreach (i = tile.names.sub,
                           .packages = c("raster","stringr","dplyr","broom","tidyr")) %dopar% {
                               seg.df <- Create.Segment.Feature.df(tile.dir = dd.accuracy.dir,
                                                         tile.name = i)
                               saveRDS(seg.df, file = paste0(dd.accuracy.dir,"/", i, segmentFeatureDF.appendage))
                           }
           out
       }
   }

    #+END_SRC

**** Classify Tiles at accuracy regions

#+BEGIN_SRC R
   cl <- makeCluster(cores)
   registerDoParallel(cl)


# I copied the madisonNAIP model .rds file to a wausauNAIP model.rds since we want to see the performance of
# Madison models in Wausau


   classified.grid.tiles <-
       foreach(img.nm = image.names) %do% {

           models <- list.files(Models.dir) %>%
               str_extract(., str_c(".*",img.nm,".*")) %>%
               na.omit()

           tile.names <- list.files(dd.accuracy.dir) %>%
               str_extract(., pattern = str_c(img.nm,".*[0-9]+.tif$")) %>%
               str_replace(., segmentation.layer.pattern, "") %>%
               str_replace(., ".tif", "") %>%
                       na.omit() %>%
                           unique()

           foreach(tile.nm = tile.names,
                   .packages = c("dplyr","raster","stringr","mlr","foreach","doParallel")) %dopar% {

               foreach(model = models) %do% {

                   segmentation.params <- str_extract(model, "N-[0-9]+_C-[0-9]+|Pixel")

                   if(grepl("N-[0-9]+_C-[0-9]+",segmentation.params)) {
                          segment.tile.name.append <- paste0("_",segmentation.params,".tif")
                          segment.feature.df.name.append <- paste0("_",segmentation.params,segmentFeatureDF.appendage)

                          classify.segmented.raster(segment.feature.df.dir = dd.accuracy.dir,
                                          model.dir = Models.dir,
                                          segment.dir = dd.accuracy.dir,
                                          classify.out.dir = dd.accuracy.dir,
                                          tile.name = tile.nm,
                                          segmentation.appendage = segment.tile.name.append,
                                          model.name.rds = model,
                                          segment.feature.appendage = segment.feature.df.name.append,
                                          segmentation.prms = segmentation.params)

                   } else {
                       classify.pixel.raster(tile.dir = dd.accuracy.dir,
                                             tile.name = tile.nm,
                                             pixelFeatureDF.appendage = pixel.feature.df.appendage,
                                             model.dir = Models.dir,
                                             model.rds = model,
                                             seg.prms = segmentation.params)
                   }
               }
           }
       }


  stopCluster(cl)
#+END_SRC

#+RESULTS:







*** Assess Accuracy of Wausau classified tiles
**** Point-wise accuracy.  regular confusion matrix thing.  I should do this for the grids and the field plot data
#+BEGIN_SRC R
        wau.grid.id.pattern = "wau-[0-9]+m-[0-9]+_"
        grid.pattern = "[a-zA-Z]{3}-[0-9]+m-[0-9]+_"
        image.pattern = "[a-zA-Z]{5}[a-zA-Z]+"
        target.pattern = "all|grass|impervious|tree"
        model.pattern = "rf_prob|rf_resp|svm_resp"
        seg.prms = "N-[0-9]+_C-[0-9]+|Pixel"


    grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer, stringsAsFactors = F)

        grd <- spTransform(grd, utm16)

        xy <- coordinates(grd)
        grd@data$x <- xy[,1]
        grd@data$y <- xy[,2]


        classified.tile.paths <- list.files(str_c(dd.accuracy.classified.dir), full.names = T) %>%
            str_extract(., pattern = ".*.tif$") %>%
            str_extract(., pattern = str_c(".*",grid.pattern, ".*")) %>%
            na.omit()

        grid.names <- list.files(str_c(dd.accuracy.classified.dir), full.names = T) %>%
            str_extract(., pattern = ".*.tif$") %>%
            str_extract(., pattern = wau.grid.id.pattern) %>%
            str_sub(.,1,-2) %>%
            unique() %>%
            na.omit()

    grid.name = grid.names[7]

    cl <- makeCluster(cores)
        registerDoParallel(cl)


        error.df <- foreach(grid.name = grid.names, .combine = "rbind") %do% {

            pts <- grd[grd@data$unq__ID== grid.name,]

            classified.tile.paths.at.grid <- str_extract(classified.tile.paths, str_c(".*",grid.name,"_.*")) %>%
                na.omit()

             classified.tile.paths.at.grid = classified.tile.paths.at.grid %>%
                  str_extract(., ".*wausauNAIP.*") %>%
                  na.omit()

             classified.tile.path.at.grid = classified.tile.paths.at.grid[11]


            foreach(classified.tile.path.at.grid = classified.tile.paths.at.grid,
                    .combine = "rbind",
                    .packages = c("plyr","raster","dplyr", "stringr","ggplot2")) %dopar% {

                        classified.tile.name.at.grid <- basename(classified.tile.path.at.grid)
                        classified.tile <- raster(classified.tile.path.at.grid)

                        tgt <- str_extract(classified.tile.name.at.grid, "tree|grass|impervious|all")
                        tgt <- mapvalues(tgt, c("tree","grass","impervious","all"), c("t","g","i","a"))

                        ## png(str_c(dd.accuracy.dir,"/ClassifiedTiles/ClassifiedVersusGrid","/",names(classified.tile),".png"))
                        ## print(pts.on.classified.tile.plot(pts, classified.tile, target = tgt))
                        ##dev.off()

                        PixBool <- !is.na((str_extract(classified.tile.path.at.grid, "_Pixel_")))

                        if(!is.na(str_extract(classified.tile.path.at.grid, "_all_"))) {
                            error <- calcErrorAllMultinomial(pts, classified.tile, Pixel = PixBool)
                            error <- error %>%
                                t() %>%
                                data.frame() %>%
                                mutate(grid = grid.name,
                                       image =  str_extract(classified.tile.name.at.grid, image.pattern),
                                       target.cover = str_extract(classified.tile.name.at.grid, target.pattern),
                                       model =  str_extract(classified.tile.name.at.grid, model.pattern),
                                       seg.params = str_extract(classified.tile.name.at.grid, seg.prms))
                            error
                        } else {
                            target = str_extract(classified.tile.name.at.grid, "tree|grass|impervious")
                            target <- mapvalues(target, c("tree","grass","impervious"), c("t","g","i"))
                            error <- calcErrorBinomial(pts, classified.tile, target, Pixel = PixBool)
                            error <- error %>%
                                t() %>%
                                data.frame() %>%
                                mutate(grid = grid.name,
                                       image =  str_extract(classified.tile.name.at.grid, image.pattern),
                                       target.cover = str_extract(classified.tile.name.at.grid, target.pattern),
                                       model =  str_extract(classified.tile.name.at.grid, model.pattern),
                                       seg.params = str_extract(classified.tile.name.at.grid, seg.prms))

                            error
                        }
                    }
        }



        saveRDS(error.df, str_c(derived.dir, /"point2pixel.error.df.Wausau.rds"))
  error.df <-readRDS(str_c(derived.dir, "/point2pixel.error.df.Wausau.rds"))

  error.df %>%
            arrange(overall.error) %>%
            head()

        error.df %>%
            arrange(desc(overall.error)) %>%
            head()

  error.df %>%
      filter(model == "rf_prob", target.cover == "tree") %>%
            arrange(desc(overall.error)) %>%
            head()



      error.df <- error.df %>%
            mutate(segment.size = ifelse(!is.na(str_extract(seg.params, ".*105.*")), 105,
                                  ifelse(!is.na(str_extract(seg.params, ".*60.*")), 60,
                                  ifelse(!is.na(str_extract(seg.params, ".*30.*")), 30,
                                  ifelse(!is.na(str_extract(seg.params, ".*70.*")), 105,
                                  ifelse(!is.na(str_extract(seg.params, ".*40.*")), 60,
                                  ifelse(!is.na(str_extract(seg.params, ".*20.*")), 30,1)))))))


#+END_SRC


#+BEGIN_SRC R :results graphics :file figs/grid.errors2.wausaufix.png :height 800 :width 600
  ggplot(error.df, aes(y = overall.error, x = grid, color = target.cover)) + geom_point() +
      facet_grid(image~seg.params)
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors2.wausaufix.png]]
#+BEGIN_SRC R :results graphics :file figs/grid.errors4.wausau.png :height 800 :width 600
  ggplot(error.df, aes(y = overall.error, x = grid, color = target.cover)) + geom_point() +
      facet_grid(image~segment.size)
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors4.wausau.png]]


#+BEGIN_SRC R :results graphics :file figs/grid.errors5.wausau.png :height 800 :width 600
  ggplot(error.df, aes(y = overall.error, x = segment.size)) +
      geom_point(data = error.df, aes(color = target.cover), position = position_dodge(width = 20)) +
      facet_grid(model~image)
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors5.wausau.png]]

#+BEGIN_SRC R :results graphics :file figs/grid.errors6.wausau.png :height 800 :width 800
  error.df.ssfac <- mutate(error.df, segment.size = factor(segment.size)) %>%
  filter(target.cover == "all")

      ggplot(error.df.ssfac, aes(y = overall.error, x = model)) +
          geom_boxplot(data = error.df.ssfac, aes(group = model)) +
          facet_grid(target.cover~image) +
	  geom_line(data = error.df.ssfac, aes(color = grid, group = grid), size = 1) +
	  theme_bw()
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors6.wausau.png]]

#+BEGIN_SRC R :results graphics :file figs/grid.errors6.wausau.tree.png :height 800 :width 800
  error.df.ssfac <- mutate(error.df, segment.size = factor(segment.size)) %>%
  filter(target.cover == "tree")

      ggplot(error.df.ssfac, aes(y = overall.error, x = model)) +
          geom_boxplot(data = error.df.ssfac, aes(group = model)) +
          facet_grid(target.cover~image) +
	  geom_line(data = error.df.ssfac, aes(color = grid, group = grid), size = 1) +
	  theme_bw()
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors6.wausau.tree.png]]







#+BEGIN_SRC R :results graphics :file figs/grid.errors.tree.wausau.png :height 800 :width 800
  error.df.ssfac.tree <- filter(error.df.ssfac, target.cover == "all" | target.cover == "tree")

      ggplot(error.df.ssfac.tree, aes(y = pct.tree.classified.as.other)) +
          geom_boxplot(data = error.df.ssfac.tree, aes(color = target.cover, group = interaction(target.cover,segment.size))) +
          facet_grid(image~model)
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors.tree.wausau.png]]


#+BEGIN_SRC R :results graphics :file figs/grid.errors.grass.png :height 800 :width 800
  error.df.ssfac.grass <- filter(error.df.ssfac, target.cover == "all" | target.cover == "grass")

      ggplot(error.df.ssfac.grass, aes(y = pct.grass.classified.as.other, x = segment.size)) +
          geom_boxplot(data = error.df.ssfac.grass, aes(color = target.cover, group = interaction(target.cover,segment.size))) +
          facet_grid(model~image)
#+END_SRC

#+RESULTS:
[[file:figs/grid.errors.grass.png]]

#+BEGIN_SRC R :results raw
  error.mod <- lm(overall.error ~ image * (target.cover + model + segment.size), data = error.df)
  tidy(error.mod) %>% ascii()
#+END_SRC

#+RESULTS:
|    | term                                   | estimate | std.error | statistic | p.value |
|----+----------------------------------------+----------+-----------+-----------+---------|
|  1 | (Intercept)                            |     0.26 |      0.01 |     27.44 |    0.00 |
|  2 | imagepanshpSPOT                        |     0.17 |      0.02 |     11.35 |    0.00 |
|  3 | target.covergrass                      |    -0.08 |      0.01 |     -8.45 |    0.00 |
|  4 | target.coverimpervious                 |    -0.14 |      0.01 |    -14.17 |    0.00 |
|  5 | target.covertree                       |    -0.06 |      0.01 |     -6.31 |    0.00 |
|  6 | modelrf_resp                           |     0.00 |      0.01 |      0.02 |    0.99 |
|  7 | modelsvm_resp                          |    -0.01 |      0.01 |     -1.46 |    0.14 |
|  8 | segment.size                           |    -0.00 |      0.00 |     -1.62 |    0.11 |
|  9 | imagepanshpSPOT:target.covergrass      |    -0.10 |      0.02 |     -5.90 |    0.00 |
| 10 | imagepanshpSPOT:target.coverimpervious |     0.10 |      0.02 |      6.29 |    0.00 |
| 11 | imagepanshpSPOT:target.covertree       |    -0.13 |      0.02 |     -8.34 |    0.00 |
| 12 | imagepanshpSPOT:modelrf_resp           |     0.00 |      0.01 |      0.03 |    0.97 |
| 13 | imagepanshpSPOT:modelsvm_resp          |     0.13 |      0.01 |      9.42 |    0.00 |
| 14 | imagepanshpSPOT:segment.size           |    -0.00 |      0.00 |     -5.62 |    0.00 |

                                    term      estimate    std.error
1                             (Intercept)  0.2594736239 9.457737e-03
2                         imagepanshpSPOT  0.1727955729 1.522839e-02
3                       target.covergrass -0.0818909914 9.689578e-03
4                  target.coverimpervious -0.1373055644 9.689578e-03
5                        target.covertree -0.0611569996 9.689578e-03
6                            modelrf_resp  0.0001428180 8.391421e-03
7                           modelsvm_resp -0.0122835115 8.391421e-03
8                            segment.size -0.0001441090 8.903396e-05
9       imagepanshpSPOT:target.covergrass -0.0950710892 1.612641e-02
10 imagepanshpSPOT:target.coverimpervious  0.1013795711 1.612641e-02
11       imagepanshpSPOT:target.covertree -0.1345326137 1.612641e-02
12           imagepanshpSPOT:modelrf_resp  0.0004778158 1.396589e-02
13          imagepanshpSPOT:modelsvm_resp  0.1315548935 1.396589e-02
14           imagepanshpSPOT:segment.size -0.0008378628 1.489573e-04
      statistic       p.value
1   27.43506508 3.802666e-151
2   11.34693391  2.306554e-29
3   -8.45145037  4.066308e-17
4  -14.17043735  1.931840e-44
5   -6.31162645  3.083836e-10
6    0.01701953  9.864219e-01
7   -1.46381779  1.433277e-01
8   -1.61858472  1.056209e-01
9   -5.89536419  4.069309e-09
10   6.28655355  3.619056e-10
11  -8.34237580  1.011573e-16
12   0.03421307  9.727091e-01
13   9.41973196  7.679367e-21
14  -5.62485092  1.992621e-08

#+BEGIN_SRC R :results raw
options(asciiType = "org")
options(warn = -1)
  error.df %>%
      group_by(image, target.cover, model, seg.params) %>%
      summarize(overall.error = mean(overall.error)) %>%
      ungroup() %>%
      arrange(overall.error) %>%
      head(n=40) %>%
      ascii()
#+END_SRC

#+RESULTS:
 |    | image       | target.cover | model    | seg.params | overall.error |
 |----+-------------+--------------+----------+------------+---------------|
 |  1 | madisonNAIP | impervious   | rf_prob  | Pixel      |          0.10 |
 |  2 | madisonNAIP | impervious   | rf_resp  | Pixel      |          0.10 |
 |  3 | madisonNAIP | impervious   | svm_resp | Pixel      |          0.11 |
 |  4 | madisonNAIP | impervious   | rf_resp  | N-30_C-15  |          0.11 |
 |  5 | madisonNAIP | impervious   | rf_prob  | N-30_C-15  |          0.11 |
 |  6 | madisonNAIP | impervious   | rf_resp  | N-60_C-30  |          0.11 |
 |  7 | madisonNAIP | impervious   | rf_prob  | N-60_C-30  |          0.11 |
 |  8 | madisonNAIP | impervious   | rf_prob  | N-105_C-32 |          0.11 |
 |  9 | madisonNAIP | impervious   | rf_resp  | N-105_C-32 |          0.11 |
 | 10 | madisonNAIP | impervious   | svm_resp | N-60_C-30  |          0.12 |
 | 11 | madisonNAIP | impervious   | svm_resp | N-30_C-15  |          0.12 |
 | 12 | madisonNAIP | impervious   | svm_resp | N-105_C-32 |          0.13 |
 | 13 | madisonNAIP | grass        | svm_resp | N-60_C-30  |          0.14 |
 | 14 | madisonNAIP | grass        | svm_resp | N-30_C-15  |          0.14 |
 | 15 | madisonNAIP | grass        | svm_resp | N-105_C-32 |          0.14 |
 | 16 | madisonNAIP | tree         | svm_resp | N-60_C-30  |          0.16 |
 | 17 | madisonNAIP | grass        | rf_resp  | N-60_C-30  |          0.16 |
 | 18 | madisonNAIP | grass        | rf_prob  | N-105_C-32 |          0.16 |
 | 19 | madisonNAIP | grass        | rf_resp  | N-105_C-32 |          0.16 |
 | 20 | madisonNAIP | grass        | rf_prob  | N-60_C-30  |          0.16 |
 | 21 | madisonNAIP | grass        | rf_resp  | N-30_C-15  |          0.17 |
 | 22 | madisonNAIP | tree         | svm_resp | N-30_C-15  |          0.17 |
 | 23 | madisonNAIP | grass        | rf_prob  | N-30_C-15  |          0.17 |
 | 24 | madisonNAIP | tree         | svm_resp | N-105_C-32 |          0.17 |
 | 25 | madisonNAIP | grass        | svm_resp | Pixel      |          0.18 |
 | 26 | madisonNAIP | tree         | svm_resp | Pixel      |          0.18 |
 | 27 | madisonNAIP | tree         | rf_prob  | N-105_C-32 |          0.19 |
 | 28 | madisonNAIP | tree         | rf_resp  | N-105_C-32 |          0.19 |
 | 29 | madisonNAIP | tree         | rf_prob  | N-30_C-15  |          0.19 |
 | 30 | madisonNAIP | tree         | rf_resp  | N-60_C-30  |          0.19 |
 | 31 | madisonNAIP | tree         | rf_resp  | N-30_C-15  |          0.19 |
 | 32 | madisonNAIP | tree         | rf_prob  | N-60_C-30  |          0.19 |
 | 33 | madisonNAIP | grass        | rf_prob  | Pixel      |          0.21 |
 | 34 | madisonNAIP | grass        | rf_resp  | Pixel      |          0.21 |
 | 35 | madisonNAIP | tree         | rf_prob  | Pixel      |          0.22 |
 | 36 | madisonNAIP | tree         | rf_resp  | Pixel      |          0.22 |
 | 37 | panshpSPOT  | tree         | rf_resp  | Pixel      |          0.22 |
 | 38 | panshpSPOT  | tree         | rf_prob  | Pixel      |          0.23 |
 | 39 | madisonNAIP | all          | svm_resp | N-60_C-30  |          0.23 |
 | 40 | madisonNAIP | all          | rf_resp  | N-60_C-30  |          0.24 |



#+BEGIN_SRC R :results raw
  options(asciiType = "org")
  options(warn = -1)
    error.df %>%
        filter(target.cover == "all") %>%
        group_by(image, target.cover, model, seg.params) %>%
        summarize(overall.error = mean(overall.error)) %>%
        ungroup() %>%
        arrange(overall.error) %>%
        head(n=40) %>%
        ascii()
#+END_SRC

#+RESULTS:
 |    | image       | target.cover | model    | seg.params | overall.error |
 |----+-------------+--------------+----------+------------+---------------|
 |  1 | madisonNAIP | all          | svm_resp | N-60_C-30  |          0.23 |
 |  2 | madisonNAIP | all          | rf_resp  | N-60_C-30  |          0.24 |
 |  3 | madisonNAIP | all          | rf_prob  | N-60_C-30  |          0.24 |
 |  4 | madisonNAIP | all          | rf_resp  | N-105_C-32 |          0.24 |
 |  5 | madisonNAIP | all          | rf_prob  | N-105_C-32 |          0.24 |
 |  6 | madisonNAIP | all          | svm_resp | N-30_C-15  |          0.24 |
 |  7 | madisonNAIP | all          | rf_prob  | N-30_C-15  |          0.24 |
 |  8 | madisonNAIP | all          | rf_resp  | N-30_C-15  |          0.25 |
 |  9 | madisonNAIP | all          | svm_resp | Pixel      |          0.25 |
 | 10 | madisonNAIP | all          | svm_resp | N-105_C-32 |          0.25 |
 | 11 | madisonNAIP | all          | rf_resp  | Pixel      |          0.28 |
 | 12 | madisonNAIP | all          | rf_prob  | Pixel      |          0.28 |
 | 13 | panshpSPOT  | all          | rf_resp  | Pixel      |          0.42 |
 | 14 | panshpSPOT  | all          | rf_prob  | Pixel      |          0.43 |
 | 15 | panshpSPOT  | all          | svm_resp | Pixel      |          0.57 |
 | 16 | panshpSPOT  | all          | rf_prob  | N-20_C-10  |               |
 | 17 | panshpSPOT  | all          | rf_prob  | N-40_C-20  |               |
 | 18 | panshpSPOT  | all          | rf_prob  | N-70_C-21  |               |
 | 19 | panshpSPOT  | all          | rf_resp  | N-20_C-10  |               |
 | 20 | panshpSPOT  | all          | rf_resp  | N-40_C-20  |               |
 | 21 | panshpSPOT  | all          | rf_resp  | N-70_C-21  |               |
 | 22 | panshpSPOT  | all          | svm_resp | N-20_C-10  |               |
 | 23 | panshpSPOT  | all          | svm_resp | N-40_C-20  |               |
 | 24 | panshpSPOT  | all          | svm_resp | N-70_C-21  |               |



#+BEGIN_SRC R :results raw
  options(asciiType = "org")
  options(warn = -1)
    error.df %>%
        filter(target.cover == "all") %>%
        group_by(image, target.cover, model, seg.params) %>%
        summarize(pct.tree.classified.as.other = mean(pct.tree.classified.as.other)) %>%
        ungroup() %>%
        arrange(pct.tree.classified.as.other) %>%
        head(n=40) %>%
        ascii()

#+END_SRC

#+RESULTS:
 |    | image       | target.cover | model    | seg.params | pct.tree.classified.as.other |
 |----+-------------+--------------+----------+------------+------------------------------|
 |  1 | panshpSPOT  | all          | rf_prob  | N-20_C-10  |                              |
 |  2 | panshpSPOT  | all          | rf_prob  | N-40_C-20  |                              |
 |  3 | panshpSPOT  | all          | rf_prob  | N-70_C-21  |                              |
 |  4 | panshpSPOT  | all          | rf_resp  | N-20_C-10  |                              |
 |  5 | panshpSPOT  | all          | rf_resp  | N-40_C-20  |                              |
 |  6 | panshpSPOT  | all          | rf_resp  | N-70_C-21  |                              |
 |  7 | panshpSPOT  | all          | svm_resp | N-20_C-10  |                              |
 |  8 | panshpSPOT  | all          | svm_resp | N-40_C-20  |                              |
 |  9 | panshpSPOT  | all          | svm_resp | N-70_C-21  |                              |
 | 10 | madisonNAIP | all          | rf_prob  | N-105_C-32 |                              |
 | 11 | madisonNAIP | all          | rf_prob  | N-30_C-15  |                              |
 | 12 | madisonNAIP | all          | rf_prob  | N-60_C-30  |                              |
 | 13 | madisonNAIP | all          | rf_prob  | Pixel      |                              |
 | 14 | madisonNAIP | all          | rf_resp  | N-105_C-32 |                              |
 | 15 | madisonNAIP | all          | rf_resp  | N-30_C-15  |                              |
 | 16 | madisonNAIP | all          | rf_resp  | N-60_C-30  |                              |
 | 17 | madisonNAIP | all          | rf_resp  | Pixel      |                              |
 | 18 | madisonNAIP | all          | svm_resp | N-105_C-32 |                              |
 | 19 | madisonNAIP | all          | svm_resp | N-30_C-15  |                              |
 | 20 | madisonNAIP | all          | svm_resp | N-60_C-30  |                              |
 | 21 | madisonNAIP | all          | svm_resp | Pixel      |                              |
 | 22 | panshpSPOT  | all          | rf_prob  | Pixel      |                              |
 | 23 | panshpSPOT  | all          | rf_resp  | Pixel      |                              |
 | 24 | panshpSPOT  | all          | svm_resp | Pixel      |                              |


**** RMSE at grid level
***** Combine google earth grid estimates of cover with classified tile estimates of cover

 Create dataframe with structure:

 | %t.img | %g.img | %i.img | %o.img | image      | segmentation | target.cover        | target.type         | model                   | tile                   | cropped.to.n.pts | %t.goog | %g.goog | %i.goog | %o.goog |   |   |   |   |   |   |   |   |
 |--------+--------+--------+--------+------------+--------------+---------------------+---------------------+-------------------------+------------------------+------------------+---------+---------+---------+---------+---+---+---+---+---+---+---+---|
 |    0-1 |    0-1 |    0-1 |    0-1 | NAIP       | Pixel        | grass               | binomial (two)      | random forest prob      | mad-size-id (up to 50) |                4 |     0-1 |     0-1 |     0-1 |     0-1 |   |   |   |   |   |   |   |   |
 |        |        |        |        | panshpSPOT | 30 m2        | tree                | multinomial (three) | random forest resp      |                        |                9 |         |         |         |         |   |   |   |   |   |   |   |   |
 |        |        |        |        |            | 60 m2        | impervious          |                     | support vector machines |                        |               16 |         |         |         |         |   |   |   |   |   |   |   |   |
 |        |        |        |        |            |              | NA (if multinomial) |                     |                         |                        |               25 |         |         |         |         |   |   |   |   |   |   |   |   |
 |        |        |        |        |            | 105 m2       |                     |                     |                         |                        |              ... |         |         |         |         |   |   |   |   |   |   |   |   |



****** Create DF of % cover from grids cropped to different extents
 #+BEGIN_SRC R
        grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer)
        grd.df <- grd@data

   n.rows.and.columns.for.subset = c(15)

        out <- foreach(n.rows.and.columns.for.sub = n.rows.and.columns.for.subset) %do% {
            calc.pct.cvr.for.grid.subset(grd.df, n.rows.and.columns.for.sub)
        }

        Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets <- bind_rows(out)

   Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets <- Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets %>%
       rename(grid = unq__ID)

     saveRDS(Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets, str_c(derived.dir,"/","Wausau.Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets.dataframe",".rds"))
 #+END_SRC

 #+RESULTS:
 : OGR data source with driver: ESRI Shapefile
 : Source: "../RD_Accuracy/Grids", layer: "All_Grids_Accuracy_Assessment_pts"
 : with 18365 features
 : It has 10 fields
 :  Joining by: "unq__ID"
 : Joining by: "unq__ID"

****** Create DF of % cover from classified rasters cropped to different extents

#+BEGIN_SRC R

    grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer)


    # get path of grid tiles (not interested in fieldplot classified tiles)
        classified.tile.paths <- list.files(str_c(dd.accuracy.classified.dir), full.names = T) %>%
            str_extract(., pattern = ".*.tif$") %>%
            str_extract(., pattern = str_c(".*",wau.grid.id.pattern, ".*")) %>%
              na.omit()


  n.rows.and.columns.for.subset = c(15)


  cl <- makeCluster(cores)
  registerDoParallel(cl)


      out <- foreach(n.rows.and.columns.for.sub = n.rows.and.columns.for.subset) %do% {
             pct.class.cover <- foreach(tile.path = classified.tile.paths, .packages = c("raster","dplyr","stringr")) %dopar% {
               calculate.percent.cover.in.classified.tile(pts = grd,
                                                           tile.pth = tile.path,
                                                           n.rows.and.columns.subset = n.rows.and.columns.for.sub)

            }
                saveRDS(pct.class.cover, str_c(derived.dir,"/","Wausau.Percent.Cover.Classified.Tiles.nPoints",n.rows.and.columns.for.sub, ".rds"))
      }


  class.cover.files <- list.files(derived.dir, pattern = "Wausau.Percent.Cover.Classified.Tiles.nPoints*", full.names = T)

  class.cover.dfs <- lapply(class.cover.files, readRDS)

  out <- unlist(class.cover.dfs,recursive = F)

       Percent.Cover.Classified.Tiles.dataframe <- bind_rows(out)





  # delete this line if I run it again.
  ## Percent.Cover.Classified.Tiles.dataframe <-rename(Percent.Cover.Classified.Tiles.dataframe,
  ##                                                   image = tile,
  ##                                                   pct_g_pred = pct_g,
  ##                                                   pct_i_pred = pct_i,
  ##                                                   pct_t_pred = pct_t,
  ##                                                   pct_o_pred = pct_o)

    ## saveRDS(Percent.Cover.Classified.Tiles.dataframe, str_c(derived.dir,"/","Percent.Cover.Classified.Tiles.dataframe",".rds"))

#+END_SRC

#+RESULTS:
: OGR data source with driver: ESRI Shapefile
: Source: "../RD_Accuracy/Grids", layer: "All_Grids_Accuracy_Assessment_pts"
: with 18365 features
: It has 10 fields




****** Join Cover from Grids with predicted Cover from images
#+BEGIN_SRC R
    Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets <- readRDS(str_c(derived.dir,"/","Wausau.Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets.dataframe",".rds"))

    str(Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets)
    str(Percent.Cover.Classified.Tiles.dataframe)

  Percent.Cover.Classified.Tiles.dataframe %>%
      filter(seg.params == "Pixel") %>%
      data.frame() %>%
      head()

    Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets %>%
        filter(n.points == 400)


  #Percent.Cover.Classified.Tiles.dataframe <- Percent.Cover.Classified.Tiles.dataframe %>%
  #    rename(pct_g_pred = pct_g, pct_t_pred = pct_t, pct_i_pred = pct_i, pct_o_pred = pct_o)


    grid.master.df <- left_join(Percent.Cover.Classified.Tiles.dataframe, Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets)

    # Should join by Joining by: c("grid", "target.cover", "n.points", "target.type")

    str(grid.master.df)

    grid.master.df %>%
  #      filter(n.points == 400) %>%
        data.frame() %>%
        head(n=40)




#+END_SRC


***** Make RMSE plots

#+BEGIN_SRC R :results graphics :file figs/wausauNAIP.100m.RMSE_plot.png :height 800 :width 600

    sub.for.rmse.plot <- grid.master.df %>%
        filter(target.type == "multinomial",
               image == "wausauNAIP",
               n.points == 225)


    ggplot(sub.for.rmse.plot, aes( x = pct.t.googleEarth, y = pct_t_pred, color = model)) +
  geom_point() + geom_smooth() + theme_classic() +
  geom_line(data = data.frame(pct.t.googleEarth = c(0,1), pct_t_pred = c(0,1), seg.params = "1:1"),
  color = "black", size = 1) +
  ggtitle("NAIP, n.pts: 225")

#+END_SRC

#+RESULTS:
[[file:figs/wausauNAIP.100m.RMSE_plot.png]]



***** Calc RMSE table

 Create dataframe with structure:

 | RMSE | image | segmentation | target | model | cropped.to.n.pts | cover_type |   |   |   |   |   |   |   |
 |------+-------+--------------+--------+-------+------------------+------------+---+---+---+---+---+---+---|
 |      |       |              |        |       |                  |            |   |   |   |   |   |   |   |


****** Calc Error Column

#+BEGIN_SRC R
  error_tree <- grid.master.df %>%
      filter(target.cover == "tree" | target.cover == "all") %>%
      select(-target.cover) %>%
      group_by(image, model, n.points, seg.params, target.type) %>%
      mutate(t_error = (pct_t_pred - pct.t.googleEarth))

  error_tree %>%
      select(image, model, n.points, seg.params, target.type, grid, t_error) %>%
      filter(n.points == 225) %>%
      ungroup() %>%
      arrange(desc(abs(t_error))) %>%
      data.frame() %>%
      head(n=50)
#+END_SRC

#+RESULTS:
#+begin_example

       image    model n.points seg.params target.type        grid     t_error
1  wausauNAIP svm_resp      225  N-60_C-30    binomial  wau-100m-9 -0.23684326
2  wausauNAIP  rf_prob      225  N-60_C-30    binomial  wau-100m-9 -0.16171938
3  wausauNAIP  rf_resp      225  N-60_C-30    binomial  wau-100m-9 -0.15985461
4  wausauNAIP  rf_prob      225  N-60_C-30 multinomial  wau-100m-9 -0.15170287
5  wausauNAIP svm_resp      225  N-60_C-30    binomial  wau-100m-3 -0.13554282
6  wausauNAIP  rf_resp      225  N-60_C-30 multinomial  wau-100m-9 -0.13444036
7  wausauNAIP svm_resp      225  N-60_C-30 multinomial  wau-100m-9 -0.12255907
8  wausauNAIP svm_resp      225  N-60_C-30    binomial  wau-100m-2 -0.11762135
9  wausauNAIP svm_resp      225  N-60_C-30 multinomial  wau-100m-3 -0.10061635
10 wausauNAIP svm_resp      225  N-60_C-30    binomial  wau-100m-8 -0.09735509
11 wausauNAIP svm_resp      225  N-60_C-30    binomial  wau-100m-1 -0.07842719
12 wausauNAIP  rf_resp      225  N-60_C-30    binomial  wau-100m-8 -0.06687931
13 wausauNAIP  rf_prob      225  N-60_C-30 multinomial  wau-100m-8 -0.06576044
14 wausauNAIP  rf_prob      225  N-60_C-30    binomial  wau-100m-8 -0.06410878
15 wausauNAIP  rf_prob      225  N-60_C-30    binomial  wau-100m-4 -0.06165438
16 wausauNAIP  rf_resp      225  N-60_C-30    binomial  wau-100m-4 -0.06165438
17 wausauNAIP  rf_resp      225  N-60_C-30 multinomial  wau-100m-8 -0.06155138
18 wausauNAIP  rf_prob      225  N-60_C-30 multinomial  wau-100m-2 -0.05987913
19 wausauNAIP svm_resp      225  N-60_C-30    binomial  wau-100m-5 -0.05903233
20 wausauNAIP  rf_resp      225  N-60_C-30 multinomial  wau-100m-2 -0.05733804
21 wausauNAIP  rf_prob      225  N-60_C-30    binomial  wau-100m-5 -0.05104043
22 wausauNAIP  rf_prob      225  N-60_C-30 multinomial  wau-100m-4 -0.04940013
23 wausauNAIP  rf_resp      225  N-60_C-30 multinomial  wau-100m-4 -0.04940013
24 wausauNAIP  rf_resp      225  N-60_C-30    binomial  wau-100m-5 -0.04677808
25 wausauNAIP svm_resp      225  N-60_C-30    binomial  wau-100m-4 -0.04428532
26 wausauNAIP svm_resp      225  N-60_C-30 multinomial  wau-100m-6  0.04281694
27 wausauNAIP  rf_prob      225  N-60_C-30    binomial  wau-100m-2 -0.04046953
28 wausauNAIP  rf_resp      225  N-60_C-30    binomial  wau-100m-2 -0.04046953
29 wausauNAIP  rf_resp      225  N-60_C-30 multinomial  wau-100m-6  0.03791524
30 wausauNAIP  rf_prob      225  N-60_C-30 multinomial  wau-100m-6  0.03541111
31 wausauNAIP svm_resp      225  N-60_C-30 multinomial  wau-100m-2 -0.03495483
32 wausauNAIP  rf_prob      225  N-60_C-30 multinomial  wau-100m-5 -0.02850326
33 wausauNAIP  rf_prob      225  N-60_C-30 multinomial  wau-100m-7 -0.02720576
34 wausauNAIP  rf_prob      225  N-60_C-30    binomial  wau-100m-7 -0.02720576
35 wausauNAIP  rf_resp      225  N-60_C-30    binomial  wau-100m-7 -0.02720576
36 wausauNAIP svm_resp      225  N-60_C-30    binomial  wau-100m-7 -0.02720576
37 wausauNAIP  rf_prob      225  N-60_C-30 multinomial wau-100m-10  0.02521039
38 wausauNAIP  rf_resp      225  N-60_C-30 multinomial wau-100m-10  0.02521039
39 wausauNAIP  rf_resp      225  N-60_C-30 multinomial  wau-100m-7 -0.02473689
40 wausauNAIP svm_resp      225  N-60_C-30 multinomial wau-100m-10  0.02435165
41 wausauNAIP  rf_resp      225  N-60_C-30 multinomial  wau-100m-5 -0.02392124
42 wausauNAIP svm_resp      225  N-60_C-30 multinomial  wau-100m-7 -0.02114093
43 wausauNAIP  rf_resp      225  N-60_C-30 multinomial  wau-100m-3 -0.02113971
44 wausauNAIP svm_resp      225  N-60_C-30 multinomial  wau-100m-4 -0.01983010
45 wausauNAIP svm_resp      225  N-60_C-30 multinomial  wau-100m-1 -0.01870105
46 wausauNAIP  rf_prob      225  N-60_C-30 multinomial  wau-100m-3 -0.01611159
47 wausauNAIP svm_resp      225  N-60_C-30 multinomial  wau-100m-8 -0.01391964
48 wausauNAIP  rf_prob      225  N-60_C-30    binomial  wau-100m-3 -0.01340830
49 wausauNAIP  rf_resp      225  N-60_C-30    binomial  wau-100m-3 -0.01340830
50 wausauNAIP svm_resp      225  N-60_C-30    binomial wau-100m-10  0.01340275
#+end_example



#+BEGIN_SRC R

    RMSE_tree <- grid.master.df %>%
        filter(target.cover == "tree" | target.cover == "all") %>%
        select(-target.cover) %>%
        group_by(image, model, n.points, seg.params, target.type) %>%
        summarize(RMSE_t = sqrt( mean( (pct_t_pred - pct.t.googleEarth)^2, na.rm =T ) ) )

  RMSE_tree <- RMSE_tree %>%
      mutate(segment.size = ifelse(!is.na(str_extract(seg.params, ".*105.*")), 105,
                            ifelse(!is.na(str_extract(seg.params, ".*60.*")), 60,
                            ifelse(!is.na(str_extract(seg.params, ".*30.*")), 30,
                            ifelse(!is.na(str_extract(seg.params, ".*70.*")), 105,
                            ifelse(!is.na(str_extract(seg.params, ".*40.*")), 60,
                            ifelse(!is.na(str_extract(seg.params, ".*20.*")), 30,1)))))))
#+END_SRC

#+RESULTS:

***** RMSE analysis

Which combination of image, segmentation, target, model and n.pts
(spatial scale) minimize error for each cover_type?

#+BEGIN_SRC R :results raw
options(asciiType = "org")
options(warn = -1)
  RMSE_tree %>%
      ungroup() %>%
      arrange(RMSE_t) %>%
      head(n = 30) %>%
      ascii()
#+END_SRC

#+RESULTS:
 |   | image      | model    | n.points | seg.params | target.type | RMSE_t | segment.size |
 |---+------------+----------+----------+------------+-------------+--------+--------------|
 | 1 | wausauNAIP | svm_resp |   225.00 | N-60_C-30  | multinomial |   0.05 |        60.00 |
 | 2 | wausauNAIP | rf_resp  |   225.00 | N-60_C-30  | multinomial |   0.06 |        60.00 |
 | 3 | wausauNAIP | rf_prob  |   225.00 | N-60_C-30  | multinomial |   0.06 |        60.00 |
 | 4 | wausauNAIP | rf_resp  |   225.00 | N-60_C-30  | binomial    |   0.06 |        60.00 |
 | 5 | wausauNAIP | rf_prob  |   225.00 | N-60_C-30  | binomial    |   0.06 |        60.00 |
 | 6 | wausauNAIP | svm_resp |   225.00 | N-60_C-30  | binomial    |   0.11 |        60.00 |



Plot:
x = cropped.to.n.pts
y = RMSE
color = model
facet(segmentation~cover_type)

#+BEGIN_SRC R :results graphics :file figs/RMSE_tree_compare_n.ptsXRMSE.png :height 800 :width 600

  ggplot(RMSE_tree, aes(x = n.points, y = RMSE_t, color = model)) + geom_point() +
      facet_grid(segment.size~image)

#+END_SRC

#+RESULTS:
[[file:figs/RMSE_tree_compare_n.ptsXRMSE.png]]


#+BEGIN_SRC R :results graphics :file figs/RMSE_tree_compare_AreaXRMSE_NAIP_seg60.png
  RMSE_tree.sub <- RMSE_tree%>%
      filter(segment.size == 60, image == "madisonNAIP", target.type == "binomial", model == "svm_resp") %>%
      mutate(area_meters_squared = ((sqrt(n.points) - 1) * 7)^2)


  ggplot(RMSE_tree.sub, aes(x = area_meters_squared, y = RMSE_t), color = "blue") + geom_point() +
      labs(y = "Root Mean Squared Prediction Error \n for Percent Tree Cover") +
      theme_classic() +
      theme(axis.title = element_text(size = 24),
            axis.text =  element_text(size = 22)) +
      xlim(0,45000)

#+END_SRC

#+RESULTS:
[[file:figs/RMSE_tree_compare_AreaXRMSE_NAIP_seg60.png]]


#+BEGIN_SRC R :results graphics :file figs/RMSE_tree_compare_seg.sizeXRMSE.png :height 800 :width 600

  ggplot(RMSE_tree, aes(x = segment.size, y = RMSE_t, color = n.points, group = interaction(n.points,target.type))) + geom_line() +
      facet_grid(model~image)

#+END_SRC

#+RESULTS:
[[file:figs/RMSE_tree_compare_seg.sizeXRMSE.png]]


#+BEGIN_SRC R :results raw

  m1 <-lm(RMSE_t*100 ~ image * (model +  target.type + n.points * segment.size), data = RMSE_tree)
  tidy(m1, digits = 2) %>%
ascii()
#+END_SRC

#+RESULTS:
#+begin_example
|    | term                                   | estimate | std.error | statistic | p.value |
|----+----------------------------------------+----------+-----------+-----------+---------|
| 1  | (Intercept)                            | 42.29    | 1.85      | 22.89     | 0.00    |
| 2  | imagepanshpSPOT                        | -5.24    | 2.61      | -2.01     | 0.05    |
| 3  | modelrf_resp                           | 0.05     | 1.56      | 0.03      | 0.97    |
| 4  | modelsvm_resp                          | -4.90    | 1.56      | -3.14     | 0.00    |
| 5  | target.typemultinomial                 | -0.76    | 1.28      | -0.59     | 0.55    |
| 6  | n.points                               | -0.04    | 0.01      | -5.20     | 0.00    |
| 7  | segment.size                           | -0.17    | 0.02      | -7.10     | 0.00    |
| 8  | n.points:segment.size                  | -0.00    | 0.00      | -0.82     | 0.41    |
| 9  | imagepanshpSPOT:modelrf_resp           | -0.88    | 2.21      | -0.40     | 0.69    |
| 10 | imagepanshpSPOT:modelsvm_resp          | 9.12     | 2.21      | 4.13      | 0.00    |
| 11 | imagepanshpSPOT:target.typemultinomial | -3.40    | 1.80      | -1.88     | 0.06    |
| 12 | imagepanshpSPOT:n.points               | 0.01     | 0.01      | 0.66      | 0.51    |
| 13 | imagepanshpSPOT:segment.size           | 0.20     | 0.03      | 6.02      | 0.00    |
| 14 | imagepanshpSPOT:n.points:segment.size  | 0.00     | 0.00      | 0.02      | 0.99    |
#+end_example


** How accurate is NAIP?
#+BEGIN_SRC R
  pts.robi <- readOGR(dsn = "../RD_Accuracy/PointsByRobi/", layer = "accuracy_cover_2500")
  proj4string(pts.robi) <- utm16
  #pts.robi <- spTransform(pts.robi, utm16)
  plot(pts.robi)

  madison <-  readOGR(dsn = "../RD_US_UrbanAreasShapefile", layer = "cb_2013_us_ua10_500k")
  madison <- madison[madison@data$NAME10 == "Madison, WI",]
  plot(madison, add = T)

  madison <- spTransform(madison, utm16)

  pts.urb <- over(pts.robi, madison) %>% na.omit()

#+END_SRC

#+RESULTS:
: OGR data source with driver: ESRI Shapefile
: Source: "../RD_Accuracy/PointsByRobi/", layer: "accuracy_cover_2500"
: with 2500 features
: It has 7 fields
: Warning message:
: closing unused connection 3 (<-localhost:11969)

** plot grid on google earth

 #+BEGIN_SRC R :results graphics :file figs/grid200m-3.on.GoogleEarth.png
       grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer, stringsAsFactors = F)

       grd <- spTransform(grd, CRS("+init=epsg:4326"))

     xy <- coordinates(grd)
     grd@data$x <- xy[,1]
     grd@data$y <- xy[,2]

       grd.200m3 <- grd[grd@data$unq__ID == "mad-200m-3",]

       b <- bbox(grd.200m3)

     library(ggmap)

     mp <- get_map(b, maptype = "satellite", zoom = 18)

     UTC_pal <- c(grass = "#ffff99", impervious = "#f0027f", tree = "#7fc97f", o = "#666666", soil ="#fdc086")

     grd.200m3@data <- grd.200m3@data %>%
         mutate(cover_type = mapvalues(cvr_typ, from = c("g","i","t","s"), to = c("grass","impervious","tree","soil")))

     ggmap(mp) + geom_point(data = grd.200m3@data, aes(x = x, y = y, color = cover_type)) +
         scale_color_manual(values = UTC_pal) +
         theme(legend.text = element_text(size = rel(1.4)),
               legend.title = element_text(size = rel(2))) +
         labs(color = "Cover Type")





 #+END_SRC

 #+RESULTS:
 [[file:figs/grid200m-3.on.GoogleEarth.png]]




* plot grid on google earth
:PROPERTIES:
:ARCHIVE_TIME: 2016-06-07 Tue 21:50
:ARCHIVE_FILE: /ssh:erker@kang:/home/erker/mydata2/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Workflow
:ARCHIVE_CATEGORY: utc
:END:

 #+BEGIN_SRC R :results graphics :file figs/grid200m-3.on.GoogleEarth.png
       grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer, stringsAsFactors = F)

       grd <- spTransform(grd, CRS("+init=epsg:4326"))

     xy <- coordinates(grd)
     grd@data$x <- xy[,1]
     grd@data$y <- xy[,2]

       grd.200m3 <- grd[grd@data$unq__ID == "mad-200m-3",]

       b <- bbox(grd.200m3)

     library(ggmap)

     mp <- get_map(b, maptype = "satellite", zoom = 18)

     UTC_pal <- c(grass = "#ffff99", impervious = "#f0027f", tree = "#7fc97f", o = "#666666", soil ="#fdc086")

     grd.200m3@data <- grd.200m3@data %>%
         mutate(cover_type = mapvalues(cvr_typ, from = c("g","i","t","s"), to = c("grass","impervious","tree","soil")))

     ggmap(mp) + geom_point(data = grd.200m3@data, aes(x = x, y = y, color = cover_type)) +
         scale_color_manual(values = UTC_pal) +
         theme(legend.text = element_text(size = rel(1.4)),
               legend.title = element_text(size = rel(2))) +
         labs(color = "Cover Type")





 #+END_SRC

 #+RESULTS:
 [[file:figs/grid200m-3.on.GoogleEarth.png]]




* Create and SaveModels
:PROPERTIES:
:ARCHIVE_TIME: 2016-06-08 Wed 16:17
:ARCHIVE_FILE: /ssh:erker@kang:/home/erker/mydata2/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Workflow/Determine how to make best classifier for Madison : image, segmentation, model, n.classes, target, and def truth/Training
:ARCHIVE_CATEGORY: utc
:END:
for tuning see:
https://mlr-org.github.io/mlr-tutorial/release/html/nested_resampling/index.html

#+BEGIN_SRC R :results none
       cl <- makeCluster(cores)
       registerDoParallel(cl)

  foreach(img.nm = image.names,
              .packages = c("mlr","stringr","dplyr","foreach","doParallel")) %dopar% {

      ModelBuildingRDSs <- list.files(dd.training.dir) %>%
          str_extract(., str_c(img.nm,".*",ModelBuilding.appendage)) %>%
          na.omit()

      foreach(ModelBuildingRDS = ModelBuildingRDSs) %do% {
          Build.and.Save.models(dir = dd.training.dir,
                                modelBuildingData = ModelBuildingRDS,
                                models.dir = Models.dir,
                                image.name = img.nm)

      }
  }

  Build.and.Save.models <- function(
                dir = dd.training.dir,
                modelBuildingData = ModelBuildingRDS,
                models.dir = Models.dir,
                image.name){

  dat <- readRDS(paste0(dir,"/",modelBuildingData)) %>%
      as.data.frame()

        image.and.segmentation.stem = str_replace(modelBuildingData, ModelBuilding.appendage,"")

        names <- colnames(dat)
        names <- str_replace(names, "\\(",".")
        names <- str_replace(names, "\\)",".")
        names <- str_replace(names, "\\:",".")
        colnames(dat) <- names

              dat_G <- dat %>%
                  mutate(Class = as.character(Class),
                         Class = ifelse(Class == "g", Class, "o"))

              dat_I <- dat %>%
                  mutate(Class = as.character(Class),
                         Class = ifelse(Class == "i", Class, "o"))

              dat_T <- dat %>%
                  mutate(Class = as.character(Class),
                         Class = ifelse(Class == "t", Class, "o"))

            # Create Tasks
        all.task <- makeClassifTask(id = paste0(image.name,"_all"), data = dat, target = "Class")
        grass.task <- makeClassifTask(id = paste0(image.name,"_grass"), data = dat_G, target = "Class")
        impervious.task <- makeClassifTask(id = paste0(image.name,"_impervious"), data = dat_I, target = "Class")
        tree.task <- makeClassifTask(id = paste0(image.name,"_tree"), data = dat_T, target = "Class",positive = "t")

        task.list <- list(all = all.task, grass = grass.task, impervious = impervious.task, tree = tree.task)

                                                   # Make Learners
           RF_prob <- makeLearner(id = "rf_prob","classif.randomForest", predict.type = "prob", fix.factors.prediction = TRUE)
           RF_response <- makeLearner(id = "rf_resp", "classif.randomForest", predict.type = "response", fix.factors.prediction = TRUE)
           SVM_response <- makeLearner(id = "svm_resp", "classif.svm", predict.type = "response", fix.factors.prediction = TRUE)

           learner.list <- list(RF_prob = RF_prob, RF_response = RF_response, SVM_response = SVM_response)

                                                   # Train Learners on Tasks, Make models
  #         cl<-makeCluster(cores)
  #         registerDoParallel(cl)

  models <- foreach(tsk = task.list, .packages = "mlr") %do% {
      foreach(lnr = learner.list) %do% {
          mod <- train(lnr, tsk)
          mod
      }
  }
         saveRDS(models, file = paste0(models.dir,"/",image.and.segmentation.stem, models.appendage))
    }
 #+END_SRC


* Save Pixel Feature Dataframe
:PROPERTIES:
:ARCHIVE_TIME: 2016-06-30 Thu 15:59
:ARCHIVE_FILE: /ssh:kang:/home/erker/mydata2/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Workflow/Determine how to make best classifier for Madison : image, segmentation, model, n.classes, target, and def truth/Training/For Each Training Tile/Make PixelFeatureDFs and SegmentationFeatureDFs for Training Regions
:ARCHIVE_CATEGORY: utc
:END:
 #+BEGIN_SRC R
   pixel.feature.df <- Create.Pixel.Feature.df(tile.dir = dd.training.dir,
                                               tile.name = i,
                                               tile.appendage = ratio.tile.name.append,
                                               texture.pattern = texture.pattern,
                                               Pixel.DF.appendage = pixel.feature.df.appendage,
                                               band.names = band.names.wRatios)

#+END_SRC

 #+results:


* Add Texture
:PROPERTIES:
:ARCHIVE_TIME: 2016-06-30 Thu 15:59
:ARCHIVE_FILE: /ssh:kang:/home/erker/mydata2/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Workflow/Determine how to make best classifier for Madison : image, segmentation, model, n.classes, target, and def truth/Training/For Each Training Tile/Make PixelFeatureDFs and SegmentationFeatureDFs for Training Regions
:ARCHIVE_CATEGORY: utc
:END:
#+begin_src R
  out <- add.texture(tile.dir = dd.training.dir,
              tile.name = i,
              ratio.append = ratio.tile.name.append,
              band.num = 8,
              window = list(c(3,3), c(5,5)),
              statistics = c("homogeneity", "contrast", "correlation"),
              shift = list(c(0,1),c(1,0),c(1,1),c(-1,1)))

#+end_src

#+results:



* Add Ratios
:PROPERTIES:
:ARCHIVE_TIME: 2016-06-30 Thu 15:59
:ARCHIVE_FILE: /ssh:kang:/home/erker/mydata2/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Workflow/Determine how to make best classifier for Madison : image, segmentation, model, n.classes, target, and def truth/Training/For Each Training Tile/Make PixelFeatureDFs and SegmentationFeatureDFs for Training Regions
:ARCHIVE_CATEGORY: utc
:END:
#+BEGIN_SRC R
   add.ratios.ndvi(tile.dir = dd.training.dir,
                   tile.name = i)

 #+END_SRC

#+results:
:  There were 50 or more warnings (use warnings() to see the first 50)


* Perform PCA
:PROPERTIES:
:ARCHIVE_TIME: 2016-06-30 Thu 15:59
:ARCHIVE_FILE: /ssh:kang:/home/erker/mydata2/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Workflow/Determine how to make best classifier for Madison : image, segmentation, model, n.classes, target, and def truth/Training/For Each Training Tile/Make PixelFeatureDFs and SegmentationFeatureDFs for Training Regions
:ARCHIVE_CATEGORY: utc
:END:
#+BEGIN_SRC R :results none
	      image.pca(image.name = img.nm,
                        tile.dir = dd.training.dir,
                        tile.name = i,
                        pca.di = dd.pca.dir)
      }
}
   #+END_SRC

* Segmentation
:PROPERTIES:
:ARCHIVE_TIME: 2016-07-01 Fri 11:56
:ARCHIVE_FILE: /ssh:kang:/home/erker/mydata2/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Workflow/Determine how to make best classifier for Madison : image, segmentation, model, n.classes, target, and def truth/Training/Make Feature and model building data frames, for Each Training Tile/Make PixelFeatureDFs and SegmentationFeatureDFs for Training Regions
:ARCHIVE_CATEGORY: utc
:END:

#+BEGIN_SRC R
  #  system("source activate utc")
  #  system("export PATH=/home/RUSSELL/erker/.conda/envs/utc/bin:$PATH")

      segment_size <- c(30,60,105)
      compactness <- c(15,30,32)
      o.wd <- getwd()


      cl <- makeCluster(cores)
      registerDoParallel(cl)

      for(img.nm in image.names) {

          tile.names <- list.files(dd.training.dir) %>%
              str_extract(., pattern = str_c(img.nm,".[0-9]+.tif")) %>%
              str_extract(., pattern = str_c(img.nm,".[0-9]+")) %>%
              na.omit()

          pixel_size <- ifelse(img.nm == "madisonNAIP", 1, 1.5)
          compactness <- if(img.nm == "madisonNAIP") compactness else round(2/3*compactness)

          for(j in 1:length(segment_size)) {

              foreach (i = tile.names) %dopar% {
                  system(paste0("cd ",dd.training.dir,";", "python ../../code/fia_segment_cmdArgs.py ",pixel_size," ",segment_size[j]," ",compactness[j]," ",i))
               }
          }
      }

      setwd(o.wd)
#+END_SRC

#+results:



* Create Segment Feature Dataframe
:PROPERTIES:
:ARCHIVE_TIME: 2016-07-01 Fri 11:57
:ARCHIVE_FILE: /ssh:kang:/home/erker/mydata2/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Workflow/Determine how to make best classifier for Madison : image, segmentation, model, n.classes, target, and def truth/Training/Make Feature and model building data frames, for Each Training Tile/Make PixelFeatureDFs and SegmentationFeatureDFs for Training Regions
:ARCHIVE_CATEGORY: utc
:END:
#+BEGIN_SRC R :results none
  cl <- makeCluster(cores)
  registerDoParallel(cl)

  seg.feature.dfs <- foreach(img.nm = image.names) %do% {

      tile.names <- list.files(dd.training.dir) %>%
          str_extract(., pattern = str_c(img.nm,"-[0-9]+",segmentation.layer.pattern,".tif$")) %>%
          na.omit()

      seg.params <- unique(str_extract(tile.names, segmentation.layer.pattern))

      foreach(seg.param.set = seg.params) %do% {

          tile.names.sub <- tile.names[which(complete.cases(str_extract(tile.names,seg.param.set)))] %>%
              str_sub(start = 1, end = -5)

          out <- foreach (i = tile.names.sub,
                          .packages = c("raster","stringr","dplyr","broom","tidyr")) %dopar% {
                              seg.df <- Create.Segment.Feature.df(tile.dir = dd.training.dir,
                                                                  tile.name = i)
                              saveRDS(seg.df, file = paste0(dd.training.dir,"/", i,segmentFeatureDF.appendage))
                          }
          out
      }
  }
    #+END_SRC



* Classify Every Urban Area in the State Functions <2016-07-06 Wed>
:PROPERTIES:
:ARCHIVE_TIME: 2016-07-06 Wed 12:00
:ARCHIVE_FILE: /ssh:kang:/home/erker/mydata2/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Classify Every Urban Area in the State
:ARCHIVE_CATEGORY: utc
:END:
** Extract Name from path
#+BEGIN_SRC R
  extract.name.from.path <- function(path) {
      str_extract(basename(path), "[A-Za-z0-9_]*.") %>%
          str_sub(.,1,-2)
  }
#+END_SRC

** Reproject Shapefile to Image Coordinate Reference System
#+BEGIN_SRC R
  Reproject_Shapefile_to_Image_CRS <- function(shapefile.dsn,
                                               shapefile.layer,
                                               image.path,
                                               shapefile.out.dsn) {
      r <- stack(image.path)
      shapefile <- readOGR(shapefile.dsn, shapefile.layer)
      shapefile.WimageCRS <- spTransform(shapefile, crs(r))
      image.name <- extract.name.from.path(image.path)
      shapefile.layer  <- str_c(image.name,"_",shapefile.layer)
      writeOGR(shapefile.WimageCRS, shapefile.out.dsn, shapefile.layer, driver = "ESRI Shapefile", overwrite =T)
  }
#+END_SRC

** Crop image to each Shapefile polygon
#+BEGIN_SRC R
  Crop_image_to_each_Shapefile_polygon <- function(shapefile.dsn,
                                                   shapefile.layer,
                                                   image.path,
                                                   cores,
                                                   output.dir)  {
      image.name <- extract.name.from.path(image.path)
      shape <- readOGR(shapefile.dsn, str_c(image.name,"_",shapefile.layer))
      polygons <- as(shape, "SpatialPolygons")

      image <- stack(image.path)

      cl <- makeCluster(cores)
      registerDoParallel(cl)

      foreach (i = seq_along(polygons),
               .packages = c("raster")) %dopar% {
                   r <- image
                   r <- crop(r, polygons[i])
                   writeRaster(r, paste0(output.dir,"/",image.name,"-",i,".tif"),
                               overwrite = T)
               }
  }

#+END_SRC

** Crop image to regions around shapefile points
#+BEGIN_SRC R

                                          # assign the polygon name to the points.
  give_polygons_attributes_of_first_point_within <- function(points,
                                                             polygons){
      if (length(points@data$row) >1) {
          points <- points[points@data$row ==1 & points@data$col ==1 ,]
      }
      po <- gIntersects(points, polygons, byid=TRUE)
      out <- foreach(polygon.number = seq_along(polygons), .combine = "rbind") %do% {
          first.point.data <- points[po[polygon.number,],]@data %>%
              slice(1)
          pd <- as(polygons[polygon.number], "SpatialPolygonsDataFrame")
          pd@data <- first.point.data
          pd
      }
  }

  Crop_image_to_regions_around_points_nameBygrid<- function(shapefile.dsn,
                                                            shapefile.layer,
                                                            image.path,
                                                            cores,
                                                            output.dir,
                                                            column.name = "unq__ID",
                                                            point.buffer.size = 4,
                                                            polygon.buffer.size = 15)  {
      image.name <- extract.name.from.path(image.path)
      points <- readOGR(shapefile.dsn,str_c(image.name,"_",shapefile.layer))
      box <- gBuffer(points, width = point.buffer.size, byid = F)
      box <- disaggregate(box)

      polygons <- as(box, "SpatialPolygons")

      polygons <- give_polygons_attributes_of_first_point_within(points,polygons)

      image <- stack(image.path)

      image.extent <- as(extent(image), "SpatialPolygons")
      proj4string(image.extent) <- proj4string(image)

      polygons.in.image <- foreach(i = seq_along(polygons),.combine = "c") %do% {
          gIntersects(polygons[i,],image.extent)
      }

      polygons <- polygons[polygons.in.image,]

      cl <- makeCluster(cores)
      registerDoParallel(cl)

      foreach (k = seq_along(polygons),
               .packages = c("raster","rgeos")) %dopar% {
                   r <- image
                   poly <- gBuffer(polygons[k,],width = polygon.buffer.size, byid = T)
                   r <- crop(r, poly)
                   tile.id <- polygons@data[k,column.name]
                   writeRaster(r, paste0(output.dir,"/",image.name,"_",tile.id,".tif"),
                               overwrite = T)
               }
  }

                                          #  shapefile.dsn = grid.accuracy.region.imageCRS.dsn
                                          #  shapefile.layer = grid.accuracy.region.layer,
                                          #  output.dir = image.cropped.to.grid.accuracy.dir


  Crop_image_to_regions_around_points <- function(shapefile.dsn,
                                                  shapefile.layer,
                                                  image.path,
                                                  cores,
                                                  output.dir)  {

      points <- readOGR(shapefile.dsn, shapefile.layer)
      box <- gBuffer(points, width = 8)
      box <- disaggregate(box)

      polygons <- as(box, "SpatialPolygons")

      image <- stack(image.path)

      cl <- makeCluster(cores)
      registerDoParallel(cl)

      foreach (i = seq_along(polygons),
               .packages = c("raster")) %dopar% {
                   r <- image
                   r <- crop(r, polygons[i])
                   writeRaster(r, paste0(output.dir,"/",i,".tif"),
                               overwrite = T)
               }
  }

#+END_SRC

** Make new ratio bands from image
#+BEGIN_SRC R
  ratio <- function(image_w4bands, numerator_bandNumber) {
      r <- image_w4bands[,,numerator_bandNumber,drop = F] / sum(image_w4bands)
      return(r)
  }

  ndvi_nodrop <- function(image_w4bands,red_bandnumber,nir_bandnumber,...) {
      red_band <- image_w4bands[[red_bandnumber]]
      nir_band <- image_w4bands[[nir_bandnumber]]
      ndvi <- (nir_band - red_band)/(nir_band + red_band)
      return(ndvi)
  }

  add.ratios.ndvi <- function(tile.dir,
                              tile.name,
                              out.tile.name.append = ratio.tile.name.append,
                              band.names = c("blue","green","red","nir"),
                              red.band.number = 3,
                              nir.band.number = 4) {

      in.tile.path <- str_c(tile.dir, "/", tile.name, ".tif")
      tile <- stack(in.tile.path)
      names(tile) <- band.names

                                          # Create a ratio image for each band
      ratio.brick <- ratio(tile)
      ratio.brick <- ratio.brick*200 # rescale ndvi to save as 'INT1U'
      names(ratio.brick) <- paste0(band.names,rep("_ratio",times = 4))
      ndvi <- ndvi_nodrop(tile, red.band.number, nir.band.number)
      ndvi <- (ndvi+1)*100 # rescale ndvi to savep as 'INT1U'

                                          # if tile is not scaled 0-255, do it here
      if (getRasterMax(tile) > 255) {
          min <- getRasterMin(tile)
          max <- getRasterMax(tile)
          tile <- rescale.0.255(tile,min,max)
      }

      ratio.tile <- raster::stack(tile, ratio.brick, ndvi)
      writeRaster(ratio.tile,
                  filename = paste0(tile.dir,"/",tile.name,out.tile.name.append, ".tif"),
                  overwrite = T,
                  datatype = 'INT1U')
  }
#+END_SRC

** Image PCA
#+BEGIN_SRC R
  getRasterMin <- function(t) {
      return(min(cellStats(t, stat = "min")))
  }

  getRasterMax <- function(t) {
      return(max(cellStats(t, stat = "max")))
  }

  rescale.0.255 <- function(raster,
                            min,
                            max) {
                                (raster - min)/(max-min) * 255
  }

  image.pca <- function(image.name,
                        pca.model.name.append = pca.model.name.appendage,
                        tile.dir,
                        tile.name,
                        in.image.appendage = ratio.tile.name.append,
                        out.image.appendage = pca.tile.name.append,
                        band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi"),
                        comps.to.use = c(1,2,3),
                        pca.dir = dd.pca.dir) {


      out.path <- str_c(tile.dir, "/", tile.name, out.image.appendage, ".tif")

      s <- stack(str_c(tile.dir, "/", tile.name, in.image.appendage,".tif"))
      names(s) <- band.names

      pca.model <- readRDS(str_c(pca.dir,"/",image.name,pca.model.name.append))

      r <- predict(s, pca.model, index = comps.to.use)

      min.r <- getRasterMin(r)
      max.r <- getRasterMax(r)
      rescaled.r <- rescale.0.255(r, min.r, max.r)
      writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')
  }



  make.and.save.pca.transformation <- function(tile.dir,
                                               image.name,
                                               pca.model.name.append = pca.model.name.appendage,
                                               max.sample.size = 10000,
                                               core.num = cores,
                                               band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {

      tile.paths <- list.files(str_c(tile.dir), pattern = str_c(image.name,".*_with_ratios.tif$"), full.names = T)

      tile.names <- basename(tile.paths)

      cl <- makeCluster(core.num)
      registerDoParallel(cl)

      sr <- foreach (i = seq_along(tile.names), .packages = c("raster"), .combine ="rbind") %dopar% {
          tile <- stack(tile.paths[i])
          s <- sampleRandom(tile, ifelse(ncell(tile) > max.sample.size ,max.sample.size, ncell(tile)))
      }

      colnames(sr) <- band.names

                                          # Perform PCA on sample
      pca <- prcomp(sr, scale = T)
      saveRDS(pca,paste0(tile.dir,"/",image.name,pca.model.name.append))
      return(pca)
  }


  image.pca.forWholeState <- function(pca.model.name.append = pca.model.name.appendage,
                                      tile.dir,
                                      tile.name,
                                      in.image.appendage = ratio.tile.name.append,
                                      out.image.appendage = pca.tile.name.append,
                                      band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi"),
                                      comps.to.use = c(1,2,3),
                                      pca.transform) {


      out.path <- str_c(tile.dir, "/", tile.name, out.image.appendage, ".tif")

      s <- stack(str_c(tile.dir, "/", tile.name, in.image.appendage,".tif"))
      names(s) <- band.names

      r <- predict(s, pca.transform, index = comps.to.use)

      min.r <- getRasterMin(r)
      max.r <- getRasterMax(r)
      rescaled.r <- rescale.0.255(r, min.r, max.r)
      writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')
  }



  ## image.dir <- image.cropped.to.training.dir
  ## image.name <- 9
  ##                         in.image.appendage = ratio.tile.name.append
  ##                         out.image.appendage = pca.tile.name.append
  ##                         band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")
  ##                         max.sample.size = 10000
  ##                         comps.to.use = c(1,2,3)

  ##       out.path <- str_c(image.dir, "/", image.name, out.image.appendage, ".tif")

  ##       s <- stack(str_c(image.dir, "/", image.name, in.image.appendage,".tif"))
  ##       names(s) <- band.names

  ##       sr <- sampleRandom(s, ifelse(ncell(s) > max.sample.size, max.sample.size, ncell(s)))
  ##       pca <- prcomp(sr, scale = T)

  ##       r <- predict(s, pca, index = comps.to.use)

  ##       min.r <- getRasterMin(r)
  ##       max.r <- getRasterMax(r)
  ##       rescaled.r <- rescale.0.255(r, min.r, max.r)
  ##       writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')









                                          # Function takes raster stack, samples data, performs pca and returns stack of first n_pcomp bands
  ## predict_pca_wSampling_parallel <- function(stack, sampleNumber, n_pcomp, nCores = detectCores()-1) {
  ##     sr <- sampleRandom(stack,sampleNumber)
  ##     pca <- prcomp(sr, scale=T)
  ##     beginCluster()
  ##     r <- clusterR(stack, predict, args = list(pca, index = 1:n_pcomp))
  ##     endCluster()
  ##     return(r)
  ## }
#+END_SRC

** polygonize segment raster with gdal and add Class to shapefile

#+BEGIN_SRC R
  gdal_polygonizeR <- function(x, outshape=NULL, gdalformat = 'ESRI Shapefile',
                               pypath=NULL, readpoly=TRUE, quiet=TRUE) {
      if (isTRUE(readpoly)) require(rgdal)
      if (is.null(pypath)) {
          pypath <- Sys.which('gdal_polygonize.py')
      }
      if (!file.exists(pypath)) stop("Can't find gdal_polygonize.py on your system.")
      owd <- getwd()
      on.exit(setwd(owd))
      setwd(dirname(pypath))
      if (!is.null(outshape)) {
          outshape <- sub('\\.shp$', '', outshape)
          f.exists <- file.exists(paste(outshape, c('shp', 'shx', 'dbf'), sep='.'))
          if (any(f.exists))
              stop(sprintf('File already exists: %s',
                           toString(paste(outshape, c('shp', 'shx', 'dbf'),
                                          sep='.')[f.exists])), call.=FALSE)
      } else outshape <- tempfile()
      if (is(x, 'Raster')) {
          require(raster)
          writeRaster(x, {f <- tempfile(fileext='.asc')})
          rastpath <- normalizePath(f)
      } else if (is.character(x)) {
          rastpath <- normalizePath(x)
      } else stop('x must be a file path (character string), or a Raster object.')
      system2('python', args=(sprintf('"%1$s" "%2$s" -f "%3$s" "%4$s.shp"',
                                      pypath, rastpath, gdalformat, outshape)))
      if (isTRUE(readpoly)) {
          shp <- readOGR(dirname(outshape), layer = basename(outshape), verbose=!quiet)
          return(shp)
      }
      return(NULL)
  }


  polygonize.and.add.Class <- function(image.dir,
                                       image.name,
                                       segment.appendage = segment.tile.name.append,
                                       no.class = "N") {
      seg <- raster(paste0(image.dir,"/",image.name,segment.appendage,'.tif'))
      segPoly <- gdal_polygonizeR(seg)
      segPoly$Class <- no.class
      writeOGR(obj = segPoly,
               dsn = paste0(image.dir,"/",image.name),
               layer = paste0(image.name,segment.appendage),
               driver = "ESRI Shapefile",
               overwrite = T)
  }






#+END_SRC

** other Functions
#+BEGIN_SRC R

  Water_Urban_mask <- function(tile.path, tile.name, urban, water) {
                                          # load image tile
      tile <- stack(tile.path)
                                          # get extent image and make sp object
      et <- as(extent(tile), "SpatialPolygons")
      proj4string(et) <- "+init=epsg:26916"
                                          # Mask out non-urban areas
      if(gContainsProperly(urban,et) & !gIntersects(water,et)){
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      } else if (gContainsProperly(urban,et) & gIntersects(water,et)) {
          tile <- mask(tile, water, inverse = T)
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      } else if (gIntersects(urban, et) & !gIntersects(water,et)) {
          tile <- mask(tile, urban)
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      } else if (gIntersects(urban, et) & gIntersects(water,et)) {
          tile <- mask(tile, urban)
          tile <- mask(tile, water, inverse = T)
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      }
  }

  Crop_mask <- function(tile.path, tile.name, CDL_stack, n_years){

      tile <- stack(tile.path)
      crops <- crop(CDL_stack, tile)

                                          # These are the values in the CDL that correspond to non crop cover types and not water
      NonCroppedValues <- c(0,63:65, 81:83, 87:88, 112, 121:124, 131, 141:143, 152, 176, 190, 195)
                                          # open water is 111

      NonCroppedValues <- c(0,63:65, 81:83, 87:88, 112, 121:124, 131, 141:143, 152, 176, 190, 195)
                                          # open water is 111. I don't include it in the above list so that it gets masked

                                          # I'm going to add 37, Other Hay/Non-alfalfa, to the non crop cover types
      NonCroppedValues <- c(NonCroppedValues, 37)
                                          # I'm going to add 36, Alfalfa, to the non crop cover types
      NonCroppedValues <- c(NonCroppedValues, 36)

                                          # find cells that have been assigned crop all three years
      crops[crops %in% NonCroppedValues] <- 0
      crops[!(crops %in% NonCroppedValues)] <- 1
      cropsum <- overlay(crops, fun = sum)

      dis.cropsum <- disaggregate(cropsum, fact = 20)
      dis.cropsum <- resample(dis.cropsum, tile, "ngb")
      masked_tile <- mask(tile, dis.cropsum, maskvalue = n_years)

                                          #               Save Image
      writeRaster(masked_tile, paste0(crop.masked.tiles.directory, "/", tile.name), overwrite = T)
  }








#+END_SRC

** Make Pixel Feature DF
#+BEGIN_SRC R
  Create.Pixel.Feature.df <- function(tile.dir,
                                      tile.name,
                                      tile.appendage = ratio.tile.name.append,
                                      Pixel.DF.appendage = pixel.feature.df.appendage,
                                      band.names = band.names.wRatios) {
      r <- stack(paste0(tile.dir,"/",tile.name,tile.appendage,".tif"))
      names(r) <- band.names
      r.df <- as.data.frame(r, xy=T)
      saveRDS(r.df, file = paste0(tile.dir,"/", tile.name, Pixel.DF.appendage, ".rds"))
  }



  ## Create.Pixel.Feature.df<- function(raster.list,
  ##                                    band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {
  ##     r.df.list <- lapply(raster.list, function(r) {
  ##                             names(r) <- band.names
  ##                             as.data.frame(r, xy=T)
  ##            })
  ##     bind_rows(r.df.list)
  ## }

  Create.Pixel.Feature.df.noRowbind<- function(raster.list,
                                               band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {
      r.df.list <- lapply(raster.list, function(r) {
          names(r) <- band.names
          as.data.frame(r, xy=T)
      })
      r.df.list
  }


  Create.Pixel.Feature.df.foreachTile <- function(dir = image.cropped.to.grid.accuracy.dir[i],
                                                  base_pattern = "mad-[0-9]+m-[0-9]+_with_ratios.tif",
                                                  band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {

      file.list <- list.files(dir, full.names = T) %>%
          str_extract(., paste0(".*",base_pattern)) %>%
          na.omit() %>%
          unique()

      r.df.list <- lapply(file.list, function(r) {
          ras <- stack(r)
          names(ras) <- band.names
          ras.df <- as.data.frame(r, xy=T)

          r <- str_extract(r, base_pattern) %>%
              str_sub(., 1, -17)

          saveRDS(ras.df, file = str_c(dir,"/",r,"PixelFeatureDF",".rds"))
      })
  }

#+END_SRC

** Make Segment Feature DF
#+BEGIN_SRC R
  fitXYlm <- function(x,y,z) {
      if(is.na(sum(z))) {
          z <- rep(0, length(z))
      }
      dat <- data.frame(x,y,z)
      mod <- lm(z ~ x * y, data = dat)
      coefs <-tidy(mod) %>%
          dplyr::select(term,estimate) %>%
          spread(key = term, value = estimate)

      error <- glance(mod) %>%
          select(sigma)

      bind_cols(coefs,error)
  }

                                          #foreach(seg.param.set = seg.param) %do% {}

  Create.Segment.Feature.df <- function(tile.dir,
                                        tile.name,
                                        ratio.appendage = ratio.tile.name.append,
                                        band.names = band.names.wRatios){

                                          #tile.name.stem everything before segmentation parameters
      tile.name.stem = str_replace(tile.name, pattern = segmentation.layer.pattern, "")

      ratio.tile.path <- str_c(tile.dir, "/", tile.name.stem, ratio.tile.name.append, ".tif")
      r.tile <- stack(ratio.tile.path)

      names(r.tile) <- band.names


      seg.tile.path <-  str_c(tile.dir, "/", tile.name,".tif")
      s.tile <- raster(seg.tile.path)

                                          # Create a data_frame where mean and variances are calculated by zone
      x <- as.data.frame(r.tile, xy = T)
      s <- as.data.frame(s.tile)
      colnames(s) <- "segment"
      r <- bind_cols(x,s)
      r2 <- r %>%
          group_by(segment) %>%
          mutate(x.center = x - quantile(x = x, probs = .5),
                 y.center = y - quantile(x = y, probs = .5))

      spatial.model.coef <- r2 %>%
          do(fitXYlm(x = .$x.center, y = .$y.center, z = .$n_ratio))

      mean.and.sd <- r2 %>%
          summarize(mean(blue),
                    mean(green),
                    mean(red),
                    mean(nir),
                    mean(b_ratio),
                    mean(g_ratio),
                    mean(r_ratio),
                    mean(n_ratio),
                    mean(ndvi),
                    sd(blue),
                    sd(green),
                    sd(red),
                    sd(nir),
                    sd(b_ratio),
                    sd(g_ratio),
                    sd(r_ratio),
                    sd(n_ratio),
                    sd(ndvi))

      tile.name = data.frame(tile.name = rep(tile.name.stem, nrow(mean.and.sd)))

      out <- left_join(spatial.model.coef, mean.and.sd) %>%
          bind_cols(., tile.name)

      names <- colnames(out)
      names <- str_replace(names, "\\(",".")
      names <- str_replace(names, "\\)",".")
      names <- str_replace(names, "\\:",".")
      colnames(out) <- names
      out
  }

  Create.Segment.Feature.df.noLM <- function(tile.dir,
                                             tile.name,
                                             ratio.appendage = ratio.tile.name.append,
                                             band.names = band.names.wRatios){

                                          #tile.name.stem everything before segmentation parameters
      tile.name.stem = str_replace(tile.name, pattern = segmentation.layer.pattern, "")

      ratio.tile.path <- str_c(tile.dir, "/", tile.name.stem, ratio.tile.name.append, ".tif")
      r.tile <- stack(ratio.tile.path)

      names(r.tile) <- band.names


      seg.tile.path <-  str_c(tile.dir, "/", tile.name,".tif")
      s.tile <- raster(seg.tile.path)

                                          # Create a data_frame where mean and variances are calculated by zone
      x <- as.data.frame(r.tile, xy = T)
      s <- as.data.frame(s.tile)
      colnames(s) <- "segment"
      r <- bind_cols(x,s)
      r2 <- r %>%
          group_by(segment)

      mean.and.sd <- r2 %>%
          summarize(mean(blue),
                    mean(green),
                    mean(red),
                    mean(nir),
                    mean(b_ratio),
                    mean(g_ratio),
                    mean(r_ratio),
                    mean(n_ratio),
                    mean(ndvi),
                    sd(blue),
                    sd(green),
                    sd(red),
                    sd(nir),
                    sd(b_ratio),
                    sd(g_ratio),
                    sd(r_ratio),
                    sd(n_ratio),
                    sd(ndvi))

      tile.name = data.frame(tile.name = rep(tile.name.stem, nrow(mean.and.sd)))

      out <- bind_cols(mean.and.sd, tile.name)

      names <- colnames(out)
      names <- str_replace(names, "\\(",".")
      names <- str_replace(names, "\\)",".")
      names <- str_replace(names, "\\:",".")
      colnames(out) <- names
      out
  }

#+END_SRC

** Create ModelBuilding dataframe
#+BEGIN_SRC R
  getSegment.class.and.features.Within.Polygon <- function(SegmentFeatureDF,
                                                           training.sp,
                                                           seg.tiles.dir,
                                                           seg.params){
      seg.files <- list.files(seg.tiles.dir, pattern = str_c(seg.params,".tif$"), full.names = T)
                                          # find number of pixels in each segment
      n.pixels.per.seg <- foreach(seg.file = seg.files, .combine = "rbind") %do% {
          seg <- stack(seg.file)
          s.df <- as.data.frame(seg) %>%
              gather(key = tile.name, value = segment.id) %>%
              group_by(segment.id, tile.name) %>%
              summarize(n.pixels.per.seg = n())
      }
                                          # find number of pixels in each segment are in a polygon
      n.pixels.per.seg.in.polygon <- foreach(seg.file = seg.files, .combine = "rbind") %do% {
          seg <- stack(seg.file)
          a <- raster::extract(seg, as(training.sp,"SpatialPolygons"), df = T)
          if(length(a) > 1) {
              a <- a %>%
                  gather(key = tile.name, value = segment.id, -ID) %>%
                  rename(polygon.id = ID) %>%
                  group_by(polygon.id, tile.name, segment.id) %>%
                  summarize(n.pixels.per.seg.in.polygon = n())
          }
      }
                                          # get pct of segment in a polygon,
                                          # filter segments that have more than 50%,
                                          #join Class information from polygons
      if(!is.null(n.pixels.per.seg.in.polygon)) {
          n.pixels <- left_join(n.pixels.per.seg.in.polygon,n.pixels.per.seg) %>%
              mutate(pct.seg.in.polygon = n.pixels.per.seg.in.polygon/n.pixels.per.seg) %>%
              filter(pct.seg.in.polygon >= .5) %>%
              left_join(.,training.sp@data, by = c("polygon.id" = "id")) %>%
              ungroup() %>%
              mutate(tile.name = str_extract(tile.name, "X[0-9]+_"),
                     tile.name = str_sub(tile.name,2,-2)) %>%
              mutate(segment = segment.id)

          left_join(n.pixels, SegmentFeatureDF) %>%
              dplyr::select(-segment,
                            -segment.id,
                            -tile.name,
                            -polygon.id,
                            -n.pixels.per.seg,
                            -n.pixels.per.seg.in.polygon,
                            -pct.seg.in.polygon) %>%
              filter(complete.cases(.))
      }
  }

                                          # returns dataframe of values of pixels within polygon
  getPixel.Class.and.Coords.Within.Polygon <- function(PixelFeatureDF,
                                                       training.sp) {
      xy <- select(PixelFeatureDF,x,y) %>% data.frame
      PixelFeatureDF <- data.frame(PixelFeatureDF)
      coordinates(PixelFeatureDF) <- xy
      proj4string(PixelFeatureDF) <- utm16

      training.sp <- spTransform(training.sp,utm16)

      pts.in.poly <- over(PixelFeatureDF,training.sp)
      PixelFeatureDF@data <- cbind(PixelFeatureDF@data, pts.in.poly)
      PixelFeatureDF <- PixelFeatureDF[which(complete.cases(pts.in.poly)),]
      PixelFeatureDF@data
  }

                                          # this is an old way
  create.df.toBuildModel.fromTrainingPolygons.and.SegmentFeatureDFs <- function(manuallyClassifiedPolygondir,
                                                                                image.dir,
                                                                                segment.feature.df.appendage = segment.feature.df.name.append,
                                                                                modelBuildingData.name = "modelBuildingData.rds") {

      segment.feature.df.appendage = segment.feature.df.name.append

                                          # list shapefiles with manually classified polygons
      trainingShapefiles <- list.files(manuallyClassifiedPolygondir) %>%
          str_sub(.,end = nchar(.)-4) %>%
          unique()

                                          # load training data from shapefiles into memory
      shapelist.data <- lapply(trainingShapefiles, function(shp) {
          readOGR(dsn = manuallyClassifiedPolygondir, layer = shp)@data %>%
                                                                     na.omit() %>%
                                                                     rename(zone = DN) %>%
                                                                     filter(Class != "N")
      })

      names(shapelist.data) <- trainingShapefiles


                                          # list .rds segment feature dataframe files
      segmentFeatureDF.rds.files <- list.files(image.dir, full.names = T) %>%
          str_extract(pattern = str_c(".*",segment.feature.df.appendage,".rds")) %>%
          na.omit()

      trainingData <- list()

      foreach(j = seq_along(shapelist.data)) %do% {
          d <- readRDS(segmentFeatureDF.rds.files[j])
          trainingData[[j]] <- left_join(shapelist.data[[j]],d, by = c("zone" = "segment"))
      }

      trainingData <- bind_rows(trainingData) %>%
          filter(Class != "N")

      saveRDS(trainingData, file = str_c(image.dir, "/",modelBuildingData.name))

  }

#+END_SRC
** Build and Save Models
#+BEGIN_SRC R
  Build.and.Save.models <- function(
                                    dir = dd.training.dir,
                                    modelBuildingData = ModelBuildingRDS,
                                    models.dir = Models.dir,
                                    image.name){

      dat <- readRDS(paste0(dir,"/",modelBuildingData)) %>%
          as.data.frame()

      image.and.segmentation.stem = str_replace(modelBuildingData, ModelBuilding.appendage,"")

      names <- colnames(dat)
      names <- str_replace(names, "\\(",".")
      names <- str_replace(names, "\\)",".")
      names <- str_replace(names, "\\:",".")
      colnames(dat) <- names

      dat_G <- dat %>%
          mutate(Class = as.character(Class),
                 Class = ifelse(Class == "g", Class, "o"))

      dat_I <- dat %>%
          mutate(Class = as.character(Class),
                 Class = ifelse(Class == "i", Class, "o"))

      dat_T <- dat %>%
          mutate(Class = as.character(Class),
                 Class = ifelse(Class == "t", Class, "o"))

                                          # Create Tasks
      all.task <- makeClassifTask(id = paste0(image.name,"_all"), data = dat, target = "Class")
      grass.task <- makeClassifTask(id = paste0(image.name,"_grass"), data = dat_G, target = "Class")
      impervious.task <- makeClassifTask(id = paste0(image.name,"_impervious"), data = dat_I, target = "Class")
      tree.task <- makeClassifTask(id = paste0(image.name,"_tree"), data = dat_T, target = "Class",positive = "t")

      task.list <- list(all = all.task, grass = grass.task, impervious = impervious.task, tree = tree.task)

                                          # Make Learners
      RF_prob <- makeLearner(id = "rf_prob","classif.randomForest", predict.type = "prob", fix.factors.prediction = TRUE)
      RF_response <- makeLearner(id = "rf_resp", "classif.randomForest", predict.type = "response", fix.factors.prediction = TRUE)
      SVM_response <- makeLearner(id = "svm_resp", "classif.svm", predict.type = "response", fix.factors.prediction = TRUE)

      learner.list <- list(RF_prob = RF_prob, RF_response = RF_response, SVM_response = SVM_response)

                                          # Train Learners on Tasks, Make models
                                          #         cl<-makeCluster(cores)
                                          #         registerDoParallel(cl)

      models <- foreach(tsk = task.list, .packages = "mlr") %do% {
          foreach(lnr = learner.list) %do% {
              mod <- train(lnr, tsk)
              mod
          }
      }
      saveRDS(models, file = paste0(models.dir,"/",image.and.segmentation.stem, models.appendage))
  }

#+END_SRC

** Classify Raster
#+BEGIN_SRC R

  classify.segmented.raster <- function(segment.feature.df.dir,
                                        segment.dir,
                                        model.dir,
                                        model.name.rds = "models",
                                        segment.feature.appendage = segment.feature.df.name.append,
                                        segmentation.appendage = segment.tile.name.append,
                                        segmentation.prms,
                                        classify.out.dir,
                                        tile.name = i) {
      df <- readRDS(paste0(segment.feature.df.dir,"/",tile.name,segment.feature.appendage))
      models <-readRDS(paste0(model.dir,"/",model.name.rds))
      umod <- unlist(models, recursive = F)
      seg.path <- paste0(segment.dir,"/",tile.name,segment.tile.name.append)
      seg <- raster(seg.path)
                                          #       dfRowsWithNA <- which(is.na(df[,2]))
      complete.df <- df[complete.cases(df),] # svm can't predict with NAs
      lapply(umod, function(mod) {
          pred <- predict(mod, newdata = complete.df)
          response <- factor(as.character(pred$data$response), levels = c("g","i","t","o"))
          m <- cbind(zone = complete.df$segment, response)
          m <- left_join(as.data.frame(df["segment"]), as.data.frame(m), by = c("segment" = "zone"))
          r <- reclassify(seg, m)
                                          #        x <- data.frame(ID = 1:4, LandCover = c("G","I","T","O")) %>%
                                          #            filter(LandCover %in% levels(factor(response)))
                                          #        levels(r) <- x
          if (ncol(pred$data) > 2) {
              prob <- (pred$data[,grep("prob.*", x = colnames(pred$data))]) # get columns that contain probabilities
              ProbOfClass <- apply(prob, MARGIN = 1, FUN = max)
              m <- cbind(segment = df$segment, ProbOfClass)
              m <- left_join(as.data.frame(df["segment"]), as.data.frame(m))
              p <- reclassify(seg, m)
              r <- stack(r,p)
          }
          path <- paste0(segment.dir,"/",ClassifiedTilesDirName,"/",tile.name,"_",segmentation.prms,"_",mod$task.desc$id,"_",mod$learner$id,".tif")
          writeRaster(r, path, overwrite=TRUE)
          print(path)
      })
  }


  classify.pixel.raster <- function(tile.dir = dd.accuracy.dir,
                                    tile.name,
                                    pixelFeatureDF.appendage = pixel.feature.df.appendage,
                                    model.dir = Models.dir,
                                    model.rds,
                                    seg.prms = "Pixel") {
      ras <- stack(str_c(tile.dir,"/",tile.name,".tif"))
      pix.mods <- readRDS(str_c(model.dir,"/",model.rds))
      pix.umods <- unlist(pix.mods, recursive = F)

      pix.feature.df <- readRDS(str_c(tile.dir,"/",tile.name,pixelFeatureDF.appendage,".rds"))

      if(!is.null(pix.feature.df$y)) {
          pix.feature.df <- dplyr::select(pix.feature.df, -x, -y)
      }

                                          # I set NA's to 0 here.  Not the best choice.  Not sure why they exist.
                                          # imputing to mean would probably be better

      pix.feature.df <- as.matrix(pix.feature.df)

      pix.feature.df[which(is.na(pix.feature.df))] <- 0

      pix.feature.df <- as.data.frame(pix.feature.df)


      lapply(pix.umods, function(pix.mod) {
          pred <- predict(pix.mod, newdata = pix.feature.df)
          a <- ras[[1]]
          values(a) <- pred$data$response
          path <- paste0(tile.dir,"/",ClassifiedTilesDirName,"/",tile.name,"_",seg.prms,"_",pix.mod$task.desc$id,"_",pix.mod$learner$id,".tif")
          writeRaster(a, path, overwrite = T)
          print(path)
      })
  }








#+END_SRC

#+BEGIN_SRC R :results graphics :file figs/pixClss.png
                                          #plot(a)
#+END_SRC

** Calculate Percent Cover in Classified Tiles
#+BEGIN_SRC R

  get.prcnt.class <- function(points,r) {
      r <- crop(r,points)  # should I do a mask instead??
      g <- cellStats(r == 1, stat = sum)
      im <- cellStats(r == 2, stat = sum)
      tr <- cellStats(r == 3, stat = sum)
      o <-  cellStats(r == 4, stat = sum)
      totC <- ncell(r)
      return(c(pct_g_pred = g/totC, pct_i_pred = im/totC, pct_t_pred = tr/totC, pct_o_pred = o/totC))
  }


  get_area_convexHull <- function(points) {
      ch <- chull(coordinates(points))
      coords <- coordinates(points)[c(ch,ch[1]),]
      poly <- SpatialPolygons(list(Polygons(list(Polygon(coords)),ID = 1)))
      gArea(poly)
  }



  calculate.percent.cover.in.classified.tile <- function(pts,
                                                         tile.dir = dd.accuracy.classified.dir,
                                                         tile.pth,
                                                         n.rows.and.columns.subset,
                                                         mod = 1,
                                                         mad.grid.id.pattern = "mad-[0-9]+m-[0-9]+",
                                                         grid.pattern = "[a-zA-Z]{3}-[0-9]+m-[0-9]+_",
                                                         image.pattern = "[a-zA-Z]{5}[a-zA-Z]+",
                                                         target.pattern = "all|grass|impervious|tree",
                                                         model.pattern = "rf_prob|rf_resp|svm_resp",
                                                         seg.prms = "N-[0-9]+_C-[0-9]+|Pixel"
                                                         ) {
      tile.nm <- basename(tile.pth)


      pts.sub <- pts@data  %>%
          filter.by.row.and.col(.,n.rows.and.columns.subset, mod = mod)

      coordinates(pts.sub) <- ~ crds_x1 + crds_x2

      proj4string(pts.sub) <- utm16
      tile.unique.name <- str_extract(tile.pth, mad.grid.id.pattern)
      pts.at.grid <- pts.sub[which(pts.sub@data$unq__ID == tile.unique.name),]
      tile <- raster(tile.pth, proj4string = "+init:epsg=32616")

      area.pts <- get_area_convexHull(pts.at.grid)

      if(!is.null(raster::intersect(extent(tile),bbox(pts.at.grid)))) {

          get.prcnt.class(pts.at.grid,tile) %>%
              t() %>%
              as.data.frame() %>%
              mutate(grid.tile.target.model = tile.nm,
                     grid = str_sub(str_extract(grid.tile.target.model, grid.pattern),1,-2),
                     image =  str_extract(grid.tile.target.model, image.pattern),
                     target.cover = str_extract(grid.tile.target.model, target.pattern),
                     model =  str_extract(grid.tile.target.model, model.pattern),
                     n.points = n.rows.and.columns.subset * n.rows.and.columns.subset,
                     area = area.pts,
                     seg.params = str_extract(grid.tile.target.model, seg.prms),
                     target.type = ifelse(target.cover == "all", "multinomial", "binomial"))
      }
  }

#+END_SRC

** Calculate Percent Cover of Grids, subsetted
#+BEGIN_SRC R
  filter.by.row.and.col <- function(df,nrow.and.col, mod) {
      nrow <-df %>%
          group_by(unq__ID) %>%
          summarize(nrow = max(row))

      df <- left_join(df,nrow)

      df %>%
          filter(nrow >= nrow.and.col,   # remove grids that have fewer than the number of rows & columns
                 row <= nrow.and.col,    # remove rows greater than the number we are interested in
                 col <=nrow.and.col,   # same for columns as rows
                 row %% mod == 0,
                 col %% mod == 0)
  }

  add.n.pts.per.grid <- function(df){
      n.pts<-df %>%
          group_by(unq__ID) %>%
          summarize(n.points = n())

      left_join(df,n.pts)
  }


  get.pct.cvr.typ <- function(df) {
      df %>%
          group_by(unq__ID, cvr_typ,n.points, area) %>%
          summarize(number = n()) %>%
          ungroup() %>%
          mutate(google.truth.pct.cover = number/n.points) %>%
          dplyr::select(-number)
  }

  combine.classes.to.g.i.t.o <- function(df) {

      df %>%
          mutate(cvr_typ = as.character(cvr_typ),
                 cvr_typ = ifelse(cvr_typ == "s",
                                  "i",
                                  cvr_typ),
                 cvr_typ = ifelse(cvr_typ != "g" &
                                  cvr_typ != "i" &
                                  cvr_typ != "t", "o", cvr_typ)) %>%
          group_by(unq__ID, cvr_typ, n.points, area) %>%
          summarize(google.truth.pct.cover = sum(google.truth.pct.cover))

  }


  calc.binomial.pct.cvrs <- function(df) {

      out <- foreach(target.cvr.type = c("g","i","t")) %do%{
          df %>%
              mutate(cvr_typ = ifelse(cvr_typ == target.cvr.type, cvr_typ, "o")) %>%
              group_by(unq__ID, n.points, cvr_typ) %>%
              summarize(pct.cover = sum(pct.cover)) %>%
              mutate(target.type = "binomial",
                     target.cover = target.cvr.type,
                     target.cover = ifelse(target.cover == "g", "grass",
                                    ifelse(target.cover == "t", "tree",
                                           "impervious"))) %>%
              spread(key = cvr_typ, value = pct.cover)
      }
      out <- bind_rows(out)
      out %>%
          rename(pct.g.googleEarth = g, pct.i.googleEarth = i, pct.t.googleEarth = t, pct.o.googleEarth = o)
  }



  get.area.convexHull <- function(x_coord, y_coord) {
      m <- matrix(c(x_coord, y_coord), ncol = 2)
      ch <- chull(m)
      coords <- m[c(ch,ch[1]),]
      poly <- SpatialPolygons(list(Polygons(list(Polygon(coords)),ID = 1)))
      gArea(poly)
  }



  calc.pct.cvr.for.grid.subset <- function(df,
                                           n.rows.and.columns.for.subset=20,
                                           mod,
                                           gridID = "unq__ID") {


      df <- filter.by.row.and.col(df, n.rows.and.columns.for.subset, mod) %>%
          add.n.pts.per.grid() %>%
          group_by_(gridID)


      area.df <- df %>%
          summarize(area = get.area.convexHull(crds_x1, crds_x2))

      df <- left_join(df, area.df)


      df <- df %>%
          get.pct.cvr.typ() %>%
          combine.classes.to.g.i.t.o() %>%
                                          #               ungroup() %>%
                                          #               dplyr::select(-n.points) %>%
          spread(., key = cvr_typ, value = google.truth.pct.cover, fill = 0)

                                          #         df[is.na(df)] <- 0

      df.multnm <- df %>%
          mutate(target.type = "multinomial") %>%
          rename(pct.g.googleEarth = g, pct.i.googleEarth = i, pct.t.googleEarth = t) %>%
          mutate(target.cover = "all")

      if(!is.null(df.multnm$o)) { df.multnm <- rename(df.multnm, pct.o.googleEarth = o)}

      df <- df %>%
          gather(key = cvr_typ, value = pct.cover, -unq__ID, -n.points)

      df.binm <- df %>%
          calc.binomial.pct.cvrs()


      df.out <- bind_rows(df.binm, df.multnm)
      return(df.out)
  }



#+END_SRC

** Point-wise error functions
#+BEGIN_SRC R
  calcErrorAllMultinomial <-  function(pts, tile, Pixel = F) {
      classification <- raster::extract(classified.tile, pts)
      if(Pixel == T) {
          lvls <- levels(classified.tile)[[1]]
          classification <- mapvalues(classification, from = lvls[,1], to = as.character(lvls[,2]))
      } else {
          classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
      }
      google = pts@data$cvr_typ
      overall.error <- 1 - mean(classification == google)
      pct.grass.classified.as.other <- 1 - mean(classification[which(google == "g")] == google[which(google == "g")])
      pct.impervious.classified.as.other <- 1 - mean(classification[which(google == "i")] == google[which(google == "i")])
      pct.tree.classified.as.other <- 1 - mean(classification[which(google == "t")] == google[which(google == "t")])
      error <- c(overall.error = overall.error,
                 pct.grass.classified.as.other = pct.grass.classified.as.other,
                 pct.impervious.classified.as.other = pct.impervious.classified.as.other,
                 pct.tree.classified.as.other = pct.tree.classified.as.other)
      return(error)
  }

  calcErrorBinomial <-  function(pts, tile, target, Pixel = F) {
      classification <- raster::extract(classified.tile, pts)
      if(Pixel == T) {
          lvls <- levels(classified.tile)[[1]]
          classification <- mapvalues(classification, from = lvls[,1], to = as.character(lvls[,2]))
      } else {
          classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
      }
      classification <- ifelse(classification == target, classification, "o")
      google <- pts@data$cvr_typ
      google <- ifelse(google == target, google, "o")
      overall.error <- 1 - mean(classification == google)
      pct.grass.classified.as.other <- 1 - mean(classification[which(google == "g")] == google[which(google == "g")])
      pct.impervious.classified.as.other <- 1 - mean(classification[which(google == "i")] == google[which(google == "i")])
      pct.tree.classified.as.other <- 1 - mean(classification[which(google == "t")] == google[which(google == "t")])
      error <- c(overall.error = overall.error,
                 pct.grass.classified.as.other = pct.grass.classified.as.other,
                 pct.impervious.classified.as.other = pct.impervious.classified.as.other,
                 pct.tree.classified.as.other = pct.tree.classified.as.other)
      return(error)
  }




  calcConfusionMat <- function(pts, tile) {
      classification <- raster::extract(classified.tile, pts)
      classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
      table(classification, google = pts@data$cvr_typ)
  }


#+END_SRC
** Plot points on classifed tile

#+BEGIN_SRC R
      pts.on.classified.tile.plot <- function(pts, classified.tile, target = NULL) {
          if(target == "a") {
              pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
              pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, fill = cvr_typ), shape = 21, color = "black", size =2, stroke = .2)
          } else {
              pts@data <- pts@data %>%
                  mutate(cvr_typ = ifelse(cvr_typ == target, cvr_typ, "o"))
                  pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
          }
          r.df <- as.data.frame(classified.tile, xy = T)
          names(r.df) <- c("x","y","cvr_typ")
          r.df <- r.df %>%
              mutate(cvr_typ = mapvalues(cvr_typ, from = c(1,2,3,4), to = c("g","i","t","o")))
          pxls.plot <- ggplot() + geom_raster(data = r.df, aes(x = x, y = y, fill = cvr_typ))
          title <- ggtitle(label = names(classified.tile))
          UTC_pal <- c(g = "#ffff99", i = "#f0027f", t = "#7fc97f", o = "#666666")
          pxls.plot + pts.plot + title + scale_fill_manual(values = UTC_pal)+ scale_color_manual(values = UTC_pal) +
  coord_equal()
      }



#+END_SRC

* Functions old from classifying every urban area
:PROPERTIES:
:ARCHIVE_TIME: 2016-07-13 Wed 12:25
:ARCHIVE_FILE: /ssh:erker@krusty:/home/erker/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Classify Every Urban Area in the State
:ARCHIVE_CATEGORY: utc
:END:

** Extract Name from path
#+BEGIN_SRC R
  extract.name.from.path <- function(path) {
      str_extract(basename(path), "[A-Za-z0-9_]*.") %>%
          str_sub(.,1,-2)
  }
#+END_SRC

** Reproject Shapefile to Image Coordinate Reference System
#+BEGIN_SRC R
  Reproject_Shapefile_to_Image_CRS <- function(shapefile.dsn,
                                               shapefile.layer,
                                               image.path,
                                               shapefile.out.dsn) {
      r <- stack(image.path)
      shapefile <- readOGR(shapefile.dsn, shapefile.layer)
      shapefile.WimageCRS <- spTransform(shapefile, crs(r))
      image.name <- extract.name.from.path(image.path)
      shapefile.layer  <- str_c(image.name,"_",shapefile.layer)
      writeOGR(shapefile.WimageCRS, shapefile.out.dsn, shapefile.layer, driver = "ESRI Shapefile", overwrite =T)
  }
#+END_SRC

** Crop image to each Shapefile polygon
#+BEGIN_SRC R
  Crop_image_to_each_Shapefile_polygon <- function(shapefile.dsn,
                                                   shapefile.layer,
                                                   image.path,
                                                   cores,
                                                   output.dir)  {
      image.name <- extract.name.from.path(image.path)
      shape <- readOGR(shapefile.dsn, str_c(image.name,"_",shapefile.layer))
      polygons <- as(shape, "SpatialPolygons")

      image <- stack(image.path)

      cl <- makeCluster(cores)
      registerDoParallel(cl)

      foreach (i = seq_along(polygons),
               .packages = c("raster")) %dopar% {
                   r <- image
                   r <- crop(r, polygons[i])
                   writeRaster(r, paste0(output.dir,"/",image.name,"-",i,".tif"),
                               overwrite = T)
               }
  }

#+END_SRC

** Crop image to regions around shapefile points
#+BEGIN_SRC R

                                          # assign the polygon name to the points.
  give_polygons_attributes_of_first_point_within <- function(points,
                                                             polygons){
      if (length(points@data$row) >1) {
          points <- points[points@data$row ==1 & points@data$col ==1 ,]
      }
      po <- gIntersects(points, polygons, byid=TRUE)
      out <- foreach(polygon.number = seq_along(polygons), .combine = "rbind") %do% {
          first.point.data <- points[po[polygon.number,],]@data %>%
              slice(1)
          pd <- as(polygons[polygon.number], "SpatialPolygonsDataFrame")
          pd@data <- first.point.data
          pd
      }
  }

  Crop_image_to_regions_around_points_nameBygrid<- function(shapefile.dsn,
                                                            shapefile.layer,
                                                            image.path,
                                                            cores,
                                                            output.dir,
                                                            column.name = "unq__ID",
                                                            point.buffer.size = 4,
                                                            polygon.buffer.size = 15)  {
      image.name <- extract.name.from.path(image.path)
      points <- readOGR(shapefile.dsn,str_c(image.name,"_",shapefile.layer))
      box <- gBuffer(points, width = point.buffer.size, byid = F)
      box <- disaggregate(box)

      polygons <- as(box, "SpatialPolygons")

      polygons <- give_polygons_attributes_of_first_point_within(points,polygons)

      image <- stack(image.path)

      image.extent <- as(extent(image), "SpatialPolygons")
      proj4string(image.extent) <- proj4string(image)

      polygons.in.image <- foreach(i = seq_along(polygons),.combine = "c") %do% {
          gIntersects(polygons[i,],image.extent)
      }

      polygons <- polygons[polygons.in.image,]

      cl <- makeCluster(cores)
      registerDoParallel(cl)

      foreach (k = seq_along(polygons),
               .packages = c("raster","rgeos")) %dopar% {
                   r <- image
                   poly <- gBuffer(polygons[k,],width = polygon.buffer.size, byid = T)
                   r <- crop(r, poly)
                   tile.id <- polygons@data[k,column.name]
                   writeRaster(r, paste0(output.dir,"/",image.name,"_",tile.id,".tif"),
                               overwrite = T)
               }
  }

                                          #  shapefile.dsn = grid.accuracy.region.imageCRS.dsn
                                          #  shapefile.layer = grid.accuracy.region.layer,
                                          #  output.dir = image.cropped.to.grid.accuracy.dir


  Crop_image_to_regions_around_points <- function(shapefile.dsn,
                                                  shapefile.layer,
                                                  image.path,
                                                  cores,
                                                  output.dir)  {

      points <- readOGR(shapefile.dsn, shapefile.layer)
      box <- gBuffer(points, width = 8)
      box <- disaggregate(box)

      polygons <- as(box, "SpatialPolygons")

      image <- stack(image.path)

      cl <- makeCluster(cores)
      registerDoParallel(cl)

      foreach (i = seq_along(polygons),
               .packages = c("raster")) %dopar% {
                   r <- image
                   r <- crop(r, polygons[i])
                   writeRaster(r, paste0(output.dir,"/",i,".tif"),
                               overwrite = T)
               }
  }

#+END_SRC

** Make new ratio bands from image
#+BEGIN_SRC R
  ratio <- function(image_w4bands, numerator_bandNumber) {
      r <- image_w4bands[,,numerator_bandNumber,drop = F] / sum(image_w4bands)
      return(r)
  }

  ndvi_nodrop <- function(image_w4bands,red_bandnumber,nir_bandnumber,...) {
      red_band <- image_w4bands[[red_bandnumber]]
      nir_band <- image_w4bands[[nir_bandnumber]]
      ndvi <- (nir_band - red_band)/(nir_band + red_band)
      return(ndvi)
  }

  add.ratios.ndvi <- function(tile.dir,
                              tile.name,
                              out.tile.name.append = ratio.tile.name.append,
                              band.names = c("blue","green","red","nir"),
                              red.band.number = 3,
                              nir.band.number = 4) {

      in.tile.path <- str_c(tile.dir, "/", tile.name, ".tif")
      tile <- stack(in.tile.path)
      names(tile) <- band.names

                                          # Create a ratio image for each band
      ratio.brick <- ratio(tile)
      ratio.brick <- ratio.brick*200 # rescale ndvi to save as 'INT1U'
      names(ratio.brick) <- paste0(band.names,rep("_ratio",times = 4))
      ndvi <- ndvi_nodrop(tile, red.band.number, nir.band.number)
      ndvi <- (ndvi+1)*100 # rescale ndvi to savep as 'INT1U'

                                          # if tile is not scaled 0-255, do it here
      if (getRasterMax(tile) > 255) {
          min <- getRasterMin(tile)
          max <- getRasterMax(tile)
          tile <- rescale.0.255(tile,min,max)
      }

      ratio.tile <- raster::stack(tile, ratio.brick, ndvi)
      writeRaster(ratio.tile,
                  filename = paste0(tile.dir,"/",tile.name,out.tile.name.append, ".tif"),
                  overwrite = T,
                  datatype = 'INT1U')
  }
#+END_SRC

** Image PCA
#+BEGIN_SRC R
  getRasterMin <- function(t) {
      return(min(cellStats(t, stat = "min")))
  }

  getRasterMax <- function(t) {
      return(max(cellStats(t, stat = "max")))
  }

  rescale.0.255 <- function(raster,
                            min,
                            max) {
                                (raster - min)/(max-min) * 255
  }

  image.pca <- function(image.name,
                        pca.model.name.append = pca.model.name.appendage,
                        tile.dir,
                        tile.name,
                        in.image.appendage = ratio.tile.name.append,
                        out.image.appendage = pca.tile.name.append,
                        band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi"),
                        comps.to.use = c(1,2,3),
                        pca.dir = dd.pca.dir) {


      out.path <- str_c(tile.dir, "/", tile.name, out.image.appendage, ".tif")

      s <- stack(str_c(tile.dir, "/", tile.name, in.image.appendage,".tif"))
      names(s) <- band.names

      pca.model <- readRDS(str_c(pca.dir,"/",image.name,pca.model.name.append))

      r <- predict(s, pca.model, index = comps.to.use)

      min.r <- getRasterMin(r)
      max.r <- getRasterMax(r)
      rescaled.r <- rescale.0.255(r, min.r, max.r)
      writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')
  }



  make.and.save.pca.transformation <- function(tile.dir,
                                               image.name,
                                               pca.model.name.append = pca.model.name.appendage,
                                               max.sample.size = 10000,
                                               core.num = cores,
                                               band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {

      tile.paths <- list.files(str_c(tile.dir), pattern = str_c(image.name,".*_with_ratios.tif$"), full.names = T)

      tile.names <- basename(tile.paths)

      cl <- makeCluster(core.num)
      registerDoParallel(cl)

      sr <- foreach (i = seq_along(tile.names), .packages = c("raster"), .combine ="rbind") %dopar% {
          tile <- stack(tile.paths[i])
          s <- sampleRandom(tile, ifelse(ncell(tile) > max.sample.size ,max.sample.size, ncell(tile)))
      }

      colnames(sr) <- band.names

                                          # Perform PCA on sample
      pca <- prcomp(sr, scale = T)
      saveRDS(pca,paste0(tile.dir,"/",image.name,pca.model.name.append))
      return(pca)
  }


  image.pca.forWholeState <- function(pca.model.name.append = pca.model.name.appendage,
                                      tile.dir,
                                      tile.name,
                                      in.image.appendage = ratio.tile.name.append,
                                      out.image.appendage = pca.tile.name.append,
                                      band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi"),
                                      comps.to.use = c(1,2,3),
                                      pca.transform) {


      out.path <- str_c(tile.dir, "/", tile.name, out.image.appendage, ".tif")

      s <- stack(str_c(tile.dir, "/", tile.name, in.image.appendage,".tif"))
      names(s) <- band.names

      r <- predict(s, pca.transform, index = comps.to.use)

      min.r <- getRasterMin(r)
      max.r <- getRasterMax(r)
      rescaled.r <- rescale.0.255(r, min.r, max.r)
      writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')
  }



  ## image.dir <- image.cropped.to.training.dir
  ## image.name <- 9
  ##                         in.image.appendage = ratio.tile.name.append
  ##                         out.image.appendage = pca.tile.name.append
  ##                         band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")
  ##                         max.sample.size = 10000
  ##                         comps.to.use = c(1,2,3)

  ##       out.path <- str_c(image.dir, "/", image.name, out.image.appendage, ".tif")

  ##       s <- stack(str_c(image.dir, "/", image.name, in.image.appendage,".tif"))
  ##       names(s) <- band.names

  ##       sr <- sampleRandom(s, ifelse(ncell(s) > max.sample.size, max.sample.size, ncell(s)))
  ##       pca <- prcomp(sr, scale = T)

  ##       r <- predict(s, pca, index = comps.to.use)

  ##       min.r <- getRasterMin(r)
  ##       max.r <- getRasterMax(r)
  ##       rescaled.r <- rescale.0.255(r, min.r, max.r)
  ##       writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')









                                          # Function takes raster stack, samples data, performs pca and returns stack of first n_pcomp bands
  ## predict_pca_wSampling_parallel <- function(stack, sampleNumber, n_pcomp, nCores = detectCores()-1) {
  ##     sr <- sampleRandom(stack,sampleNumber)
  ##     pca <- prcomp(sr, scale=T)
  ##     beginCluster()
  ##     r <- clusterR(stack, predict, args = list(pca, index = 1:n_pcomp))
  ##     endCluster()
  ##     return(r)
  ## }
#+END_SRC

** polygonize segment raster with gdal and add Class to shapefile

#+BEGIN_SRC R
  gdal_polygonizeR <- function(x, outshape=NULL, gdalformat = 'ESRI Shapefile',
                               pypath=NULL, readpoly=TRUE, quiet=TRUE) {
      if (isTRUE(readpoly)) require(rgdal)
      if (is.null(pypath)) {
          pypath <- Sys.which('gdal_polygonize.py')
      }
      if (!file.exists(pypath)) stop("Can't find gdal_polygonize.py on your system.")
      owd <- getwd()
      on.exit(setwd(owd))
      setwd(dirname(pypath))
      if (!is.null(outshape)) {
          outshape <- sub('\\.shp$', '', outshape)
          f.exists <- file.exists(paste(outshape, c('shp', 'shx', 'dbf'), sep='.'))
          if (any(f.exists))
              stop(sprintf('File already exists: %s',
                           toString(paste(outshape, c('shp', 'shx', 'dbf'),
                                          sep='.')[f.exists])), call.=FALSE)
      } else outshape <- tempfile()
      if (is(x, 'Raster')) {
          require(raster)
          writeRaster(x, {f <- tempfile(fileext='.asc')})
          rastpath <- normalizePath(f)
      } else if (is.character(x)) {
          rastpath <- normalizePath(x)
      } else stop('x must be a file path (character string), or a Raster object.')
      system2('python', args=(sprintf('"%1$s" "%2$s" -f "%3$s" "%4$s.shp"',
                                      pypath, rastpath, gdalformat, outshape)))
      if (isTRUE(readpoly)) {
          shp <- readOGR(dirname(outshape), layer = basename(outshape), verbose=!quiet)
          return(shp)
      }
      return(NULL)
  }


  polygonize.and.add.Class <- function(image.dir,
                                       image.name,
                                       segment.appendage = segment.tile.name.append,
                                       no.class = "N") {
      seg <- raster(paste0(image.dir,"/",image.name,segment.appendage,'.tif'))
      segPoly <- gdal_polygonizeR(seg)
      segPoly$Class <- no.class
      writeOGR(obj = segPoly,
               dsn = paste0(image.dir,"/",image.name),
               layer = paste0(image.name,segment.appendage),
               driver = "ESRI Shapefile",
               overwrite = T)
  }






#+END_SRC

** other Functions
#+BEGIN_SRC R

  Water_Urban_mask <- function(tile.path, tile.name, urban, water) {
                                          # load image tile
      tile <- stack(tile.path)
                                          # get extent image and make sp object
      et <- as(extent(tile), "SpatialPolygons")
      proj4string(et) <- "+init=epsg:26916"
                                          # Mask out non-urban areas
      if(gContainsProperly(urban,et) & !gIntersects(water,et)){
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      } else if (gContainsProperly(urban,et) & gIntersects(water,et)) {
          tile <- mask(tile, water, inverse = T)
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      } else if (gIntersects(urban, et) & !gIntersects(water,et)) {
          tile <- mask(tile, urban)
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      } else if (gIntersects(urban, et) & gIntersects(water,et)) {
          tile <- mask(tile, urban)
          tile <- mask(tile, water, inverse = T)
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      }
  }

  Crop_mask <- function(tile.path, tile.name, CDL_stack, n_years){

      tile <- stack(tile.path)
      crops <- crop(CDL_stack, tile)

                                          # These are the values in the CDL that correspond to non crop cover types and not water
      NonCroppedValues <- c(0,63:65, 81:83, 87:88, 112, 121:124, 131, 141:143, 152, 176, 190, 195)
                                          # open water is 111

      NonCroppedValues <- c(0,63:65, 81:83, 87:88, 112, 121:124, 131, 141:143, 152, 176, 190, 195)
                                          # open water is 111. I don't include it in the above list so that it gets masked

                                          # I'm going to add 37, Other Hay/Non-alfalfa, to the non crop cover types
      NonCroppedValues <- c(NonCroppedValues, 37)
                                          # I'm going to add 36, Alfalfa, to the non crop cover types
      NonCroppedValues <- c(NonCroppedValues, 36)

                                          # find cells that have been assigned crop all three years
      crops[crops %in% NonCroppedValues] <- 0
      crops[!(crops %in% NonCroppedValues)] <- 1
      cropsum <- overlay(crops, fun = sum)

      dis.cropsum <- disaggregate(cropsum, fact = 20)
      dis.cropsum <- resample(dis.cropsum, tile, "ngb")
      masked_tile <- mask(tile, dis.cropsum, maskvalue = n_years)

                                          #               Save Image
      writeRaster(masked_tile, paste0(crop.masked.tiles.directory, "/", tile.name), overwrite = T)
  }








#+END_SRC

** Make Pixel Feature DF
#+BEGIN_SRC R
  Create.Pixel.Feature.df <- function(tile.dir,
                                      tile.name,
                                      tile.appendage = ratio.tile.name.append,
                                      Pixel.DF.appendage = pixel.feature.df.appendage,
                                      band.names = band.names.wRatios) {
      r <- stack(paste0(tile.dir,"/",tile.name,tile.appendage,".tif"))
      names(r) <- band.names
      r.df <- as.data.frame(r, xy=T)
      saveRDS(r.df, file = paste0(tile.dir,"/", tile.name, Pixel.DF.appendage, ".rds"))
  }



  ## Create.Pixel.Feature.df<- function(raster.list,
  ##                                    band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {
  ##     r.df.list <- lapply(raster.list, function(r) {
  ##                             names(r) <- band.names
  ##                             as.data.frame(r, xy=T)
  ##            })
  ##     bind_rows(r.df.list)
  ## }

  Create.Pixel.Feature.df.noRowbind<- function(raster.list,
                                               band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {
      r.df.list <- lapply(raster.list, function(r) {
          names(r) <- band.names
          as.data.frame(r, xy=T)
      })
      r.df.list
  }


  Create.Pixel.Feature.df.foreachTile <- function(dir = image.cropped.to.grid.accuracy.dir[i],
                                                  base_pattern = "mad-[0-9]+m-[0-9]+_with_ratios.tif",
                                                  band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {

      file.list <- list.files(dir, full.names = T) %>%
          str_extract(., paste0(".*",base_pattern)) %>%
          na.omit() %>%
          unique()

      r.df.list <- lapply(file.list, function(r) {
          ras <- stack(r)
          names(ras) <- band.names
          ras.df <- as.data.frame(r, xy=T)

          r <- str_extract(r, base_pattern) %>%
              str_sub(., 1, -17)

          saveRDS(ras.df, file = str_c(dir,"/",r,"PixelFeatureDF",".rds"))
      })
  }

#+END_SRC

** Make Segment Feature DF
#+BEGIN_SRC R
  fitXYlm <- function(x,y,z) {
      if(is.na(sum(z))) {
          z <- rep(0, length(z))
      }
      dat <- data.frame(x,y,z)
      mod <- lm(z ~ x * y, data = dat)
      coefs <-tidy(mod) %>%
          dplyr::select(term,estimate) %>%
          spread(key = term, value = estimate)

      error <- glance(mod) %>%
          select(sigma)

      bind_cols(coefs,error)
  }

                                          #foreach(seg.param.set = seg.param) %do% {}

  Create.Segment.Feature.df <- function(tile.dir,
                                        tile.name,
                                        ratio.appendage = ratio.tile.name.append,
                                        band.names = band.names.wRatios){

                                          #tile.name.stem everything before segmentation parameters
      tile.name.stem = str_replace(tile.name, pattern = segmentation.layer.pattern, "")

      ratio.tile.path <- str_c(tile.dir, "/", tile.name.stem, ratio.tile.name.append, ".tif")
      r.tile <- stack(ratio.tile.path)

      names(r.tile) <- band.names


      seg.tile.path <-  str_c(tile.dir, "/", tile.name,".tif")
      s.tile <- raster(seg.tile.path)

                                          # Create a data_frame where mean and variances are calculated by zone
      x <- as.data.frame(r.tile, xy = T)
      s <- as.data.frame(s.tile)
      colnames(s) <- "segment"
      r <- bind_cols(x,s)
      r2 <- r %>%
          group_by(segment) %>%
          mutate(x.center = x - quantile(x = x, probs = .5),
                 y.center = y - quantile(x = y, probs = .5))

      spatial.model.coef <- r2 %>%
          do(fitXYlm(x = .$x.center, y = .$y.center, z = .$n_ratio))

      mean.and.sd <- r2 %>%
          summarize(mean(blue),
                    mean(green),
                    mean(red),
                    mean(nir),
                    mean(b_ratio),
                    mean(g_ratio),
                    mean(r_ratio),
                    mean(n_ratio),
                    mean(ndvi),
                    sd(blue),
                    sd(green),
                    sd(red),
                    sd(nir),
                    sd(b_ratio),
                    sd(g_ratio),
                    sd(r_ratio),
                    sd(n_ratio),
                    sd(ndvi))

      tile.name = data.frame(tile.name = rep(tile.name.stem, nrow(mean.and.sd)))

      out <- left_join(spatial.model.coef, mean.and.sd) %>%
          bind_cols(., tile.name)

      names <- colnames(out)
      names <- str_replace(names, "\\(",".")
      names <- str_replace(names, "\\)",".")
      names <- str_replace(names, "\\:",".")
      colnames(out) <- names
      out
  }

  Create.Segment.Feature.df.noLM <- function(tile.dir,
                                             tile.name,
                                             ratio.appendage = ratio.tile.name.append,
                                             band.names = band.names.wRatios){

                                          #tile.name.stem everything before segmentation parameters
      tile.name.stem = str_replace(tile.name, pattern = segmentation.layer.pattern, "")

      ratio.tile.path <- str_c(tile.dir, "/", tile.name.stem, ratio.tile.name.append, ".tif")
      r.tile <- stack(ratio.tile.path)

      names(r.tile) <- band.names


      seg.tile.path <-  str_c(tile.dir, "/", tile.name,".tif")
      s.tile <- raster(seg.tile.path)

                                          # Create a data_frame where mean and variances are calculated by zone
      x <- as.data.frame(r.tile, xy = T)
      s <- as.data.frame(s.tile)
      colnames(s) <- "segment"
      r <- bind_cols(x,s)
      r2 <- r %>%
          group_by(segment)

      mean.and.sd <- r2 %>%
          summarize(mean(blue),
                    mean(green),
                    mean(red),
                    mean(nir),
                    mean(b_ratio),
                    mean(g_ratio),
                    mean(r_ratio),
                    mean(n_ratio),
                    mean(ndvi),
                    sd(blue),
                    sd(green),
                    sd(red),
                    sd(nir),
                    sd(b_ratio),
                    sd(g_ratio),
                    sd(r_ratio),
                    sd(n_ratio),
                    sd(ndvi))

      tile.name = data.frame(tile.name = rep(tile.name.stem, nrow(mean.and.sd)))

      out <- bind_cols(mean.and.sd, tile.name)

      names <- colnames(out)
      names <- str_replace(names, "\\(",".")
      names <- str_replace(names, "\\)",".")
      names <- str_replace(names, "\\:",".")
      colnames(out) <- names
      out
  }

#+END_SRC

** Create ModelBuilding dataframe
#+BEGIN_SRC R
  getSegment.class.and.features.Within.Polygon <- function(SegmentFeatureDF,
                                                           training.sp,
                                                           seg.tiles.dir,
                                                           seg.params){
      seg.files <- list.files(seg.tiles.dir, pattern = str_c(seg.params,".tif$"), full.names = T)
                                          # find number of pixels in each segment
      n.pixels.per.seg <- foreach(seg.file = seg.files, .combine = "rbind") %do% {
          seg <- stack(seg.file)
          s.df <- as.data.frame(seg) %>%
              gather(key = tile.name, value = segment.id) %>%
              group_by(segment.id, tile.name) %>%
              summarize(n.pixels.per.seg = n())
      }
                                          # find number of pixels in each segment are in a polygon
      n.pixels.per.seg.in.polygon <- foreach(seg.file = seg.files, .combine = "rbind") %do% {
          seg <- stack(seg.file)
          a <- raster::extract(seg, as(training.sp,"SpatialPolygons"), df = T)
          if(length(a) > 1) {
              a <- a %>%
                  gather(key = tile.name, value = segment.id, -ID) %>%
                  rename(polygon.id = ID) %>%
                  group_by(polygon.id, tile.name, segment.id) %>%
                  summarize(n.pixels.per.seg.in.polygon = n())
          }
      }
                                          # get pct of segment in a polygon,
                                          # filter segments that have more than 50%,
                                          #join Class information from polygons
      if(!is.null(n.pixels.per.seg.in.polygon)) {
          n.pixels <- left_join(n.pixels.per.seg.in.polygon,n.pixels.per.seg) %>%
              mutate(pct.seg.in.polygon = n.pixels.per.seg.in.polygon/n.pixels.per.seg) %>%
              filter(pct.seg.in.polygon >= .5) %>%
              left_join(.,training.sp@data, by = c("polygon.id" = "id")) %>%
              ungroup() %>%
              mutate(tile.name = str_extract(tile.name, "X[0-9]+_"),
                     tile.name = str_sub(tile.name,2,-2)) %>%
              mutate(segment = segment.id)

          left_join(n.pixels, SegmentFeatureDF) %>%
              dplyr::select(-segment,
                            -segment.id,
                            -tile.name,
                            -polygon.id,
                            -n.pixels.per.seg,
                            -n.pixels.per.seg.in.polygon,
                            -pct.seg.in.polygon) %>%
              filter(complete.cases(.))
      }
  }

                                          # returns dataframe of values of pixels within polygon
  getPixel.Class.and.Coords.Within.Polygon <- function(PixelFeatureDF,
                                                       training.sp) {
      xy <- select(PixelFeatureDF,x,y) %>% data.frame
      PixelFeatureDF <- data.frame(PixelFeatureDF)
      coordinates(PixelFeatureDF) <- xy
      proj4string(PixelFeatureDF) <- utm16

      training.sp <- spTransform(training.sp,utm16)

      pts.in.poly <- over(PixelFeatureDF,training.sp)
      PixelFeatureDF@data <- cbind(PixelFeatureDF@data, pts.in.poly)
      PixelFeatureDF <- PixelFeatureDF[which(complete.cases(pts.in.poly)),]
      PixelFeatureDF@data
  }

                                          # this is an old way
  create.df.toBuildModel.fromTrainingPolygons.and.SegmentFeatureDFs <- function(manuallyClassifiedPolygondir,
                                                                                image.dir,
                                                                                segment.feature.df.appendage = segment.feature.df.name.append,
                                                                                modelBuildingData.name = "modelBuildingData.rds") {

      segment.feature.df.appendage = segment.feature.df.name.append

                                          # list shapefiles with manually classified polygons
      trainingShapefiles <- list.files(manuallyClassifiedPolygondir) %>%
          str_sub(.,end = nchar(.)-4) %>%
          unique()

                                          # load training data from shapefiles into memory
      shapelist.data <- lapply(trainingShapefiles, function(shp) {
          readOGR(dsn = manuallyClassifiedPolygondir, layer = shp)@data %>%
                                                                     na.omit() %>%
                                                                     rename(zone = DN) %>%
                                                                     filter(Class != "N")
      })

      names(shapelist.data) <- trainingShapefiles


                                          # list .rds segment feature dataframe files
      segmentFeatureDF.rds.files <- list.files(image.dir, full.names = T) %>%
          str_extract(pattern = str_c(".*",segment.feature.df.appendage,".rds")) %>%
          na.omit()

      trainingData <- list()

      foreach(j = seq_along(shapelist.data)) %do% {
          d <- readRDS(segmentFeatureDF.rds.files[j])
          trainingData[[j]] <- left_join(shapelist.data[[j]],d, by = c("zone" = "segment"))
      }

      trainingData <- bind_rows(trainingData) %>%
          filter(Class != "N")

      saveRDS(trainingData, file = str_c(image.dir, "/",modelBuildingData.name))

  }

#+END_SRC
** Build and Save Models
#+BEGIN_SRC R
  Build.and.Save.models <- function(
                                    dir = dd.training.dir,
                                    modelBuildingData = ModelBuildingRDS,
                                    models.dir = Models.dir,
                                    image.name){

      dat <- readRDS(paste0(dir,"/",modelBuildingData)) %>%
          as.data.frame()

      image.and.segmentation.stem = str_replace(modelBuildingData, ModelBuilding.appendage,"")

      names <- colnames(dat)
      names <- str_replace(names, "\\(",".")
      names <- str_replace(names, "\\)",".")
      names <- str_replace(names, "\\:",".")
      colnames(dat) <- names

      dat_G <- dat %>%
          mutate(Class = as.character(Class),
                 Class = ifelse(Class == "g", Class, "o"))

      dat_I <- dat %>%
          mutate(Class = as.character(Class),
                 Class = ifelse(Class == "i", Class, "o"))

      dat_T <- dat %>%
          mutate(Class = as.character(Class),
                 Class = ifelse(Class == "t", Class, "o"))

                                          # Create Tasks
      all.task <- makeClassifTask(id = paste0(image.name,"_all"), data = dat, target = "Class")
      grass.task <- makeClassifTask(id = paste0(image.name,"_grass"), data = dat_G, target = "Class")
      impervious.task <- makeClassifTask(id = paste0(image.name,"_impervious"), data = dat_I, target = "Class")
      tree.task <- makeClassifTask(id = paste0(image.name,"_tree"), data = dat_T, target = "Class",positive = "t")

      task.list <- list(all = all.task, grass = grass.task, impervious = impervious.task, tree = tree.task)

                                          # Make Learners
      RF_prob <- makeLearner(id = "rf_prob","classif.randomForest", predict.type = "prob", fix.factors.prediction = TRUE)
      RF_response <- makeLearner(id = "rf_resp", "classif.randomForest", predict.type = "response", fix.factors.prediction = TRUE)
      SVM_response <- makeLearner(id = "svm_resp", "classif.svm", predict.type = "response", fix.factors.prediction = TRUE)

      learner.list <- list(RF_prob = RF_prob, RF_response = RF_response, SVM_response = SVM_response)

                                          # Train Learners on Tasks, Make models
                                          #         cl<-makeCluster(cores)
                                          #         registerDoParallel(cl)

      models <- foreach(tsk = task.list, .packages = "mlr") %do% {
          foreach(lnr = learner.list) %do% {
              mod <- train(lnr, tsk)
              mod
          }
      }
      saveRDS(models, file = paste0(models.dir,"/",image.and.segmentation.stem, models.appendage))
  }

#+END_SRC

** Classify Raster
#+BEGIN_SRC R

  classify.segmented.raster <- function(segment.feature.df.dir,
                                        segment.dir,
                                        model.dir,
                                        model.name.rds = "models",
                                        segment.feature.appendage = segment.feature.df.name.append,
                                        segmentation.appendage = segment.tile.name.append,
                                        segmentation.prms,
                                        classify.out.dir,
                                        tile.name = i) {
      df <- readRDS(paste0(segment.feature.df.dir,"/",tile.name,segment.feature.appendage))
      models <-readRDS(paste0(model.dir,"/",model.name.rds))
      umod <- unlist(models, recursive = F)
      seg.path <- paste0(segment.dir,"/",tile.name,segment.tile.name.append)
      seg <- raster(seg.path)
                                          #       dfRowsWithNA <- which(is.na(df[,2]))
      complete.df <- df[complete.cases(df),] # svm can't predict with NAs
      lapply(umod, function(mod) {
          pred <- predict(mod, newdata = complete.df)
          response <- factor(as.character(pred$data$response), levels = c("g","i","t","o"))
          m <- cbind(zone = complete.df$segment, response)
          m <- left_join(as.data.frame(df["segment"]), as.data.frame(m), by = c("segment" = "zone"))
          r <- reclassify(seg, m)
                                          #        x <- data.frame(ID = 1:4, LandCover = c("G","I","T","O")) %>%
                                          #            filter(LandCover %in% levels(factor(response)))
                                          #        levels(r) <- x
          if (ncol(pred$data) > 2) {
              prob <- (pred$data[,grep("prob.*", x = colnames(pred$data))]) # get columns that contain probabilities
              ProbOfClass <- apply(prob, MARGIN = 1, FUN = max)
              m <- cbind(segment = df$segment, ProbOfClass)
              m <- left_join(as.data.frame(df["segment"]), as.data.frame(m))
              p <- reclassify(seg, m)
              r <- stack(r,p)
          }
          path <- paste0(segment.dir,"/",ClassifiedTilesDirName,"/",tile.name,"_",segmentation.prms,"_",mod$task.desc$id,"_",mod$learner$id,".tif")
          writeRaster(r, path, overwrite=TRUE)
          print(path)
      })
  }


  classify.pixel.raster <- function(tile.dir = dd.accuracy.dir,
                                    tile.name,
                                    pixelFeatureDF.appendage = pixel.feature.df.appendage,
                                    model.dir = Models.dir,
                                    model.rds,
                                    seg.prms = "Pixel") {
      ras <- stack(str_c(tile.dir,"/",tile.name,".tif"))
      pix.mods <- readRDS(str_c(model.dir,"/",model.rds))
      pix.umods <- unlist(pix.mods, recursive = F)

      pix.feature.df <- readRDS(str_c(tile.dir,"/",tile.name,pixelFeatureDF.appendage,".rds"))

      if(!is.null(pix.feature.df$y)) {
          pix.feature.df <- dplyr::select(pix.feature.df, -x, -y)
      }

                                          # I set NA's to 0 here.  Not the best choice.  Not sure why they exist.
                                          # imputing to mean would probably be better

      pix.feature.df <- as.matrix(pix.feature.df)

      pix.feature.df[which(is.na(pix.feature.df))] <- 0

      pix.feature.df <- as.data.frame(pix.feature.df)


      lapply(pix.umods, function(pix.mod) {
          pred <- predict(pix.mod, newdata = pix.feature.df)
          a <- ras[[1]]
          values(a) <- pred$data$response
          path <- paste0(tile.dir,"/",ClassifiedTilesDirName,"/",tile.name,"_",seg.prms,"_",pix.mod$task.desc$id,"_",pix.mod$learner$id,".tif")
          writeRaster(a, path, overwrite = T)
          print(path)
      })
  }








#+END_SRC

#+BEGIN_SRC R :results graphics :file figs/pixClss.png
                                          #plot(a)
#+END_SRC

** Calculate Percent Cover in Classified Tiles
#+BEGIN_SRC R

  get.prcnt.class <- function(points,r) {
      r <- crop(r,points)  # should I do a mask instead??
      g <- cellStats(r == 1, stat = sum)
      im <- cellStats(r == 2, stat = sum)
      tr <- cellStats(r == 3, stat = sum)
      o <-  cellStats(r == 4, stat = sum)
      totC <- ncell(r)
      return(c(pct_g_pred = g/totC, pct_i_pred = im/totC, pct_t_pred = tr/totC, pct_o_pred = o/totC))
  }


  get_area_convexHull <- function(points) {
      ch <- chull(coordinates(points))
      coords <- coordinates(points)[c(ch,ch[1]),]
      poly <- SpatialPolygons(list(Polygons(list(Polygon(coords)),ID = 1)))
      gArea(poly)
  }



  calculate.percent.cover.in.classified.tile <- function(pts,
                                                         tile.dir = dd.accuracy.classified.dir,
                                                         tile.pth,
                                                         n.rows.and.columns.subset,
                                                         mod = 1,
                                                         mad.grid.id.pattern = "mad-[0-9]+m-[0-9]+",
                                                         grid.pattern = "[a-zA-Z]{3}-[0-9]+m-[0-9]+_",
                                                         image.pattern = "[a-zA-Z]{5}[a-zA-Z]+",
                                                         target.pattern = "all|grass|impervious|tree",
                                                         model.pattern = "rf_prob|rf_resp|svm_resp",
                                                         seg.prms = "N-[0-9]+_C-[0-9]+|Pixel"
                                                         ) {
      tile.nm <- basename(tile.pth)


      pts.sub <- pts@data  %>%
          filter.by.row.and.col(.,n.rows.and.columns.subset, mod = mod)

      coordinates(pts.sub) <- ~ crds_x1 + crds_x2

      proj4string(pts.sub) <- utm16
      tile.unique.name <- str_extract(tile.pth, mad.grid.id.pattern)
      pts.at.grid <- pts.sub[which(pts.sub@data$unq__ID == tile.unique.name),]
      tile <- raster(tile.pth, proj4string = "+init:epsg=32616")

      area.pts <- get_area_convexHull(pts.at.grid)

      if(!is.null(raster::intersect(extent(tile),bbox(pts.at.grid)))) {

          get.prcnt.class(pts.at.grid,tile) %>%
              t() %>%
              as.data.frame() %>%
              mutate(grid.tile.target.model = tile.nm,
                     grid = str_sub(str_extract(grid.tile.target.model, grid.pattern),1,-2),
                     image =  str_extract(grid.tile.target.model, image.pattern),
                     target.cover = str_extract(grid.tile.target.model, target.pattern),
                     model =  str_extract(grid.tile.target.model, model.pattern),
                     n.points = n.rows.and.columns.subset * n.rows.and.columns.subset,
                     area = area.pts,
                     seg.params = str_extract(grid.tile.target.model, seg.prms),
                     target.type = ifelse(target.cover == "all", "multinomial", "binomial"))
      }
  }

#+END_SRC

** Calculate Percent Cover of Grids, subsetted
#+BEGIN_SRC R
  filter.by.row.and.col <- function(df,nrow.and.col, mod) {
      nrow <-df %>%
          group_by(unq__ID) %>%
          summarize(nrow = max(row))

      df <- left_join(df,nrow)

      df %>%
          filter(nrow >= nrow.and.col,   # remove grids that have fewer than the number of rows & columns
                 row <= nrow.and.col,    # remove rows greater than the number we are interested in
                 col <=nrow.and.col,   # same for columns as rows
                 row %% mod == 0,
                 col %% mod == 0)
  }

  add.n.pts.per.grid <- function(df){
      n.pts<-df %>%
          group_by(unq__ID) %>%
          summarize(n.points = n())

      left_join(df,n.pts)
  }


  get.pct.cvr.typ <- function(df) {
      df %>%
          group_by(unq__ID, cvr_typ,n.points, area) %>%
          summarize(number = n()) %>%
          ungroup() %>%
          mutate(google.truth.pct.cover = number/n.points) %>%
          dplyr::select(-number)
  }

  combine.classes.to.g.i.t.o <- function(df) {

      df %>%
          mutate(cvr_typ = as.character(cvr_typ),
                 cvr_typ = ifelse(cvr_typ == "s",
                                  "i",
                                  cvr_typ),
                 cvr_typ = ifelse(cvr_typ != "g" &
                                  cvr_typ != "i" &
                                  cvr_typ != "t", "o", cvr_typ)) %>%
          group_by(unq__ID, cvr_typ, n.points, area) %>%
          summarize(google.truth.pct.cover = sum(google.truth.pct.cover))

  }


  calc.binomial.pct.cvrs <- function(df) {

      out <- foreach(target.cvr.type = c("g","i","t")) %do%{
          df %>%
              mutate(cvr_typ = ifelse(cvr_typ == target.cvr.type, cvr_typ, "o")) %>%
              group_by(unq__ID, n.points, cvr_typ) %>%
              summarize(pct.cover = sum(pct.cover)) %>%
              mutate(target.type = "binomial",
                     target.cover = target.cvr.type,
                     target.cover = ifelse(target.cover == "g", "grass",
                                    ifelse(target.cover == "t", "tree",
                                           "impervious"))) %>%
              spread(key = cvr_typ, value = pct.cover)
      }
      out <- bind_rows(out)
      out %>%
          rename(pct.g.googleEarth = g, pct.i.googleEarth = i, pct.t.googleEarth = t, pct.o.googleEarth = o)
  }



  get.area.convexHull <- function(x_coord, y_coord) {
      m <- matrix(c(x_coord, y_coord), ncol = 2)
      ch <- chull(m)
      coords <- m[c(ch,ch[1]),]
      poly <- SpatialPolygons(list(Polygons(list(Polygon(coords)),ID = 1)))
      gArea(poly)
  }



  calc.pct.cvr.for.grid.subset <- function(df,
                                           n.rows.and.columns.for.subset=20,
                                           mod,
                                           gridID = "unq__ID") {


      df <- filter.by.row.and.col(df, n.rows.and.columns.for.subset, mod) %>%
          add.n.pts.per.grid() %>%
          group_by_(gridID)


      area.df <- df %>%
          summarize(area = get.area.convexHull(crds_x1, crds_x2))

      df <- left_join(df, area.df)


      df <- df %>%
          get.pct.cvr.typ() %>%
          combine.classes.to.g.i.t.o() %>%
                                          #               ungroup() %>%
                                          #               dplyr::select(-n.points) %>%
          spread(., key = cvr_typ, value = google.truth.pct.cover, fill = 0)

                                          #         df[is.na(df)] <- 0

      df.multnm <- df %>%
          mutate(target.type = "multinomial") %>%
          rename(pct.g.googleEarth = g, pct.i.googleEarth = i, pct.t.googleEarth = t) %>%
          mutate(target.cover = "all")

      if(!is.null(df.multnm$o)) { df.multnm <- rename(df.multnm, pct.o.googleEarth = o)}

      df <- df %>%
          gather(key = cvr_typ, value = pct.cover, -unq__ID, -n.points)

      df.binm <- df %>%
          calc.binomial.pct.cvrs()


      df.out <- bind_rows(df.binm, df.multnm)
      return(df.out)
  }



#+END_SRC

** Point-wise error functions
#+BEGIN_SRC R
  calcErrorAllMultinomial <-  function(pts, tile, Pixel = F) {
      classification <- raster::extract(classified.tile, pts)
      if(Pixel == T) {
          lvls <- levels(classified.tile)[[1]]
          classification <- mapvalues(classification, from = lvls[,1], to = as.character(lvls[,2]))
      } else {
          classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
      }
      google = pts@data$cvr_typ
      overall.error <- 1 - mean(classification == google)
      pct.grass.classified.as.other <- 1 - mean(classification[which(google == "g")] == google[which(google == "g")])
      pct.impervious.classified.as.other <- 1 - mean(classification[which(google == "i")] == google[which(google == "i")])
      pct.tree.classified.as.other <- 1 - mean(classification[which(google == "t")] == google[which(google == "t")])
      error <- c(overall.error = overall.error,
                 pct.grass.classified.as.other = pct.grass.classified.as.other,
                 pct.impervious.classified.as.other = pct.impervious.classified.as.other,
                 pct.tree.classified.as.other = pct.tree.classified.as.other)
      return(error)
  }

  calcErrorBinomial <-  function(pts, tile, target, Pixel = F) {
      classification <- raster::extract(classified.tile, pts)
      if(Pixel == T) {
          lvls <- levels(classified.tile)[[1]]
          classification <- mapvalues(classification, from = lvls[,1], to = as.character(lvls[,2]))
      } else {
          classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
      }
      classification <- ifelse(classification == target, classification, "o")
      google <- pts@data$cvr_typ
      google <- ifelse(google == target, google, "o")
      overall.error <- 1 - mean(classification == google)
      pct.grass.classified.as.other <- 1 - mean(classification[which(google == "g")] == google[which(google == "g")])
      pct.impervious.classified.as.other <- 1 - mean(classification[which(google == "i")] == google[which(google == "i")])
      pct.tree.classified.as.other <- 1 - mean(classification[which(google == "t")] == google[which(google == "t")])
      error <- c(overall.error = overall.error,
                 pct.grass.classified.as.other = pct.grass.classified.as.other,
                 pct.impervious.classified.as.other = pct.impervious.classified.as.other,
                 pct.tree.classified.as.other = pct.tree.classified.as.other)
      return(error)
  }




  calcConfusionMat <- function(pts, tile) {
      classification <- raster::extract(classified.tile, pts)
      classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
      table(classification, google = pts@data$cvr_typ)
  }


#+END_SRC
** Plot points on classifed tile

#+BEGIN_SRC R
      pts.on.classified.tile.plot <- function(pts, classified.tile, target = NULL) {
          if(target == "a") {
              pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
              pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, fill = cvr_typ), shape = 21, color = "black", size =2, stroke = .2)
          } else {
              pts@data <- pts@data %>%
                  mutate(cvr_typ = ifelse(cvr_typ == target, cvr_typ, "o"))
                  pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
          }
          r.df <- as.data.frame(classified.tile, xy = T)
          names(r.df) <- c("x","y","cvr_typ")
          r.df <- r.df %>%
              mutate(cvr_typ = mapvalues(cvr_typ, from = c(1,2,3,4), to = c("g","i","t","o")))
          pxls.plot <- ggplot() + geom_raster(data = r.df, aes(x = x, y = y, fill = cvr_typ))
          title <- ggtitle(label = names(classified.tile))
          UTC_pal <- c(g = "#ffff99", i = "#f0027f", t = "#7fc97f", o = "#666666")
          pxls.plot + pts.plot + title + scale_fill_manual(values = UTC_pal)+ scale_color_manual(values = UTC_pal) +
  coord_equal()
      }



#+END_SRC

* set figure Cairo
:PROPERTIES:
:ARCHIVE_TIME: 2016-07-27 Wed 11:27
:ARCHIVE_FILE: /ssh:krusty:/home/erker/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Workflow
:ARCHIVE_CATEGORY: utc
:END:
#+begin_src R :exports none :results silent
  library(Cairo)
  mainfont <- "Garamond"
  CairoFonts(regular = paste(mainfont,"style=Regular",sep=":"),
             bold = paste(mainfont,"style=Bold",sep=":"),
             italic = paste(mainfont,"style=Italic",sep=":"),
             bolditalic = paste(mainfont,"style=Bold Italic,BoldItalic",sep=":"))
  pdf <- CairoPDF
  png <- CairoPNG
#+end_src

* Summarize Accuracy Assessment Results
:PROPERTIES:
:ARCHIVE_TIME: 2016-08-17 Wed 13:13
:ARCHIVE_FILE: ~/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Workflow/Determine how to make best classifier for Madison : image, segmentation, model, n.classes, target, and def truth
:ARCHIVE_CATEGORY: utc
:END:

Comparing classification to other estimates of cover.
#+begin_src R :results none
      error.df <- readRDS(str_c(derived.dir, "/Grids.point2pixel.error.df.rds"))

      error.df %>%
          arrange(overall.error) %>%
          head()

      error.df %>%
          arrange(desc(overall.error)) %>%
          head()

      error.df %>%
          filter(seg.params != "Pixel") %>%
          arrange(desc(overall.error)) %>%
          head()

  error.df <- error.df %>%
      mutate(segment.size = as.numeric(ifelse(!is.na(str_match(seg.params, "N-([0-9]+)_C-[0-9]+")[,2]), str_match(seg.params, "N-([0-9]+)_C-[0-9]+")[,2], 1)),
             segment.size = ifelse(image == "panshpSPOT", segment.size * 1.5, segment.size),
             compactness = as.numeric(str_match(seg.params, "N-[0-9]+_C-([0-9]+)")[,2]))

#+end_src

** Random Points

*** Table showing performance of classifiers
#+begin_src R

#+end_src
*** Plots showing how image, segment size, compactness, and model affect accuracy

** Field Data
** Grid of Points

*** load grid.points
#+begin_src R
  grid.points <- readOGR(dsn = accuracy.region.imageCRS.dsn,
                         layer = "madisonNAIP_Grids")

#+end_src

#+results:
:  OGR data source with driver: ESRI Shapefile
: Source: "../DD/reprojected.Accuracy.Regions", layer: "madisonNAIP_Grids"
: with 20209 features
: It has 15 fields

*** Plots of 20 best classified grids with points superimposed
For each grid, find the best classification.  Plot best 20 grids.
#+begin_src R :results raw
    best.classified.grids <- error.df %>%
        ungroup() %>%
        group_by(grid) %>%
        top_n(1, desc(overall.error)) %>%
        ungroup() %>%
        arrange(overall.error) %>%
        select(overall.error, grid,image, target.cover, model, seg.params) %>%
        mutate(path = paste0(dd.accuracy.classified.dir,"/",image,".",grid,"_",seg.params,"_",image,"_",target.cover,"_",model,".tif")) %>%
        head(n = 20)

options(warn = -1)
  best.classified.grids %>% ascii
options(warn = 1)
#+end_src

#+results:
|    | overall.error | grid        | image       | target.cover | model   | seg.params | path                                                                                             |
|----+---------------+-------------+-------------+--------------+---------+------------+--------------------------------------------------------------------------------------------------|
|  1 |          0.03 | mad.50m.2   | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.50m.2_Pixel_madisonNAIP_all_rf_prob.tif   |
|  2 |          0.04 | mad.100m.23 | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.100m.23_Pixel_madisonNAIP_all_rf_prob.tif |
|  3 |          0.04 | mad.100m.13 | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.100m.13_Pixel_madisonNAIP_all_rf_prob.tif |
|  4 |          0.04 | mad.50m.5   | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.50m.5_Pixel_madisonNAIP_all_rf_prob.tif   |
|  5 |          0.05 | mad.100m.12 | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.100m.12_Pixel_madisonNAIP_all_rf_prob.tif |
|  6 |          0.07 | mad.150m.9  | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.150m.9_Pixel_madisonNAIP_all_rf_prob.tif  |
|  7 |          0.07 | mad.150m.5  | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.150m.5_Pixel_madisonNAIP_all_rf_prob.tif  |
|  8 |          0.07 | mad.100m.3  | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.100m.3_Pixel_madisonNAIP_all_rf_prob.tif  |
|  9 |          0.08 | mad.100m.4  | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.100m.4_Pixel_madisonNAIP_all_rf_prob.tif  |
| 10 |          0.10 | mad.100m.1  | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.100m.1_Pixel_madisonNAIP_all_rf_prob.tif  |
| 11 |          0.13 | mad.200m.4  | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.200m.4_Pixel_madisonNAIP_all_rf_prob.tif  |
| 12 |          0.14 | mad.100m.27 | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.100m.27_Pixel_madisonNAIP_all_rf_prob.tif |
| 13 |          0.15 | mad.100m.21 | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.100m.21_Pixel_madisonNAIP_all_rf_prob.tif |
| 14 |          0.16 | mad.200m.1  | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.200m.1_Pixel_madisonNAIP_all_rf_prob.tif  |
| 15 |          0.17 | mad.100m.28 | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.100m.28_Pixel_madisonNAIP_all_rf_prob.tif |
| 16 |          0.17 | mad.100m.8  | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.100m.8_Pixel_madisonNAIP_all_rf_prob.tif  |
| 17 |          0.17 | mad.100m.14 | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.100m.14_Pixel_madisonNAIP_all_rf_prob.tif |
| 18 |          0.18 | mad.200m.5  | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.200m.5_Pixel_madisonNAIP_all_rf_prob.tif  |
| 19 |          0.19 | mad.50m.4   | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.50m.4_Pixel_madisonNAIP_all_rf_prob.tif   |
| 20 |          0.19 | mad.100m.11 | madisonNAIP | all          | rf_prob | Pixel      | ../DD/madison_Accuracy/ClassifiedTiles/madisonNAIP.mad.100m.11_Pixel_madisonNAIP_all_rf_prob.tif |
 Error: object 'ClassifiedTilesDirName' not found
Error in eval(expr, envir, enclos) :
  object 'best.classified.grids' not found


#+begin_src R :results none

  lapply(1:nrow(best.classified.grids), function(i){
      pts.on.classified.tile.plot.ErrorinTitle(error = best.classified.grids$overall.error[i],
                                           grd.pts = grid.points,
                                           classified.tile.path = best.classified.grids$path[i],
                                           fig.dir = "figs/bestgrids",
                                           target = "a")
  })

  ## plts <- lapply(best.classified.grids$path, function(path) {
  ##   grid.name <- str_match(path, ".*([a-z]{3}\\.[0-9]+m\\.[0-9]+)_.*")[,2]
  ##   points <- grid.points[grid.points@data$unq__ID == grid.name,]
  ##   points@data <- points@data %>%
  ##       mutate(x = coordinates(points)[,1],
  ##              y = coordinates(points)[,2])
  ##   ras <- raster(path)
  ##   pts.on.classified.tile.plot(fig.dir = "figs/bestgrids",points, ras, target = "a")
  ## })

  #+end_src

#+BEGIN_SRC R :results raw :eval no

best.grid.paths <- list.files("figs/bestgrids", full.names = T)

a <- sapply(best.grid.paths, function(x) message("[[file:",x,"]]"))

#+END_SRC

*** NEXT Plots of 20 worst classified grids with points superimposed.  NONE SHOULD BE >50% wrong!
For each grid, find the worst classification.  Plot worst 20 grids.
#+begin_src R :results raw
      worst.classified.grids <- error.df %>%
          ungroup() %>%
          group_by(grid) %>%
          top_n(1, overall.error) %>%
          ungroup() %>%
          arrange(desc(overall.error)) %>%
          select(overall.error, grid,image, target.cover, model, seg.params) %>%
          mutate(path = paste0(dd.accuracy.classified.dir,"/",image,".",grid,"_",seg.params,"_",image,"_",target.cover,"_",model,".tif")) %>%
          head(n = 20)

        saveRDS(error.df, str_c(derived.dir, "/RandomPoints.GoogleReference.point2pixel.error.df.rds"))

#+END_SRC




* testing if stretching the pca is worthwhile.
:PROPERTIES:
:ARCHIVE_TIME: 2016-09-06 Tue 14:06
:ARCHIVE_FILE: ~/Pjt_UTC/code/utc.org
:ARCHIVE_OLPATH: Workflow [2016-08-29 Mon]/Create State-wide classifiers
:ARCHIVE_CATEGORY: utc
:ARCHIVE_ITAGS: work utc
:END:

[2016-09-06 Tue]
Doesn't change segmentation significantly (one or two pixels per
segment).  This is roughly the same in all meaningful ways.


#+begin_src R
  pca <- stack(str_c(dd.training.dir, "/madisonNAIP.2_pca.tif"))
  pca.stretch <- rescale.0.b(pca,254, each.band = T)
  pca.stretch
  writeRaster(pca.stretch, str_c(dd.training.dir,"/madisonNAIP.2.stretched_pca.tif"))
#+end_src

#+results:
#+begin_example
class       : RasterBrick
dimensions  : 212, 445, 94340, 3  (nrow, ncol, ncell, nlayers)
resolution  : 1, 1  (x, y)
extent      : 297402, 297847, 4767284, 4767496  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=utm +zone=16 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
data source : in memory
names       : madisonNAIP.2_pca.1, madisonNAIP.2_pca.2, madisonNAIP.2_pca.3
min values  :                   0,                   0,                   0
max values  :                 254,                 254,                 254
Error in .getGDALtransient(x, filename = filename, options = options,  :
  filename exists; use overwrite=TRUE
#+end_example

** segment pca
#+begin_src R
  segment(dd.training.dir,
          image.name = "NAIP",
          tile.name = "madisonNAIP.2",
          compactness = 15,
          segment.size = 30,
          krusty = F)
#+end_src

#+results:
:  sh: /home/erker/.conda/envs/utc/bin/python: No such file or directory

** segment stretched pca
#+begin_src R
  segment(dd.training.dir,
          image.name = "NAIP",
          tile.name = "madisonNAIP.2.stretched",
          compactness = 15,
          segment.size = 30,
          krusty = T)
#+end_src

#+results:
:  ../DD/madison_Training/
: average number of pixels per segment is 30.0
: compactness parameter is 15
: madisonNAIP.2.stretched_pca.tif

** polygonize segments
#+begin_src R
  polygonize.and.add.Class(dd.training.dir,
                           "madisonNAIP.2",
                           segment.appendage = "_N-30_C-15")

  polygonize.and.add.Class(dd.training.dir,
                           "madisonNAIP.2.stretched",
                           segment.appendage = "_N-30_C-15")
#+end_src

#+results:
:  Creating output /var/folders/yj/vjkj1yyx1n510rf_rggqdb640000gr/T//RtmpbPQ5SS/filed875c5f3860.shp of format ESRI Shapefile.
: 0...10...20...30...40...50...60...70...80...90...100 - done.
:  Creating output /var/folders/yj/vjkj1yyx1n510rf_rggqdb640000gr/T//RtmpbPQ5SS/filed8734d05327.shp of format ESRI Shapefile.
: 0...10...20...30...40...50...60...70...80...90...100 - done.




