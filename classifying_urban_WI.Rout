
R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ## [[file:utc.org::*Libraries][Libraries:1]]
> ## install.packages(c("gdalUtils","ascii","rgeos","mlr","broom","rgdal","raster","plyr","ggplot2","dplyr","tidyr","stringr","foreach","doParallel","glcm","randomForest","kernlab","irace","parallelMap"))
> ##install.packages("e1071")
> ##  install.packages("FSelector")
> 
> setwd("/home/erker/Pjt_UTC/code")
> 
>   library(gdalUtils)
>   library(ascii)
>   library(rgeos)
rgeos version: 0.3-19, (SVN revision 524)
 GEOS runtime version: 3.5.0-CAPI-1.9.0 r4084 
 Linking to sp version: 1.2-3 
 Polygon checking: TRUE 

>   library(mlr)
Loading required package: BBmisc

Attaching package: ‘BBmisc’

The following object is masked from ‘package:rgeos’:

    symdiff

Loading required package: ggplot2
Loading required package: ParamHelpers
>   library(broom)
>   library(rgdal)
Loading required package: sp
rgdal: version: 1.1-10, (SVN revision 622)
 Geospatial Data Abstraction Library extensions to R successfully loaded
 Loaded GDAL runtime: GDAL 1.11.3, released 2015/09/16
 Path to GDAL shared files: /usr/share/gdal/1.11
 Loaded PROJ.4 runtime: Rel. 4.9.2, 08 September 2015, [PJ_VERSION: 492]
 Path to PROJ.4 shared files: (autodetected)
 Linking to sp version: 1.2-3 
>   library(raster)

Attaching package: ‘raster’

The following object is masked from ‘package:mlr’:

    resample

The following object is masked from ‘package:ParamHelpers’:

    getValues

>   library(plyr)
>   library(ggplot2)
>   library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:plyr’:

    arrange, count, desc, failwith, id, mutate, rename, summarise,
    summarize

The following objects are masked from ‘package:raster’:

    intersect, select, union

The following objects are masked from ‘package:BBmisc’:

    coalesce, collapse

The following objects are masked from ‘package:rgeos’:

    intersect, setdiff, union

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

>   library(tidyr)

Attaching package: ‘tidyr’

The following object is masked from ‘package:raster’:

    extract

The following object is masked from ‘package:ascii’:

    expand

>   library(stringr)
>   library(foreach)
>   library(doParallel)
Loading required package: iterators
Loading required package: parallel
>   library(glcm)
>   library(randomForest)
randomForest 4.6-12
Type rfNews() to see new features/changes/bug fixes.

Attaching package: ‘randomForest’

The following object is masked from ‘package:dplyr’:

    combine

The following object is masked from ‘package:ggplot2’:

    margin

>   library(kernlab)

Attaching package: ‘kernlab’

The following objects are masked from ‘package:raster’:

    buffer, rotated

The following object is masked from ‘package:ggplot2’:

    alpha

>   library(irace)
>   library(parallelMap)
>   library(FSelector)
> ## Libraries:1 ends here
> 
> ## [[file:utc.org::*Input%20Directories][Input\ Directories:1]]
> image.names <- c("NAIP","PanshpSPOT")
> image.dirs <- paste0("../RD_",image.names)
> pca.dir <- "../RD_PCA_Regions"
> training.dir <- "../RD_Training_Regions"
> accuracy.dir <- "../RD_Accuracy"
> grids.accuracy.dir <- str_c(accuracy.dir, "/Grids")
> fieldplots.accuracy.dir<- str_c(accuracy.dir, "/FieldData")
> crop.dir <- "../RD_CroplandDataLayer"
> water.dir <- "../RD_WI-waterbody-24k"
> urban.dir <- "../RD_US_UrbanAreasShapefile"
> urban.and.incorporated.dir <- "../RD_merged_WIurbanAreas_and_incorporatedAreas"
> ## Input\ Directories:1 ends here
> 
> ## [[file:utc.org::*Variable%20Names%20and%20Paths][Variable\ Names\ and\ Paths:1]]
> locations = c("madison","wausau")
> 
> image.paths <- expand.grid(image.names,locations) %>% data.frame %>%
+       mutate(img.paths = paste0(image.dirs,"/",Var2,Var1,".tif")) %>%
+       .$img.paths
> 
> ratio.appendage <- "_ratio"
> pca.appendage <- "_pca"
> model.appendage = "_model"
> 
> feature.df.appendage <- "_featureDF"
> 
> ModelBuilding.appendage = "_modelBuildingDF"
> 
> tile.id.col.nm.for.grid.and.field.accuracy <- c("unq__ID", "Plot")
> ## Variable\ Names\ and\ Paths:1 ends here
> 
> ## [[file:utc.org::*Patterns][Patterns:1]]
> grid.pattern = "[a-zA-Z]{3}\\.[0-9]+m\\.[0-9]+" #I removed "_" from end. <2016-07-02 Sat>
> texture.pattern = "stat-.*_window-.*_angle[-]+[0-9]+"
> segmentation.pattern = "Pixel|N-[0-9]+_C-[0-9]+"
> target.pattern = "all|grass|impervious|tree"
> image.pattern = "[a-zA-Z]{5}[a-zA-Z]+"
> model.pattern = "rf_prob|rf_resp|svm_resp"
> ## Patterns:1 ends here
> 
> ## [[file:utc.org::*Texture%20Params][Texture\ Params:1]]
> band.for.texture.appendage = "_ratio.nir"
> window <- list(c(3,3), c(5,5), c(7,7))
> statistics = list("homogeneity", "contrast", "correlation", "entropy")
> shift = list(c(0,1),c(1,0),c(1,1),c(-1,1))
> 
> ## band.for.texture.appendage = "_ratio.nir"
> ## window <- list(c(3,3))
> ## statistics = list("homogeneity")
> ## shift = list(c(0,1))
> 
> texture.params <- expand.grid(band.appendage = band.for.texture.appendage,window = window, statistics = statistics, shift = shift, stringsAsFactors = F)
> ## Texture\ Params:1 ends here
> 
> ## [[file:utc.org::*Segmentation%20Params][Segmentation\ Params:1]]
> segment.size <- c(rep(15,3), rep(20,3),rep(30,3),rep(45,3),rep(60,3),rep(100,3))
>   compactness <- round(segment.size * c(.3, .5, .6))
> 
>   ## segment.size <- c(rep(30,1), rep(100,1))
>   ## compactness <- segment.size * c(.5)
> 
> ## segment.size <- 20
> ## compactness <- 12
> 
>   segment.params <- data.frame(compactness = compactness, segment.size = segment.size)
> ## Segmentation\ Params:1 ends here
> 
> ## [[file:utc.org::*Input%20Shapefile%20DSNs%20and%20Layers][Input\ Shapefile\ DSNs\ and\ Layers:1]]
> pca.region.dsn <- "../RD_PCA_Regions/"
> pca.region.layer.appendage <- "_PCA_regions"
> 
> training.region.dsn <- "../RD_Training_Regions/"
> training.region.layer.appendage <- "_TrainingPolygons"
> 
> grid.accuracy.region.dsn <- "../RD_Accuracy/Grids"
> grid.accuracy.region.layer <- "Grids"
> 
> field.accuracy.region.dsn <- "../RD_Accuracy/FieldData"
> field.accuracy.region.layer <- "fieldPoints"
> 
> accuracy.region.dsn <- c(grid.accuracy.region.dsn, field.accuracy.region.dsn)
> accuracy.region.layer <- c(grid.accuracy.region.layer, field.accuracy.region.layer)
> ## Input\ Shapefile\ DSNs\ and\ Layers:1 ends here
> 
> ## [[file:utc.org::*Derived%20Directories][Derived\ Directories:1]]
> # make derived data directory
>   derived.dir <- "../DD"
> 
>   dd.training.dirs <- str_c(derived.dir, "/",locations,"_Training")
> 
>   dd.pca.dirs <- str_c(derived.dir, "/",locations,pca.appendage)
> 
>   dd.accuracy.dirs <- str_c(derived.dir, "/",locations,"_Accuracy")
> 
>   dd.models.dirs <- paste0(derived.dir,"/",locations,"_Models")
> 
>   dd.accuracy.classified.dirs <- str_c(dd.accuracy.dirs, "/ClassifiedTiles")
> 
> derived.dirs <- c(derived.dir, dd.training.dirs, dd.pca.dirs, dd.accuracy.dirs, dd.models.dirs, dd.accuracy.classified.dirs)
> ## Derived\ Directories:1 ends here
> 
> ## [[file:utc.org::*Make%20Derived%20Directories][Make\ Derived\ Directories:1]]
> sapply(derived.dirs, FUN = function(x) dir.create(x))
                                 ../DD                 ../DD/madison_Training 
                                 FALSE                                  FALSE 
                 ../DD/wausau_Training                      ../DD/madison_pca 
                                 FALSE                                  FALSE 
                      ../DD/wausau_pca                 ../DD/madison_Accuracy 
                                 FALSE                                  FALSE 
                 ../DD/wausau_Accuracy                   ../DD/madison_Models 
                                 FALSE                                  FALSE 
                   ../DD/wausau_Models ../DD/madison_Accuracy/ClassifiedTiles 
                                 FALSE                                  FALSE 
 ../DD/wausau_Accuracy/ClassifiedTiles 
                                 FALSE 
There were 11 warnings (use warnings() to see them)
> ## Make\ Derived\ Directories:1 ends here
> 
> ## [[file:utc.org::*Define%20Derived%20Shapefile%20DSNs%20and%20Layers][Define\ Derived\ Shapefile\ DSNs\ and\ Layers:1]]
> training.region.imageCRS.dsn <- str_c(derived.dir,"/reprojected.Training_Regions")
> 
> pca.region.imageCRS.dsn <- str_c(derived.dir,"/reprojected.PCA_Regions")
> 
> accuracy.region.imageCRS.dsn <- str_c(derived.dir,"/reprojected.Accuracy.Regions")
> 
> 
> lapply(training.region.imageCRS.dsn, FUN = function(x) dir.create(x))
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/reprojected.Training_Regions' already exists
> lapply(pca.region.imageCRS.dsn, FUN = function(x) dir.create(x))
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/reprojected.PCA_Regions' already exists
> lapply(accuracy.region.imageCRS.dsn, FUN = function(x) dir.create(x))
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/reprojected.Accuracy.Regions' already exists
> ## Define\ Derived\ Shapefile\ DSNs\ and\ Layers:1 ends here
> 
> ## [[file:utc.org::*number%20of%20cores][number\ of\ cores:1]]
> cores <- detectCores()
> cores <- 44
> ## number\ of\ cores:1 ends here
> 
> ## [[file:utc.org::*CRS][CRS:1]]
> utm16 <- CRS("+init=epsg:32616")
> wtm <- CRS("+init=epsg:3071")
> ## CRS:1 ends here
> 
> ## [[file:utc.org::*ASCII][ASCII:1]]
> options(asciiType = "org")
> ## ASCII:1 ends here
> 
> ## [[file:utc.org::*delete?][delete\?:1]]
> #  band.names.wRatios <- c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")
> #  pixel.feature.df.appendage = "_PixelFeatureDF"
> #  segmentFeatureDF.appendage = "_SegmentFeatureDF.rds"
> #  pca.model.name.appendage = "_pca.rds"
> 
> #     mad.grid.id.pattern = "mad.[0-9]+m.[0-9]+"
> ## delete\?:1 ends here
> 
> ## [[file:utc.org::*Extract%20Name%20from%20path][Extract\ Name\ from\ path:1]]
> # Use basename instead!
> extract.name.from.path <- function(path) {
+     str_extract(basename(path), "[A-Za-z0-9_]*.") %>%
+         str_sub(.,1,-2)
+ }
> ## Extract\ Name\ from\ path:1 ends here
> 
> ## [[file:utc.org::*Reproject%20Shapefile%20to%20Image%20Coordinate%20Reference%20System][Reproject\ Shapefile\ to\ Image\ Coordinate\ Reference\ System:1]]
> Reproject_Shapefile_to_Image_CRS <- function(shapefile.dsn,
+                                              shapefile.layer,
+                                              image.path,
+                                              shapefile.out.dsn) {
+     r <- stack(image.path)
+     shapefile <- readOGR(shapefile.dsn, shapefile.layer)
+     shapefile.WimageCRS <- spTransform(shapefile, crs(r))
+     image.name <- extract.name.from.path(image.path)
+     shapefile.layer  <- str_c(image.name,"_",shapefile.layer)
+     writeOGR(shapefile.WimageCRS, shapefile.out.dsn, shapefile.layer, driver = "ESRI Shapefile", overwrite =T)
+ }
> ## Reproject\ Shapefile\ to\ Image\ Coordinate\ Reference\ System:1 ends here
> 
> ## [[file:utc.org::*get%20polygon%20ids][get\ polygon\ ids:1]]
> IDs.SpatialPolygonsDataFrame <- function(x,...) {
+     vapply(slot(x, "polygons"), function(x) slot(x, "ID"), "")
+ }
> ## get\ polygon\ ids:1 ends here
> 
> ## [[file:utc.org::*Crop%20image%20to%20each%20Shapefile%20polygon][Crop\ image\ to\ each\ Shapefile\ polygon:1]]
> Crop_image_to_each_Shapefile_polygon <- function(shapefile.dsn,
+                                                  shapefile.layer,
+                                                  image.path,
+                                                  cores,
+                                                  output.dir)  {
+     image.name <- extract.name.from.path(image.path)
+     shape <- readOGR(shapefile.dsn, str_c(image.name,"_",shapefile.layer))
+     polygons <- as(shape, "SpatialPolygons")
+ 
+     image <- stack(image.path)
+ 
+     cl <- makeCluster(cores)
+     registerDoParallel(cl)
+ 
+     foreach (i = seq_along(polygons),
+              .packages = c("raster")) %dopar% {
+                  r <- image
+                  r <- crop(r, polygons[i])
+                  writeRaster(r, paste0(output.dir,"/",image.name,".",i,".tif"),
+                              overwrite = T)
+              }
+ }
> ## Crop\ image\ to\ each\ Shapefile\ polygon:1 ends here
> 
> ## [[file:utc.org::*Crop%20image%20to%20regions%20around%20shapefile%20points][Crop\ image\ to\ regions\ around\ shapefile\ points:1]]
> # assign the polygon name to the points.
> give_polygons_attributes_of_first_point_within <- function(points,
+                                                            polygons){
+     if (length(points@data$row) >1) {
+         points <- points[points@data$row ==1 & points@data$col ==1 ,]
+     }
+     po <- gIntersects(points, polygons, byid=TRUE)
+     out <- foreach(polygon.number = seq_along(polygons), .combine = "rbind") %do% {
+         first.point.data <- points[po[polygon.number,],]@data %>%
+                                                        slice(1)
+         pd <- as(polygons[polygon.number], "SpatialPolygonsDataFrame")
+         pd@data <- first.point.data
+         pd
+     }
+ }
> 
> Crop_image_to_regions_around_points_nameBygrid<- function(shapefile.dsn,
+                                                           shapefile.layer,
+                                                           image.path,
+                                                           cores,
+                                                           output.dir,
+                                                           column.name = "unq__ID",
+                                                           point.buffer.size = 4,
+                                                           polygon.buffer.size = 15)  {
+     image.name <- extract.name.from.path(image.path)
+     points <- readOGR(shapefile.dsn,str_c(image.name,"_",shapefile.layer))
+     box <- gBuffer(points, width = point.buffer.size, byid = F)
+     box <- disaggregate(box)
+ 
+     polygons <- as(box, "SpatialPolygons")
+ 
+     polygons <- give_polygons_attributes_of_first_point_within(points,polygons)
+ 
+     image <- stack(image.path)
+ 
+     image.extent <- as(extent(image), "SpatialPolygons")
+     proj4string(image.extent) <- proj4string(image)
+ 
+     polygons.in.image <- foreach(i = seq_along(polygons),.combine = "c") %do% {
+         gIntersects(polygons[i,],image.extent)
+     }
+ 
+     polygons <- polygons[polygons.in.image,]
+ 
+     cl <- makeCluster(cores)
+     registerDoParallel(cl)
+ 
+     foreach (k = seq_along(polygons),
+              .packages = c("raster","rgeos")) %do% {
+                  r <- image
+                  poly <- gBuffer(polygons[k,],width = polygon.buffer.size, byid = T)
+                  r <- crop(r, poly)
+                  tile.id <- polygons@data[k,column.name]
+                  writeRaster(r, paste0(output.dir,"/",image.name,".",tile.id,".tif"),
+                              overwrite = T)
+              }
+ }
> 
>                                         #  shapefile.dsn = grid.accuracy.region.imageCRS.dsn
>                                         #  shapefile.layer = grid.accuracy.region.layer,
>                                         #  output.dir = image.cropped.to.grid.accuracy.dir
> 
> 
> Crop_image_to_regions_around_points <- function(shapefile.dsn,
+                                                 shapefile.layer,
+                                                 image.path,
+                                                 cores,
+                                                 output.dir)  {
+ 
+     points <- readOGR(shapefile.dsn, shapefile.layer)
+     box <- gBuffer(points, width = 8)
+     box <- disaggregate(box)
+ 
+     polygons <- as(box, "SpatialPolygons")
+ 
+     image <- stack(image.path)
+ 
+     cl <- makeCluster(cores)
+     registerDoParallel(cl)
+ 
+     foreach (i = seq_along(polygons),
+              .packages = c("raster")) %dopar% {
+                  r <- image
+                  r <- crop(r, polygons[i])
+                  writeRaster(r, paste0(output.dir,"/",i,".tif"),
+                              overwrite = T)
+              }
+ }
> ## Crop\ image\ to\ regions\ around\ shapefile\ points:1 ends here
> 
> ## [[file:utc.org::*Save%20each%20band][Save\ each\ band:1]]
> save_each_band <- function(tile.path, band.names) {
+     tile <- stack(tile.path)
+     names(tile) <- band.names
+     tile.name <- str_sub(basename(tile.path),1,-5)
+     writeRaster(tile, filename = paste0(dirname(tile.path),"/",tile.name,"_",names(tile), ".tif"), bylayer = T, format = "GTiff", overwrite = T)
+ }
> ## Save\ each\ band:1 ends here
> 
> ## [[file:utc.org::*Add%20Texture][Add\ Texture:1]]
> named.glcm <- function(tile.dir, tile.basename, band.appendage, window, statistics, shift, na_opt, na_val,...) {
+ 
+     tile.path <- paste0(tile.dir, "/", tile.basename,band.appendage,".tif")
+     x <- raster(tile.path)
+ 
+     if (statistics == "correlation") {
+         texture <- glcm(x, window = window, statistics = statistics, shift = shift, na_opt = na_opt, na_val = na_val)
+         texture[texture == -Inf] <- -1
+         texture[texture == Inf] <- 1
+         texture[is.na(texture)] <- 1
+     } else {
+         texture <- glcm(x, window = window, statistics = statistics, shift = shift, na_opt = na_opt, na_val = na_val)
+     }
+     win.size <- paste0("window.",window[1])
+     shift.dir <- paste0("angle.",atan(shift[1]/shift[2])*180/pi) # calc shift angle
+ 
+     tile.dir <- dirname(tile.path)
+     tile.name <- str_sub(basename(tile.path),1,-5)
+     fn = paste0(tile.dir,"/", tile.basename,band.appendage, "_stat.", statistics, "_", win.size,"_",shift.dir,".tif")
+     writeRaster(texture, fn, overwrite = T)
+ }
> 
> calc.texture <- function(texture.params.df,
+                          tile.dir,
+                          tile.basename) {
+ 
+     texture <- mapply(named.glcm,
+                       tile.dir = tile.dir,
+                       tile.basename = tile.basename,
+                       band.appendage = texture.params.df$band.appendage,
+                       window = texture.params.df$window,
+                       statistics = texture.params.df$statistics,
+                       shift = texture.params.df$shift,
+                       na_opt = "ignore",
+                       na_val = NA)
+ }
> ## Add\ Texture:1 ends here
> 
> ## [[file:utc.org::*Make%20new%20ratio%20bands%20from%20image][Make\ new\ ratio\ bands\ from\ image:1]]
> calc_ratios <- function(tile.path, band.names, ratio.bands, scale200 = T) {
+     tile <- stack(tile.path)
+     names(tile) <- band.names
+ 
+     ratios <- tile[[ratio.bands,drop = F]] / sum(tile)
+ 
+     if (scale200 == T) {
+         ratios <- ratios * 200
+     }
+ 
+     tile.name <- str_sub(basename(tile.path),1,-5)
+     names(ratios) <- paste0(tile.name,"_ratio.",ratio.bands)
+     writeRaster(ratios, filename= paste0(dirname(tile.path),"/",names(ratios),".tif"),
+                 bylayer = T, format= "GTiff", overwrite = T,
+                 datatype = 'INT1U')
+ }
> 
> calc_ndvi <- function(tile.path, band.names, ndvi_appendage = "_ndvi", scale200 = T) {
+ 
+     tile <- stack(tile.path)
+     names(tile) <- band.names
+ 
+     ndvi <- (tile[["nir"]] - tile[["red"]]) /  (tile[["nir"]] + tile[["red"]])
+ 
+     ndvi [ndvi < 0] <- 0
+ 
+     if (scale200 == T) {
+         ndvi <- ndvi * 200
+     }
+ 
+     tile.dir <- dirname(tile.path)
+     tile.name <- str_sub(basename(tile.path),1,-5)
+     writeRaster(ndvi, filename=paste0(tile.dir,"/",tile.name,ndvi_appendage,".tif"), bylayer=TRUE,format="GTiff", overwrite = T,datatype = 'INT1U')
+     return(ndvi)
+ }
> ## Make\ new\ ratio\ bands\ from\ image:1 ends here
> 
> ## [[file:utc.org::*Make%20Pixel%20Feature%20DF][Make\ Pixel\ Feature\ DF:1]]
> save.pixel.feature.df <- function(tile.dir,
+                                   tile.name,
+                                   feature.pattern,
+                                   feature.df.append = feature.df.appendage ) {
+     s <- stack(list.files(tile.dir, pattern = paste0(tile.name,feature.pattern), full.names = T))
+     names(s) <- sub(x = names(s), pattern = paste0("(",tile.name,"_)"), replacement = "")
+     s.df <- as.data.frame(s, xy = T)
+     saveRDS(s.df, file = paste0(tile.dir, "/", tile.name, "_Pixel",feature.df.append, ".rds"))
+ }
> ## Make\ Pixel\ Feature\ DF:1 ends here
> 
> ## [[file:utc.org::*Image%20PCA][Image\ PCA:1]]
> pca.transformation <- function(tile.dir,
+                                image.name,
+                                tile.name,
+                                loc,
+                                feature.pattern = "_(blue|green|red|nir|ratio.blue|ratio.green|ratio.red|ratio.nir|ndvi).tif",
+                                pca.append = pca.appendage,
+                                out.image.appendage = pca.appendage,
+                                comps.to.use = c(1,2,3),
+                                pca.dir = dd.pca.dir) {
+ 
+     s <- stack(list.files(tile.dir, pattern = paste0(tile.name,feature.pattern), full.names = T))
+     names(s) <- sub(x = names(s), pattern = ".*_", replacement = "")
+ 
+     pca.model <- readRDS(str_c(pca.dir,"/",loc,image.name,pca.append,".rds"))
+ 
+     r <- predict(s, pca.model, index = comps.to.use)
+ 
+     min.r <- getRasterMin(r)
+     max.r <- getRasterMax(r)
+     rescaled.r <- rescale.0.254(r, min.r, max.r)
+ 
+     out.path <- str_c(tile.dir, "/", tile.name, out.image.appendage, ".tif")
+     writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U', bylayer = F)
+ }
> 
> 
> getRasterMin <- function(t) {
+     return(min(cellStats(t, stat = "min")))
+ }
> 
> getRasterMax <- function(t) {
+     return(max(cellStats(t, stat = "max")))
+ }
> 
> rescale.0.254 <- function(raster,
+                           min,
+                           max) {
+                               (raster - min)/(max-min) * 254
+ }
> 
> ## image.pca <- function(image.name,
> ##                       pca.model.name.append = pca.model.name.appendage,
> ##                       tile.dir,
> ##                       tile.name,
> ##                       in.image.appendage = ratio.tile.name.append,
> ##                       out.image.appendage = pca.tile.name.append,
> ##                       band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi"),
> ##                       comps.to.use = c(1,2,3),
> ##                       pca.dir = dd.pca.dir) {
> 
> 
> ##     out.path <- str_c(tile.dir, "/", tile.name, out.image.appendage, ".tif")
> 
> ##     s <- stack(str_c(tile.dir, "/", tile.name, in.image.appendage,".tif"))
> ##     names(s) <- band.names
> 
> ##     pca.model <- readRDS(str_c(pca.dir,"/",image.name,pca.model.name.append))
> 
> ##     r <- predict(s, pca.model, index = comps.to.use)
> 
> ##     min.r <- getRasterMin(r)
> ##     max.r <- getRasterMax(r)
> ##     rescaled.r <- rescale.0.255(r, min.r, max.r)
> ##     writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')
> ## }
> 
> 
> make.and.save.pca.transformation <- function(image.dir,
+                                              image.name,
+                                              location,
+                                              pca.append = pca.appendage,
+                                              max.sample.size = 10000,
+                                              core.num = cores,
+                                              feature.pattern = ".*_(blue|green|red|nir|ratio.blue|ratio.green|ratio.red|ratio.nir|ndvi).tif",
+                                              ratio.appendage = ratio.tile.name.append) {
+ 
+     tile.paths <- list.files(image.dir, pattern = paste0(image.name,feature.pattern), full.names = T)
+ 
+     tile.names <- str_match(tile.paths,"(.*\\.[0-9]+)_.*")[,2] %>%  unique() # get the image names of pca regions
+ 
+     cl <- makeCluster(cores)
+     registerDoParallel(cl)
+ 
+     sr <- foreach (tile.name = tile.names, .packages = c("stringr","raster"), .combine ="rbind") %dopar% {
+         t.names <- str_extract(tile.paths, paste0(".*",tile.name,".*")) %>% na.omit()
+         tile <- stack(t.names)
+         names(tile) <- sub(x = names(tile), pattern = ".*_", replacement = "")
+         samp <- sampleRandom(tile, ifelse(ncell(tile) > max.sample.size ,max.sample.size, ncell(tile)))
+         colnames(samp) <- names(tile)
+         samp
+     }
+ 
+     stopImplicitCluster()
+                                         # Perform PCA on sample
+     pca <- prcomp(sr, scale = T)
+     saveRDS(pca,paste0(image.dir,"/",location,image.name,pca.append,".rds"))
+     return(pca)
+ }
> 
> 
> ## make.and.save.pca.transformation <- function(image.dir,
> ##                                              image.name,
> ##                                              pca.model.name.append = "_pca.rds",
> ##                                              max.sample.size = 10000,
> ##                                              core.num = cores,
> ##                                              band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi"),
> ##                                              ratio.appendage = ratio.tile.name.append) {
> ##     tile.paths <- list.files(str_c(image.dir), pattern = paste0("*",ratio.appendage), full.names = T)
> 
> ##     tile.names <- basename(tile.paths)
> 
> ##     cl <- makeCluster(core.num)
> ##     registerDoParallel(cl)
> 
> ##     sr <- foreach (i = seq_along(tile.names), .packages = c("raster"), .combine ="rbind") %dopar% {
> ##         tile <- stack(tile.paths[i])
> ##         s <- sampleRandom(tile, ifelse(ncell(tile) > max.sample.size ,max.sample.size, ncell(tile)))
> ##     }
> 
> ##     colnames(sr) <- band.names
> 
> ##                                         # Perform PCA on sample
> ##     pca <- prcomp(sr, scale = T)
> ##     saveRDS(pca,paste0(image.dir,"/",image.name,pca.model.name.append))
> 
> ##     return(pca)
> ## }
> 
> 
> image.pca.forWholeState <- function(pca.model.name.append = pca.model.name.appendage,
+                                     tile.dir,
+                                     tile.name,
+                                     in.image.appendage = ratio.tile.name.append,
+                                     out.image.appendage = pca.tile.name.append,
+                                     band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi"),
+                                     comps.to.use = c(1,2,3),
+                                     pca.transform) {
+ 
+ 
+     out.path <- str_c(tile.dir, "/", tile.name, out.image.appendage, ".tif")
+ 
+     s <- stack(str_c(tile.dir, "/", tile.name, in.image.appendage,".tif"))
+     names(s) <- band.names
+ 
+     r <- predict(s, pca.transform, index = comps.to.use)
+ 
+     min.r <- getRasterMin(r)
+     max.r <- getRasterMax(r)
+     rescaled.r <- rescale.0.254(r, min.r, max.r)
+     writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')
+ }
> 
> 
> 
> ## image.dir <- image.cropped.to.training.dir
> ## image.name <- 9
> ##                         in.image.appendage = ratio.tile.name.append
> ##                         out.image.appendage = pca.tile.name.append
> ##                         band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")
> ##                         max.sample.size = 10000
> ##                         comps.to.use = c(1,2,3)
> 
> ##       out.path <- str_c(image.dir, "/", image.name, out.image.appendage, ".tif")
> 
> ##       s <- stack(str_c(image.dir, "/", image.name, in.image.appendage,".tif"))
> ##       names(s) <- band.names
> 
> ##       sr <- sampleRandom(s, ifelse(ncell(s) > max.sample.size, max.sample.size, ncell(s)))
> ##       pca <- prcomp(sr, scale = T)
> 
> ##       r <- predict(s, pca, index = comps.to.use)
> 
> ##       min.r <- getRasterMin(r)
> ##       max.r <- getRasterMax(r)
> ##       rescaled.r <- rescale.0.255(r, min.r, max.r)
> ##       writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')
> 
> 
> 
> 
> 
> 
> 
> 
> 
>                                         # Function takes raster stack, samples data, performs pca and returns stack of first n_pcomp bands
>                                         ## predict_pca_wSampling_parallel <- function(stack, sampleNumber, n_pcomp, nCores = detectCores()-1) {
>                                         ##     sr <- sampleRandom(stack,sampleNumber)
>                                         ##     pca <- prcomp(sr, scale=T)
>                                         ##     beginCluster()
>                                         ##     r <- clusterR(stack, predict, args = list(pca, index = 1:n_pcomp))
>                                         ##     endCluster()
>                                         ##     return(r)
>                                         ## }
> ## Image\ PCA:1 ends here
> 
> ## [[file:utc.org::*Segment%20image][Segment\ image:1]]
> segment.multiple <- function(tile.dir,
+                              tile.name,
+                              image.name,
+                              segment.params.df,
+                              krusty  = T) {
+     segments <- mapply(segment,
+                        tile.dir = tile.dir,
+                        image.name = image.name,
+                        tile.name = tile.name,
+                        compactness = segment.params.df$compactness,
+                        segment.size = segment.params.df$segment.size,
+                        krusty = krusty)
+       }
> 
> segment  <- function(tile.dir,
+                      image.name,
+                      tile.name,
+                      compactness,
+                      segment.size,
+                      krusty = T) {
+     pixel_size <- ifelse(image.name == "NAIP", 1, 1.5)
+     compactness <- if(image.name == "NAIP") compactness else round(2/3*compactness)
+     if (krusty == T) {
+         system(paste("/home/erker/.conda/envs/utc/bin/python","fia_segment_cmdArgs.py",pixel_size,segment.size,compactness,tile.name,tile.dir))
+     } else {
+         system(paste("python","fia_segment_cmdArgs.py",pixel_size,segment.size,compactness,tile.name,tile.dir))
+     }
+ }
> ## Segment\ image:1 ends here
> 
> ## [[file:utc.org::*add.features][add\.features:1]]
> add.features <- function(tile.dir,
+                          tile.name,
+                          band.names,
+                          ndvi = T,
+                          ratio.bands,
+                          texture = T,
+                          texture.params.df) {
+ 
+     til.path <- paste0(tile.dir,"/",tile.name,".tif")
+     til <- stack(til.path)
+     names(til) <- band.names
+ 
+     save_each_band(tile.path = til.path,
+                    band.names = band.names)
+ 
+     if (ndvi == T) {
+         calc_ndvi(tile.path = til.path,
+                   band.names = band.names)
+     }
+ 
+     if (length(ratio.bands > 0)) {
+         calc_ratios(tile.path = til.path,
+                     band.names = band.names,
+                     ratio.bands = ratio.bands)
+     }
+ 
+     if (texture == T) {
+         calc.texture(texture.params.df = texture.params.df,
+                      tile.dir = tile.dir,
+                      tile.basename = tile.name)
+     }
+ }
> ## add\.features:1 ends here
> 
> ## [[file:utc.org::*segment%20Feature%20DF][segment\ Feature\ DF:1]]
> make.segment.feature.df.foreach.segmentation <- function(tile.dir,
+                                                          tile.name,
+                                                          feature.pattern,
+                                                          segmentation.pattern = "_N-[0-9]+_C-[0-9]+.*") {
+ 
+     segmentation.files <-  list.files(tile.dir, pattern = paste0(tile.name,segmentation.pattern))
+     segmentation.param.appendages <- str_match(segmentation.files,paste0(tile.name,"(_.*).tif"))[,2] %>% na.omit()
+ 
+ 
+     out <- lapply(X = segmentation.param.appendages, FUN = function(segmentation.param.appendage) {
+         make.segment.feature.df(tile.dir = tile.dir,
+                                 tile.name = tile.name,
+                                 segmentation.param.appendage = segmentation.param.appendage,
+                                 fea.pattern = feature.pattern)
+     })
+ 
+ }
> 
> 
> make.segment.feature.df <- function(tile.dir,
+                                     tile.name,
+                                     segmentation.param.appendage,
+                                     fea.pattern,
+                                     feature.df.append = feature.df.appendage) {
+ 
+     fea <- stack(list.files(tile.dir, pattern = paste0(tile.name,fea.pattern), full.names = T))
+     names(fea) <- sub(x = names(fea), pattern = "(madisonNAIP|madisonPanshpSPOT).*?_", replacement = "")
+ 
+     seg.path <- paste0(tile.dir,"/",tile.name,segmentation.param.appendage, ".tif")
+     seg <- raster(seg.path)
+ 
+                                         # Create a data_frame where mean and variances are calculated by zone
+     x <- as.data.frame(fea, xy = T)
+     s <- as.data.frame(seg)
+     colnames(s) <- "segment"
+     r <- bind_cols(x,s)
+     r2 <- r %>%
+         group_by(segment)
+ 
+     mean.and.sd <- r2 %>%
+         summarize_each(funs(mean(.,na.rm = T), sd(., na.rm = T))) %>%
+         select(-x_mean, -x_sd, -y_mean, -y_sd)
+ 
+     tile.name.df = data.frame(tile.name = rep(tile.name, nrow(mean.and.sd)))
+ 
+     out <- bind_cols(mean.and.sd, tile.name.df)
+ 
+ 
+     names <- colnames(out)
+     names <- str_replace(names, "\\(",".")
+     names <- str_replace(names, "\\)",".")
+     names <- str_replace(names, "\\:",".")
+     colnames(out) <- names
+     saveRDS(out, file = paste0(tile.dir,"/",tile.name,segmentation.param.appendage,feature.df.append,".rds"))
+     out
+ }
> 
> 
> 
>                                         #  make.segment.feature.df(dd.training.dir, "madisonNAIP.1", segmentation.param.appendage = "_N-100_C-10", feature.pattern = feature.pattern)
> ## segment\ Feature\ DF:1 ends here
> 
> ## [[file:utc.org::*make.feature.df][make\.feature\.df:1]]
> make.feature.df <- function(tile.dir,
+                             image.name,
+                             tile.name,
+                             band.names,
+                             ndvi = T,
+                             ratio.bands,
+                             texture = T,
+                             texture.params.df,
+                             feature.pattern = "_(blue|green|red|nir|ratio.blue|ratio.green|ratio.red|ratio.nir|ndvi|ratio.nir_stat\\.\\w+_window\\.\\d+_angle\\..?\\d+).tif",
+                             pixel.df,
+                                         #                              pca.features = c("blue","green","red","nir","ndvi","ratio.blue","ratio.green","ratio.red","ratio.nir"),
+                             pca.features = c("blue","green","red","nir"),
+                             pca.location,
+                             segmentation = T,
+                             segment.params.df,
+                             segment.feature.df = T,
+                             using.krusty = T) {
+ 
+     add.features(tile.dir,
+                  tile.name,
+                  band.names,
+                  ndvi = T,
+                  ratio.bands,
+                  texture = T,
+                  texture.params.df)
+ 
+     message ( tile.name,"features added")
+ 
+     if (pixel.df ==T) {
+ 
+         save.pixel.feature.df(tile.dir = tile.dir,
+                               tile.name = tile.name,
+                               feature.pattern)}
+ 
+     message("pixel feature df saved")
+ 
+     pca.transformation(tile.dir = tile.dir,
+                        tile.name = tile.name,
+                        image.name = image.name,
+                        loc = pca.location)
+ 
+     message("pca done")
+ 
+     if (segmentation == T) {
+ 
+         segment.multiple(tile.dir = tile.dir,
+                          tile.name = tile.name,
+                          image.name = image.name,
+                          segment.params.df = segment.params.df,
+                          krusty = using.krusty)}
+     message("segmentation done")
+     if (segment.feature.df == T) {
+ 
+         make.segment.feature.df.foreach.segmentation(tile.dir = tile.dir,
+                                                      tile.name = tile.name,
+                                                      feature.pattern = feature.pattern)}
+ 
+ 
+ }
> ## make\.feature\.df:1 ends here
> 
> ## [[file:utc.org::*polygonize%20segment%20raster%20with%20gdal%20and%20add%20Class%20to%20shapefile][polygonize\ segment\ raster\ with\ gdal\ and\ add\ Class\ to\ shapefile:1]]
> gdal_polygonizeR <- function(x, outshape=NULL, gdalformat = 'ESRI Shapefile',
+                              pypath=NULL, readpoly=TRUE, quiet=TRUE) {
+     if (isTRUE(readpoly)) require(rgdal)
+     if (is.null(pypath)) {
+         pypath <- Sys.which('gdal_polygonize.py')
+     }
+     if (!file.exists(pypath)) stop("Can't find gdal_polygonize.py on your system.")
+     owd <- getwd()
+     on.exit(setwd(owd))
+     setwd(dirname(pypath))
+     if (!is.null(outshape)) {
+         outshape <- sub('\\.shp$', '', outshape)
+         f.exists <- file.exists(paste(outshape, c('shp', 'shx', 'dbf'), sep='.'))
+         if (any(f.exists))
+             stop(sprintf('File already exists: %s',
+                          toString(paste(outshape, c('shp', 'shx', 'dbf'),
+                                         sep='.')[f.exists])), call.=FALSE)
+     } else outshape <- tempfile()
+     if (is(x, 'Raster')) {
+         require(raster)
+         writeRaster(x, {f <- tempfile(fileext='.asc')})
+         rastpath <- normalizePath(f)
+     } else if (is.character(x)) {
+         rastpath <- normalizePath(x)
+     } else stop('x must be a file path (character string), or a Raster object.')
+     system2('python', args=(sprintf('"%1$s" "%2$s" -f "%3$s" "%4$s.shp"',
+                                     pypath, rastpath, gdalformat, outshape)))
+     if (isTRUE(readpoly)) {
+         shp <- readOGR(dirname(outshape), layer = basename(outshape), verbose=!quiet)
+         return(shp)
+     }
+     return(NULL)
+ }
> 
> 
> polygonize.and.add.Class <- function(image.dir,
+                                      image.name,
+                                      segment.appendage = segment.tile.name.append,
+                                      no.class = "N") {
+     seg <- raster(paste0(image.dir,"/",image.name,segment.appendage,'.tif'))
+     segPoly <- gdal_polygonizeR(seg)
+     segPoly$Class <- no.class
+     writeOGR(obj = segPoly,
+              dsn = paste0(image.dir,"/",image.name),
+              layer = paste0(image.name,segment.appendage),
+              driver = "ESRI Shapefile",
+              overwrite = T)
+ }
> ## polygonize\ segment\ raster\ with\ gdal\ and\ add\ Class\ to\ shapefile:1 ends here
> 
> ## [[file:utc.org::*Create%20ModelBuilding%20dataframe][Create\ ModelBuilding\ dataframe:1]]
> getSegment.class.and.features.Within.Polygon<-function(SegmentFeatureDF,
+                                                        training.sp,
+                                                        seg.tiles.dir,
+                                                        seg.params){
+     seg.files <- list.files(seg.tiles.dir, pattern = str_c(seg.params,".tif$"), full.names = T)
+                                         # find number of pixels in each segment
+     n.pixels.per.seg <- foreach(seg.file = seg.files, .combine = "rbind") %do% {
+         seg <- raster::stack(seg.file)
+         s.df <- as.data.frame(seg) %>%
+             gather(key = image.name, value = segment.id) %>%
+             group_by(segment.id, image.name) %>%
+             summarize(n.pixels.per.seg = n())
+     }
+                                         # find number of pixels in each segment are in a polygon
+     n.pixels.per.seg.in.polygon <- foreach(seg.file = seg.files, .combine = "rbind") %do% {
+ 
+         seg <- raster::stack(seg.file)
+         ei <- as(extent(seg), "SpatialPolygons")
+ 
+         if(gIntersects(ei, as(training.sp,"SpatialPolygons"))) {
+ 
+             a <- raster::extract(seg, as(training.sp,"SpatialPolygons"), df = T)
+ 
+             a <- a %>%
+                 gather(key = image.name, value = segment.id, -ID) %>%
+                 rename(polygon.id = ID) %>%
+                 group_by(polygon.id, image.name, segment.id) %>%
+                 summarize(n.pixels.per.seg.in.polygon = n())
+         }
+     }
+                                         # get pct of segment in a polygon,
+                                         # filter segments that have more than 50%,
+                                         #join Class information from polygons
+     if(!is.null(n.pixels.per.seg.in.polygon)) {
+ 
+                                         #add 1 because the id from raster's extract is just the order of the polygons
+         training.sp@data$polygon.id <- as.numeric(IDs.SpatialPolygonsDataFrame(training.sp))+1
+ 
+         n.pixels <- left_join(n.pixels.per.seg.in.polygon,n.pixels.per.seg) %>%
+             mutate(pct.seg.in.polygon = n.pixels.per.seg.in.polygon/n.pixels.per.seg) %>%
+             filter(pct.seg.in.polygon >= .5) %>%
+             left_join(.,training.sp@data) %>%
+             ungroup() %>%
+             mutate(segment = segment.id)
+ 
+ 
+         n.pixels$image.name <- str_match(n.pixels$image.name, "(.*?\\.[0-9]+).*")[,2]
+ 
+         out <- left_join(n.pixels, SegmentFeatureDF) %>%
+             distinct() %>%
+             dplyr::select(-id,
+                           -segment,
+                           -segment.id,
+                           -image.name,
+                           -image.name,
+                           -tile.name,
+                           -polygon.id,
+                           -n.pixels.per.seg,
+                           -n.pixels.per.seg.in.polygon,
+                           -pct.seg.in.polygon)        %>%
+             filter(complete.cases(.))
+ 
+         out
+     }
+ }
> 
>                                         # returns dataframe of values of pixels within polygon
> getPixel.Class.and.Coords.Within.Polygon <- function(PixelFeatureDF,
+                                                      training.sp) {
+     xy <- dplyr::select(PixelFeatureDF,x,y) %>% data.frame
+     PixelFeatureDF <- data.frame(PixelFeatureDF)
+     coordinates(PixelFeatureDF) <- xy
+     proj4string(PixelFeatureDF) <- utm16
+ 
+     training.sp <- spTransform(training.sp,utm16)
+ 
+     pts.in.poly <- sp::over(PixelFeatureDF,training.sp)
+     PixelFeatureDF@data <- cbind(PixelFeatureDF@data, pts.in.poly)
+     PixelFeatureDF <- PixelFeatureDF[which(complete.cases(pts.in.poly)),]
+     PixelFeatureDF@data
+ }
> ## Create\ ModelBuilding\ dataframe:1 ends here
> 
> ## [[file:utc.org::*untuned][untuned:1]]
> Build.and.Save.models <- function(dir = dd.training.dir,
+                                   modelBuildingData = ModelBuildingRDS,
+                                   models.dir = dd.models.dir,
+                                   image.name,
+                                   location,
+                                   model.append = model.appendage){
+ 
+     dat <- readRDS(paste0(dir,"/",modelBuildingData)) %>%
+         as.data.frame() %>%
+         filter(complete.cases(.))
+ 
+     seg.p <- str_extract(modelBuildingData, segmentation.pattern)
+ 
+     names <- colnames(dat)
+     names <- str_replace(names, "\\(",".")
+     names <- str_replace(names, "\\)",".")
+     names <- str_replace(names, "\\:",".")
+     colnames(dat) <- names
+ 
+                                         # Create Tasks
+     tsk <- makeClassifTask(id = paste0(location,image.name,"_all"), data = dat, target = "Class")
+ 
+                                         # Make Learners
+     RF_prob <- makeLearner(id = "rf_prob","classif.randomForest", predict.type = "prob", fix.factors.prediction = TRUE)
+                                         #      RF_response <- makeLearner(id = "rf_resp", "classif.randomForest", predict.type = "response", fix.factors.prediction = TRUE)
+     SVM_response <- makeLearner(id = "svm_resp", "classif.svm", predict.type = "response", fix.factors.prediction = TRUE)
+ 
+                                         #      learner.list <- list(RF_prob = RF_prob, RF_response = RF_response, SVM_response = SVM_response)
+     learner.list <- list(RF_prob = RF_prob, SVM_response = SVM_response)
+ 
+                                         # Train Learners on Tasks, Make models
+                                         #         cl<-makeCluster(cores)
+                                         #         registerDoParallel(cl)
+ 
+     models <- foreach(lnr = learner.list) %do% {
+         mod <- train(lnr, tsk)
+         mod
+         saveRDS(mod, file = paste0(models.dir,"/",location,image.name,"_",seg.p, "_",lnr$id,"_Untuned",model.append, ".rds"))
+     }
+ }
> ## untuned:1 ends here
> 
> ## [[file:utc.org::*features%20selected][features\ selected:1]]
> print.feature.importance <- function(dir = dd.training.dir,
+                                   modelBuildingData = ModelBuildingRDS,
+                                   image.name,
+                                   location,
+                                   feature.importance.methods = c("information.gain","chi.squared")) {
+ 
+ 
+     dat <- readRDS(paste0(dir,"/",modelBuildingData)) %>%
+         as.data.frame() %>%
+         filter(complete.cases(.))
+ 
+     seg.p <- str_extract(modelBuildingData, segmentation.pattern)
+ 
+     names <- colnames(dat)
+     names <- str_replace(names, "\\(",".")
+     names <- str_replace(names, "\\)",".")
+     names <- str_replace(names, "\\:",".")
+     colnames(dat) <- names
+ 
+                                         # Create Tasks
+     tsk <- makeClassifTask(id = paste0(location,image.name,"_all"), data = dat, target = "Class")
+ 
+     fv = generateFilterValuesData(tsk, method = feature.importance.methods)
+ 
+     fv$data %>% arrange_(feature.importance.methods[1])
+ }
> ## features\ selected:1 ends here
> 
> ## [[file:utc.org::*features%20selected][features\ selected:2]]
> Build.and.Save.FeatureSelected.models <- function(dir = dd.training.dir,
+                                   modelBuildingData = ModelBuildingRDS,
+                                   models.dir = dd.models.dir,
+                                   image.name,
+                                   location,
+                                   model.append = model.appendage){
+ 
+     dat <- readRDS(paste0(dir,"/",modelBuildingData)) %>%
+         as.data.frame() %>%
+         filter(complete.cases(.))
+ 
+     seg.p <- str_extract(modelBuildingData, segmentation.pattern)
+ 
+     names <- colnames(dat)
+     names <- str_replace(names, "\\(",".")
+     names <- str_replace(names, "\\)",".")
+     names <- str_replace(names, "\\:",".")
+     colnames(dat) <- names
+ 
+ 
+                                         # Create Tasks
+     tsk <- makeClassifTask(id = paste0(location,image.name,"_all"), data = dat, target = "Class")
+ 
+ 
+                                         # Make Learners
+     RF_prob <- makeLearner(id = "rf_prob","classif.randomForest", predict.type = "prob", fix.factors.prediction = TRUE)
+     SVM_response <- makeLearner(id = "svm_resp", "classif.svm", predict.type = "response", fix.factors.prediction = TRUE)
+ 
+ 
+                                         # make filter wrappers
+     RF_prob_fil <- makeFilterWrapper(RF_prob, fw.method = "chi.squared")
+     SVM_response_fil <- makeFilterWrapper(SVM_response, fw.method = "chi.squared")
+ 
+ 
+                                         # make tune wrapper for feature selection
+     # inner
+     ps = makeParamSet(makeDiscreteParam("fw.abs", values = seq_len(getTaskNFeats(tsk))))
+     ctrl = makeTuneControlGrid()
+     inner = makeResampleDesc("CV", iter = 2)
+ 
+     RF_prob_tunfil = makeTuneWrapper(RF_prob_fil, resampling = inner, par.set = ps, control = ctrl, show.info = FALSE)
+ 
+     SVM_response_tunfil = makeTuneWrapper(SVM_response_fil, resampling = inner, par.set = ps, control = ctrl, show.info = FALSE)
+ 
+     learner.list <- list(RF_prob_tunfil = RF_prob_tunfil, SVM_response_tunfil = SVM_response_tunfil)
+ 
+     # outer
+     outer = makeResampleDesc("Subsample", iter = 3)
+     res = benchmark(tasks = tsk, learners = learner.list, resampling = outer, show.info = FALSE)
+ 
+ res
+ 
+ 
+     models <- foreach(lnr = learner.list) %do% {
+         mod <- train(lnr, tsk)
+         mod
+         saveRDS(mod, file = paste0(models.dir,"/",location,image.name,"_",seg.p, "_",lnr$id,"_FeatureSelected",model.append, ".rds"))
+     }
+ }
> ## features\ selected:2 ends here
> 
> ## [[file:utc.org::*tuned][tuned:1]]
> 
> ## tuned:1 ends here
> 
> ## [[file:utc.org::*Classify%20Raster][Classify\ Raster:1]]
> classify.segmented.raster <- function(segment.feature.df.dir,
+                                       segment.dir,
+                                       model.dir,
+                                       model.name.rds = "models",
+                                       segment.feature.appendage = segment.feature.df.name.append,
+                                       segmentation.appendage = segment.tile.name.append,
+                                       segmentation.prms,
+                                       classify.out.dir,
+                                       tile.name = i) {
+     df <- readRDS(paste0(segment.feature.df.dir,"/",tile.name,segment.feature.appendage))
+     mod <-readRDS(paste0(model.dir,"/",model.name.rds))
+                                         #    umod <- unlist(models, recursive = F)
+     seg.path <- paste0(segment.dir,"/",tile.name,segmentation.appendage)
+     seg <- raster(seg.path)
+                                         #       dfRowsWithNA <- which(is.na(df[,2]))
+     complete.df <- df[complete.cases(df),] # svm can't predict with NAs
+ 
+     pred <- predict(mod, newdata = complete.df)
+     response <- factor(as.character(pred$data$response), levels = c("g","i","t","o"))
+     m <- cbind(zone = complete.df$segment, response)
+     m <- left_join(as.data.frame(df["segment"]), as.data.frame(m), by = c("segment" = "zone"))
+     seg.df <- as.data.frame(seg, xy = T)
+     names(seg.df)[3] <- "segment"
+     seg.df <- left_join(seg.df, m)
+     seg.df$response <- mapvalues(seg.df$response, from = c(1,2,3,4), to = c("g","i","t","o"))
+     seg.df$response <- factor(seg.df$response)
+     r <- seg
+     values(r) <- seg.df$response
+ 
+                                         #        x <- data.frame(ID = 1:4, LandCover = c("G","I","T","O")) %>%
+                                         #            filter(LandCover %in% levels(factor(response)))
+                                         #        levels(r) <- x
+                                         # Removing Probability layer because can't have attributes with it.  When I do final classifcaiton I should add back in.
+ 
+     ## if (ncol(pred$data) > 2) {
+     ##     prob <- (pred$data[,grep("prob.*", x = colnames(pred$data))]) # get columns that contain probabilities
+     ##     ProbOfClass <- apply(prob, MARGIN = 1, FUN = max)
+     ##     m <- cbind(segment = df$segment, ProbOfClass)
+     ##     m <- left_join(as.data.frame(df["segment"]), as.data.frame(m))
+     ##     p <- reclassify(seg, m)
+     ##     r <- stack(r,p)
+     ## }
+     path <- paste0(dd.accuracy.classified.dir,"/",tile.name,"_",segmentation.prms,"_",mod$task.desc$id,"_",mod$learner$id,".tif")
+     writeRaster(r, path, overwrite=TRUE)
+     print(path)
+ 
+ }
> 
> 
> 
> 
> classify.pixel.raster <- function(tile.dir = dd.accuracy.dir,
+                                   tile.name,
+                                   pixelFeatureDF.appendage = pixel.feature.df.appendage,
+                                   model.dir = Models.dir,
+                                   model.rds,
+                                   seg.prms = "Pixel") {
+     ras <- stack(str_c(tile.dir,"/",tile.name,".tif"))
+     pix.mod <- readRDS(str_c(model.dir,"/",model.rds))
+                                         #      pix.umods <- unlist(pix.mods, recursive = F)
+ 
+     pix.feature.df <- readRDS(str_c(tile.dir,"/",tile.name,"_",seg.prms,pixelFeatureDF.appendage,".rds"))
+ 
+     if(!is.null(pix.feature.df$y)) {
+         pix.feature.df <- dplyr::select(pix.feature.df, -x, -y)
+     }
+ 
+                                         # I set NA's to 0 here.  Not the best choice.  Not sure why they exist.
+                                         # Maybe because pca transform
+                                         # imputing to mean would probably be better
+ 
+     pix.feature.df <- as.matrix(pix.feature.df)
+ 
+     pix.feature.df[which(is.na(pix.feature.df))] <- 0
+ 
+     pix.feature.df <- as.data.frame(pix.feature.df)
+ 
+     pred <- predict(pix.mod, newdata = pix.feature.df)
+     a <- ras[[1]]
+     values(a) <- pred$data$response
+     path <- paste0(dd.accuracy.classified.dir,"/",tile.name,"_",seg.prms,"_",pix.mod$task.desc$id,"_",pix.mod$learner$id,".tif")
+     writeRaster(a, path, overwrite = T)
+     print(path)
+ }
> ## Classify\ Raster:1 ends here
> 
> ## [[file:utc.org::*Calculate%20Percent%20Cover%20in%20Classified%20Tiles][Calculate\ Percent\ Cover\ in\ Classified\ Tiles:1]]
> get.prcnt.class <- function(points,r) {
+     r <- crop(r,points)  # should I do a mask instead??
+     g <- cellStats(r == 1, stat = sum)
+     im <- cellStats(r == 2, stat = sum)
+     tr <- cellStats(r == 3, stat = sum)
+     o <-  cellStats(r == 4, stat = sum)
+     totC <- ncell(r)
+     return(c(pct_g_pred = g/totC, pct_i_pred = im/totC, pct_t_pred = tr/totC, pct_o_pred = o/totC))
+ }
> 
> 
> get_area_convexHull <- function(points) {
+     ch <- chull(coordinates(points))
+     coords <- coordinates(points)[c(ch,ch[1]),]
+     poly <- SpatialPolygons(list(Polygons(list(Polygon(coords)),ID = 1)))
+     gArea(poly)
+ }
> 
> 
> 
> calculate.percent.cover.in.classified.tile <- function(pts,
+                                                        tile.dir = dd.accuracy.classified.dir,
+                                                        tile.pth,
+                                                        n.rows.and.columns.subset,
+                                                        mod = 1,
+                                                        mad.grid.id.pattern = "mad-[0-9]+m-[0-9]+",
+                                                        grid.pattern = "[a-zA-Z]{3}-[0-9]+m-[0-9]+_",
+                                                        image.pattern = "[a-zA-Z]{5}[a-zA-Z]+",
+                                                        target.pattern = "all|grass|impervious|tree",
+                                                        model.pattern = "rf_prob|rf_resp|svm_resp",
+                                                        seg.prms = "N-[0-9]+_C-[0-9]+|Pixel"
+                                                        ) {
+     tile.nm <- basename(tile.pth)
+ 
+ 
+     pts.sub <- pts@data  %>%
+         filter.by.row.and.col(.,n.rows.and.columns.subset, mod = mod)
+ 
+     coordinates(pts.sub) <- ~ crds_x1 + crds_x2
+ 
+     proj4string(pts.sub) <- utm16
+     tile.unique.name <- str_extract(tile.pth, mad.grid.id.pattern)
+     pts.at.grid <- pts.sub[which(pts.sub@data$unq__ID == tile.unique.name),]
+     tile <- raster(tile.pth, proj4string = "+init:epsg=32616")
+ 
+     area.pts <- get_area_convexHull(pts.at.grid)
+ 
+     if(!is.null(raster::intersect(extent(tile),bbox(pts.at.grid)))) {
+ 
+         get.prcnt.class(pts.at.grid,tile) %>%
+             t() %>%
+             as.data.frame() %>%
+             mutate(grid.tile.target.model = tile.nm,
+                    grid = str_sub(str_extract(grid.tile.target.model, grid.pattern),1,-2),
+                    image =  str_extract(grid.tile.target.model, image.pattern),
+                    target.cover = str_extract(grid.tile.target.model, target.pattern),
+                    model =  str_extract(grid.tile.target.model, model.pattern),
+                    n.points = n.rows.and.columns.subset * n.rows.and.columns.subset,
+                    area = area.pts,
+                    seg.params = str_extract(grid.tile.target.model, seg.prms),
+                    target.type = ifelse(target.cover == "all", "multinomial", "binomial"))
+     }
+ }
> ## Calculate\ Percent\ Cover\ in\ Classified\ Tiles:1 ends here
> 
> ## [[file:utc.org::*Calculate%20Percent%20Cover%20of%20Grids,%20subsetted][Calculate\ Percent\ Cover\ of\ Grids\,\ subsetted:1]]
> filter.by.row.and.col <- function(df,nrow.and.col, mod) {
+     nrow <-df %>%
+         group_by(unq__ID) %>%
+         summarize(nrow = max(row))
+ 
+     df <- left_join(df,nrow)
+ 
+     df %>%
+         filter(nrow >= nrow.and.col,   # remove grids that have fewer than the number of rows & columns
+                row <= nrow.and.col,    # remove rows greater than the number we are interested in
+                col <=nrow.and.col,   # same for columns as rows
+                row %% mod == 0,
+                col %% mod == 0)
+ }
> 
> add.n.pts.per.grid <- function(df){
+     n.pts<-df %>%
+         group_by(unq__ID) %>%
+         summarize(n.points = n())
+ 
+     left_join(df,n.pts)
+ }
> 
> 
> get.pct.cvr.typ <- function(df) {
+     df %>%
+         group_by(unq__ID, cvr_typ,n.points, area) %>%
+         summarize(number = n()) %>%
+         ungroup() %>%
+         mutate(google.truth.pct.cover = number/n.points) %>%
+         dplyr::select(-number)
+ }
> 
> combine.classes.to.g.i.t.o <- function(df) {
+ 
+     df %>%
+         mutate(cvr_typ = as.character(cvr_typ),
+                cvr_typ = ifelse(cvr_typ == "s",
+                                 "i",
+                                 cvr_typ),
+                cvr_typ = ifelse(cvr_typ != "g" &
+                                 cvr_typ != "i" &
+                                 cvr_typ != "t", "o", cvr_typ)) %>%
+         group_by(unq__ID, cvr_typ, n.points, area) %>%
+         summarize(google.truth.pct.cover = sum(google.truth.pct.cover))
+ 
+ }
> 
> 
> calc.binomial.pct.cvrs <- function(df) {
+ 
+     out <- foreach(target.cvr.type = c("g","i","t")) %do%{
+         df %>%
+             mutate(cvr_typ = ifelse(cvr_typ == target.cvr.type, cvr_typ, "o")) %>%
+             group_by(unq__ID, n.points, cvr_typ) %>%
+             summarize(pct.cover = sum(pct.cover)) %>%
+             mutate(target.type = "binomial",
+                    target.cover = target.cvr.type,
+                    target.cover = ifelse(target.cover == "g", "grass",
+                                   ifelse(target.cover == "t", "tree",
+                                          "impervious"))) %>%
+             spread(key = cvr_typ, value = pct.cover)
+     }
+     out <- bind_rows(out)
+     out %>%
+         rename(pct.g.googleEarth = g, pct.i.googleEarth = i, pct.t.googleEarth = t, pct.o.googleEarth = o)
+ }
> 
> 
> 
> get.area.convexHull <- function(x_coord, y_coord) {
+     m <- matrix(c(x_coord, y_coord), ncol = 2)
+     ch <- chull(m)
+     coords <- m[c(ch,ch[1]),]
+     poly <- SpatialPolygons(list(Polygons(list(Polygon(coords)),ID = 1)))
+     gArea(poly)
+ }
> 
> 
> 
> calc.pct.cvr.for.grid.subset <- function(df,
+                                          n.rows.and.columns.for.subset=20,
+                                          mod,
+                                          gridID = "unq__ID") {
+ 
+ 
+     df <- filter.by.row.and.col(df, n.rows.and.columns.for.subset, mod) %>%
+         add.n.pts.per.grid() %>%
+         group_by_(gridID)
+ 
+ 
+     area.df <- df %>%
+         summarize(area = get.area.convexHull(crds_x1, crds_x2))
+ 
+     df <- left_join(df, area.df)
+ 
+ 
+     df <- df %>%
+         get.pct.cvr.typ() %>%
+         combine.classes.to.g.i.t.o() %>%
+                                         #               ungroup() %>%
+                                         #               dplyr::select(-n.points) %>%
+         spread(., key = cvr_typ, value = google.truth.pct.cover, fill = 0)
+ 
+                                         #         df[is.na(df)] <- 0
+ 
+     df.multnm <- df %>%
+         mutate(target.type = "multinomial") %>%
+         rename(pct.g.googleEarth = g, pct.i.googleEarth = i, pct.t.googleEarth = t) %>%
+         mutate(target.cover = "all")
+ 
+     if(!is.null(df.multnm$o)) { df.multnm <- rename(df.multnm, pct.o.googleEarth = o)}
+ 
+     df <- df %>%
+         gather(key = cvr_typ, value = pct.cover, -unq__ID, -n.points)
+ 
+     df.binm <- df %>%
+         calc.binomial.pct.cvrs()
+ 
+ 
+     df.out <- bind_rows(df.binm, df.multnm)
+     return(df.out)
+ }
> ## Calculate\ Percent\ Cover\ of\ Grids\,\ subsetted:1 ends here
> 
> ## [[file:utc.org::*Point-wise%20error%20functions][Point-wise\ error\ functions:1]]
> calcErrorAllMultinomial <-  function(pts, tile, Pixel = F) {
+     classification <- raster::extract(classified.tile, pts)
+     if(Pixel == T) {
+         lvls <- levels(classified.tile)[[1]]
+         classification <- mapvalues(classification, from = lvls[,1], to = as.character(lvls[,2]))
+     } else {
+         m <- tile@data@attributes[[1]]
+         classification <- mapvalues(classification, from = m$ID, to = levels(m$category))
+     }
+     google = pts@data$cvr_typ
+     overall.error <- 1 - mean(classification == google, na.rm = T)
+     pct.grass.classified.as.other <- 1 - mean(classification[which(google == "g")] == google[which(google == "g")], na.rm = T)
+     pct.impervious.classified.as.other <- 1 - mean(classification[which(google == "i")] == google[which(google == "i")], na.rm = T)
+     pct.tree.classified.as.other <- 1 - mean(classification[which(google == "t")] == google[which(google == "t")], na.rm = T)
+     error <- c(overall.error = overall.error,
+                pct.grass.classified.as.other = pct.grass.classified.as.other,
+                pct.impervious.classified.as.other = pct.impervious.classified.as.other,
+                pct.tree.classified.as.other = pct.tree.classified.as.other)
+     return(error)
+ }
> 
> calcErrorBinomial <-  function(pts, tile, target, Pixel = F) {
+     classification <- raster::extract(classified.tile, pts)
+     if(Pixel == T) {
+         lvls <- levels(classified.tile)[[1]]
+         classification <- mapvalues(classification, from = lvls[,1], to = as.character(lvls[,2]))
+     } else {
+         classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
+     }
+     classification <- ifelse(classification == target, classification, "o")
+     google <- pts@data$cvr_typ
+     google <- ifelse(google == target, google, "o")
+     overall.error <- 1 - mean(classification == google)
+     pct.grass.classified.as.other <- 1 - mean(classification[which(google == "g")] == google[which(google == "g")])
+     pct.impervious.classified.as.other <- 1 - mean(classification[which(google == "i")] == google[which(google == "i")])
+     pct.tree.classified.as.other <- 1 - mean(classification[which(google == "t")] == google[which(google == "t")])
+     error <- c(overall.error = overall.error,
+                pct.grass.classified.as.other = pct.grass.classified.as.other,
+                pct.impervious.classified.as.other = pct.impervious.classified.as.other,
+                pct.tree.classified.as.other = pct.tree.classified.as.other)
+     return(error)
+ }
> 
> 
> 
> 
> calcConfusionMat <- function(pts, tile) {
+     classification <- raster::extract(classified.tile, pts)
+     classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
+     table(classification, google = pts@data$cvr_typ)
+ }
> ## Point-wise\ error\ functions:1 ends here
> 
> ## [[file:utc.org::*Plot%20points%20on%20classifed%20tile][Plot\ points\ on\ classifed\ tile:1]]
> pts.on.classified.tile.plot.ErrorinTitle <- function(error, grd.pts, classified.tile.path, fig.dir, target = NULL) {
+ 
+       grid.name <- str_match(classified.tile.path, ".*([a-z]{3}\\.[0-9]+m\\.[0-9]+)_.*")[,2]
+       pts <- grd.pts[grd.pts@data$unq__ID == grid.name,]
+   pts@data <- pts@data %>%
+         mutate(x = coordinates(pts)[,1],
+                y = coordinates(pts)[,2])
+ 
+     if(target == "a") {
+         pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
+         pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, fill = cvr_typ), shape = 21, color = "black", size =2, stroke = .2)
+     } else {
+         pts@data <- pts@data %>%
+             mutate(cvr_typ = ifelse(cvr_typ == target, cvr_typ, "o"))
+         pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
+     }
+     r.df <- as.data.frame(raster(classified.tile.path), xy = T)
+     names(r.df) <- c("x","y","cvr_typ")
+                                         #        r.df <- r.df %>%
+                                         #            mutate(cvr_typ = mapvalues(cvr_typ, from = c(1,2,3,4), to = c("g","i","t","o")))
+     pxls.plot <- ggplot() + geom_raster(data = r.df, aes(x = x, y = y, fill = cvr_typ))
+     title <- ggtitle(label = paste0("err:",round(error,2),"_",names(raster(classified.tile.path))))
+     UTC_pal <- c(g = "#ffff99", i = "#f0027f", t = "#7fc97f", o = "#666666")
+     plt <- pxls.plot + pts.plot + title + scale_fill_manual(values = UTC_pal)+ scale_color_manual(values = UTC_pal) + coord_equal()
+ 
+     dir.create(fig.dir)
+ 
+     png(filename = paste0(fig.dir,"/","Err.",round(error,2),"_",names(raster(classified.tile.path)),".png"))
+     print(plt)
+     dev.off()
+ #    plt
+ }
> 
> pts.on.classified.tile.plot <- function(pts, classified.tile, fig.dir, target = NULL) {
+ 
+     if(target == "a") {
+         pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
+         pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, fill = cvr_typ), shape = 21, color = "black", size =2, stroke = .2)
+     } else {
+         pts@data <- pts@data %>%
+             mutate(cvr_typ = ifelse(cvr_typ == target, cvr_typ, "o"))
+         pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
+     }
+     r.df <- as.data.frame(classified.tile, xy = T)
+     names(r.df) <- c("x","y","cvr_typ")
+                                         #        r.df <- r.df %>%
+                                         #            mutate(cvr_typ = mapvalues(cvr_typ, from = c(1,2,3,4), to = c("g","i","t","o")))
+     pxls.plot <- ggplot() + geom_raster(data = r.df, aes(x = x, y = y, fill = cvr_typ))
+     title <- ggtitle(label = names(classified.tile))
+     UTC_pal <- c(g = "#ffff99", i = "#f0027f", t = "#7fc97f", o = "#666666")
+     plt <- pxls.plot + pts.plot + title + scale_fill_manual(values = UTC_pal)+ scale_color_manual(values = UTC_pal) + coord_equal()
+ 
+     dir.create(fig.dir)
+ 
+     png(filename = paste0(fig.dir,"/",names(classified.tile),".png"))
+     print(plt)
+     dev.off()
+     plt
+ }
> ## Plot\ points\ on\ classifed\ tile:1 ends here
> 
> ## [[file:utc.org::*other%20Functions][other\ Functions:1]]
> image_to_classified_image <- function()
+ 
+ 
+ 
+ 
+ 
+                                         # contained urban, don't intersect water = as is
+                                         # contained urban, intersect water = mask water
+                                         # intersect urban, don't intersect water = mask urban
+                                         # intersect urban, intersect water = mask urban & water
+                                         # if none of the above, don't write the raster
+ 
+ 
+ 
+     Mask_water_crops_urban <- function(image.full.path, water, crops, urban) {
+ 
+     }
> 
> 
> 
> 
> Water_Urban_mask <- function(tile.path, tile.name, urban, water) {
+                                         # load image tile
+     tile <- stack(tile.path)
+                                         # get extent image and make sp object
+     et <- as(extent(tile), "SpatialPolygons")
+     proj4string(et) <- "+init=epsg:26916"
+                                         # Mask out non-urban areas
+     if(gContainsProperly(urban,et) & !gIntersects(water,et)){
+         writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
+     } else if (gContainsProperly(urban,et) & gIntersects(water,et)) {
+         tile <- mask(tile, water, inverse = T)
+         writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
+     } else if (gIntersects(urban, et) & !gIntersects(water,et)) {
+         tile <- mask(tile, urban)
+         writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
+     } else if (gIntersects(urban, et) & gIntersects(water,et)) {
+         tile <- mask(tile, urban)
+         tile <- mask(tile, water, inverse = T)
+         writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
+     }
+ }
> 
> Crop_mask <- function(tile.path, tile.name, CDL_stack, n_years){
+ 
+     tile <- stack(tile.path)
+     crops <- crop(CDL_stack, tile)
+ 
+                                         # These are the values in the CDL that correspond to non crop cover types and not water
+     NonCroppedValues <- c(0,63:65, 81:83, 87:88, 112, 121:124, 131, 141:143, 152, 176, 190, 195)
+                                         # open water is 111
+ 
+     NonCroppedValues <- c(0,63:65, 81:83, 87:88, 112, 121:124, 131, 141:143, 152, 176, 190, 195)
+                                         # open water is 111. I don't include it in the above list so that it gets masked
+ 
+                                         # I'm going to add 37, Other Hay/Non-alfalfa, to the non crop cover types
+     NonCroppedValues <- c(NonCroppedValues, 37)
+                                         # I'm going to add 36, Alfalfa, to the non crop cover types
+     NonCroppedValues <- c(NonCroppedValues, 36)
+ 
+                                         # find cells that have been assigned crop all three years
+     crops[crops %in% NonCroppedValues] <- 0
+     crops[!(crops %in% NonCroppedValues)] <- 1
+     cropsum <- overlay(crops, fun = sum)
+ 
+     dis.cropsum <- disaggregate(cropsum, fact = 20)
+     dis.cropsum <- resample(dis.cropsum, tile, "ngb")
+     masked_tile <- mask(tile, dis.cropsum, maskvalue = n_years)
+ 
+                                         #               Save Image
+     writeRaster(masked_tile, paste0(crop.masked.tiles.directory, "/", tile.name), overwrite = T)
+ }
> ## other\ Functions:1 ends here
> 
> ## [[file:utc.org::*Set%20location%20to%20Madison][Set\ location\ to\ Madison:1]]
> location <- "madison"
> image.paths <- str_extract(image.paths, paste0(".*",location,".*")) %>% na.omit
> dd.pca.dir <-  str_extract(dd.pca.dirs, paste0(".*",location,".*")) %>% na.omit
> dd.training.dir <- str_extract(dd.training.dirs, paste0(".*",location,".*")) %>% na.omit
> dd.models.dir <- str_extract(dd.models.dirs, paste0(".*",location,".*")) %>% na.omit
> dd.accuracy.dir <- str_extract(dd.accuracy.dirs, paste0(".*",location,".*")) %>% na.omit
> dd.accuracy.classified.dir <-str_extract(dd.accuracy.classified.dirs, paste0(".*",location,".*")) %>% na.omit
> ## Set\ location\ to\ Madison:1 ends here
> 
> ## [[file:utc.org::*read%20in%20pca%20model%20if%20it%20exists.%20If%20I%20run%20this,%20don't%20run%20rest%20of%20pca%20code%20in%20this%20subtre][read\ in\ pca\ model\ if\ it\ exists\.\ \ If\ I\ run\ this\,\ don\'t\ run\ rest\ of\ pca\ code\ in\ this\ subtre:1]]
> ## pca <- foreach(i = seq_along(image.names)) %do% {
> ##    readRDS(str_c(dd.pca.dir,"/madisonNAIP_pca.rds"))
> ## }
> ## read\ in\ pca\ model\ if\ it\ exists\.\ \ If\ I\ run\ this\,\ don\'t\ run\ rest\ of\ pca\ code\ in\ this\ subtre:1 ends here
> 
> ## [[file:utc.org::*Reproject%20and%20Crop%20PCA%20Region%20Shapefile%20to%20Image][Reproject\ and\ Crop\ PCA\ Region\ Shapefile\ to\ Image:1]]
> foreach(img.pth = image.paths) %do% {
+ 
+          Reproject_Shapefile_to_Image_CRS(pca.region.dsn,
+                                          str_c(location,pca.region.layer.appendage),
+                                          img.pth,
+                                          pca.region.imageCRS.dsn)
+ 
+        Crop_image_to_each_Shapefile_polygon(pca.region.imageCRS.dsn,
+                                          str_c(location,pca.region.layer.appendage),
+                                         img.pth,
+                                         cores = cores,
+                                         output.dir = dd.pca.dir)
+ }
OGR data source with driver: ESRI Shapefile 
Source: "../RD_PCA_Regions/", layer: "madison_PCA_regions"
with 8 features
It has 1 fields
OGR data source with driver: ESRI Shapefile 
Source: "../DD/reprojected.PCA_Regions", layer: "madisonNAIP_madison_PCA_regions"
with 8 features
It has 1 fields

Execution halted
