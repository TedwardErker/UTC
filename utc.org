#+TITLE: Wisconsin Urban Tree Canopy Mapping
#+AUTHOR: Tedward Erker
#+email: erker@wisc.edu
#+PROPERTY:  header-args:R :session *R:utc* :cache no :results output :tangle classifying_urban_WI.R :exports both :comments link
#+STARTUP: indent

* Begin with end in mind
** End Product:
A map of urban cover with associated model uncertainty.  For the
Madison Area.

A reproducible workflow to apply this to any city in WI (or perhaps
country) with minimal work from user.
** Automated workflow
I need to be able to run the whole script with one key stroke and get
a series of tables and figures that show the performance of the
classifiers.  Additionally (and more challenging) I need to be able to
easily add in
1) new training data
2) new features (esp additional texture layers and segmentations,
   possibly more moments than mean and sd in segments.)
3) new classifiers (more than just svm and rf)
4) new classes?


** Best Classifer
To make this map I need to find the best classifier to apply to the
maps.  To know the best classifier I need to perform an accuracy assessment.


npx = number of pixels in segmentation
cpt = compactness parameter

| Image       | Method | Pixel (Overall Accuracy) | Field Plot (RMSE) | Block (RMSE) |
|-------------+--------+--------------------------+-------------------+--------------|
| NAIP        | SVM    |                          |                   |              |
|             | RF     |                          |                   |              |
|             | SVM    |                          |                   |              |
|             | RF     |                          |                   |              |
|             | SVM    |                          |                   |              |
|             | RF     |                          |                   |              |
|             | SVM    |                          |                   |              |
|             | RF     |                          |                   |              |
|             |        |                          |                   |              |
|             |        |                          |                   |              |
|             |        |                          |                   |              |
|             |        |                          |                   |              |
|             |        |                          |                   |              |
|             |        |                          |                   |              |
| PAN_SPOT... |        |                          |                   |              |




1) Classification:
Images x segmentation x classification method

2 x 3 x 2 = 12

1) Accuracy:
   1) Pointwise - confusion matrix
      1) google earth points (robi's points)
      2) google earth points (grid of points)
      3) Field plot points
   2) Plotwise
      1) google earth grids, changing area under consideration
      2) field plot, changing definition of tree

Pointwise - confusion matrix





** Directory Structure
*** Pjt_UTC
**** code
- contains this file
**** figs
**** DD
***** Training
****** Tiles
******* image.name_tile.id
******* image.name_tile.id_dir
******** with.ratios
******** PixelFeatureDF
******** pca
******** segmentation.params
******** segmentation.params.FeatureDF
****** image.name_reprojected.training.regions
****** image.name_pca.transformation
****** Models
***** Testing


***** NAIP.image
****** pca.model.transformation
****** reprojected.training.regions
****** reprojected.testing.regions
******* grid
******* field.data
****** reprojected.pca.regions
****** training.outputs
****** feature.dfs
******* pixel.feature.df
******* segment.X.feature.df
****** Models
****** testing.accuracy.outputs
******** grid.classified.regions
******** field.classified.regions
***** PansharpenedSPOT.image
****** pca.model.transformation
****** reprojected.training.regions
****** reprojected.testing.regions
******* grid
******* field.data
****** reprojected.pca.regions
****** training.outputs
****** feature.dfs
******* pixel.feature.df
******* segment.X.feature.df
****** Models
****** testing.accuracy.outputs
******** grid.classified.regions
******** field.classified.regions



**** RD_UrbanAreasShapefile
**** RD_WaterShapefile
**** RD_CroplandDataLayer

**** RD_Training_Regions
***** Madison
Shapefile that contains the regions from which I'll do
manual/supervised classification in the Madison Area
***** Wausau
Shapefile that contains the regions from which I'll do
manual/supervised classification in the Madison Area

**** RD_Accuracy
***** Grids
***** Field Plot
***** Robi's Points
**** RD_NAIP
**** RD_SPOT
**** DD_NAIP
***** Training
****** Madison
******* j directories for each polygon of the training shapefile
******** image : raw image that is cropped to tile
******** masked : image that is masked by water, crops, and urban boundary
******** AddedFeatures : image that has added derived bands
******** PCA : image that is the PCA results scaled to 0 - 255
******** Segmentation : image that is the segmentation layer
******** Segmentation Polygons: polygonized Segmentation Layer
******** SegmentFeatures : dataframe that has each row as segment, columns as features, Class from Segmentation Polygons added.
******** Classified Segmentation Polygons: polygonized Segmentation Layer with manual classifications
******* CombinedSegmentFeatures : dataframe that is combined
****** Wausau
Same as in Madison, but for Wausau

***** Testing
****** grids
******* i directories for each polygon of the grids
******** image : raw image that is cropped to tile
******** masked : image that is masked by water, crops, and urban boundary
******** AddedFeatures : image that has added derived bands
******** PCA : image that is the PCA results scaled to 0 - 255
******** Segmentation : image that is the segmentation layer
******** SegmentFeatures : dataframe that has each row as segment, columns as features.
******** ClassifiedImages : classified images that use each model
********* k classified images for each model

****** fieldplots
Same as for grids

***** Accuracy Assessment
****** Dataframe that summary statistics for each classification, accuracy method
****** Tables of Results


***** Models
R model objects
***** Best Model
R model object, determined by accuracy assessment
***** i directories for each urban area
****** image cropped to urban area .tif
****** j directories for each tile within each of the i urban areas
******* image : raw image that is cropped to tile
******* masked : image that is masked by water, crops, and urban boundary
******* AddedFeatures : image that has added derived bands
******* PCA : image that is the PCA results scaled to 0 - 255
******* Segmentation : image that is the segmentation layer
******* SegmentFeatures : dataframe that has each row as segment, columns as features
******* ClassifiedImage : classified image that uses the best model

**** DD_SPOT
Same structure as DD_NAIP








* Workflow
** Libraries
#+BEGIN_SRC R
  library(ascii)
  library(rgeos)
  library(mlr)
  library(broom)
  library(rgdal)
  library(raster)
  library(plyr)
  library(ggplot2)
  library(dplyr)
  library(tidyr)
  library(stringr)
  library(foreach)
  library(doParallel)
  library(glcm)
  library(randomForest)
  library(kernlab)
  library(irace)
  library(parallelMap)
#+END_SRC

#+results:
#+begin_example
rgeos version: 0.3-11, (SVN revision 479)
 GEOS runtime version: 3.4.2-CAPI-1.8.2 r3921
 Linking to sp version: 1.1-0
 Polygon checking: TRUE
Loading required package: BBmisc

Attaching package: 'BBmisc'

The following object is masked from 'package:rgeos':

    symdiff

Loading required package: ggplot2
Loading required package: ParamHelpers
Loading required package: sp
rgdal: version: 1.0-4, (SVN revision 548)
 Geospatial Data Abstraction Library extensions to R successfully loaded
 Loaded GDAL runtime: GDAL 1.11.2, released 2015/02/10
 Path to GDAL shared files: /Library/Frameworks/R.framework/Versions/3.2/Resources/library/rgdal/gdal
 Loaded PROJ.4 runtime: Rel. 4.9.1, 04 March 2015, [PJ_VERSION: 491]
 Path to PROJ.4 shared files: /Library/Frameworks/R.framework/Versions/3.2/Resources/library/rgdal/proj
 Linking to sp version: 1.1-1

Attaching package: 'raster'

The following object is masked from 'package:mlr':

    resample

The following object is masked from 'package:ParamHelpers':

    getValues

Attaching package: 'dplyr'

The following objects are masked from 'package:plyr':

    arrange, count, desc, failwith, id, mutate, rename, summarise,
    summarize

The following objects are masked from 'package:raster':

    intersect, select, union

The following object is masked from 'package:BBmisc':

    collapse

The following objects are masked from 'package:rgeos':

    intersect, setdiff, union

The following objects are masked from 'package:stats':

    filter, lag

The following objects are masked from 'package:base':

    intersect, setdiff, setequal, union

Attaching package: 'tidyr'

The following object is masked from 'package:raster':

    extract

The following object is masked from 'package:ascii':

    expand
foreach: simple, scalable parallel programming from Revolution Analytics
Use Revolution R for scalability, fault tolerance and more.
http://www.revolutionanalytics.com
Loading required package: iterators
Loading required package: parallel
Error in library(glcm) : there is no package called 'glcm'
randomForest 4.6-12
Type rfNews() to see new features/changes/bug fixes.

Attaching package: 'randomForest'

The following object is masked from 'package:dplyr':

    combine

Attaching package: 'kernlab'

The following objects are masked from 'package:raster':

    buffer, rotated
#+end_example


** set figure Cairo
#+begin_src R :exports none :results silent
  library(Cairo)
  mainfont <- "Garamond"
  CairoFonts(regular = paste(mainfont,"style=Regular",sep=":"),
             bold = paste(mainfont,"style=Bold",sep=":"),
             italic = paste(mainfont,"style=Italic",sep=":"),
             bolditalic = paste(mainfont,"style=Bold Italic,BoldItalic",sep=":"))
  pdf <- CairoPDF
  png <- CairoPNG
#+end_src
** Inputs
**** Input Directories
#+BEGIN_SRC R
  image.dirs <- c("../RD_NAIP","../RD_SPOT")
  pca.dir <- "../RD_PCA_Regions"
  training.dir <- "../RD_Training_Regions"
  accuracy.dir <- "../RD_Accuracy"
  grids.accuracy.dir <- str_c(accuracy.dir, "/Grids")
  fieldplots.accuracy.dir<- str_c(accuracy.dir, "/FieldData")
  crop.dir <- "../RD_CroplandDataLayer"
  water.dir <- "../RD_WI-waterbody-24k"
  urban.dir <- "../RD_US_UrbanAreasShapefile"
  urban.and.incorporated.dir <- "../RD_merged_WIurbanAreas_and_incorporatedAreas"
#+END_SRC

#+results:

**** Variable Names and Paths
#+BEGIN_SRC R
  image.names <- c("madisonNAIP","panshpSPOT")
  image.paths <- paste0(image.dirs, "/", image.names, ".tif")

  ratio.tile.name.append <- "_ratio"
  pca.tile.name.append <- "_pca"

# don't think I need these lines:
  ## segment.params <- list(list(area = c(105,60,30), compactness = c(32,30,15)),
  ##                        list(area = c(105,60,30), compactness = c(21,20,10)))
  ## names(segment.params) <- image.names

  band.names.wRatios <- c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")

  pixel.feature.df.appendage = "_PixelFeatureDF"

  pca.model.name.appendage = "_pca.rds"

  segmentation.layer.pattern = "_N-[0-9]+_C-[0-9]+"

  segmentFeatureDF.appendage = "_SegmentFeatureDF.rds"

  FeatureDF.appendage = "_FeatureDF.rds"
  ModelBuilding.appendage = ".ModelBuilding.rds"
  models.appendage = ".models.rds"

  tile.id.col.nm.for.grid.and.field.accuracy <- c("unq__ID", "Plot")

  grid.pattern = "[a-zA-Z]{3}\\.[0-9]+m\\.[0-9]+" #I removed "_" from end. <2016-07-02 Sat>
  texture.pattern = "stat-.*_window-.*_angle[-]+[0-9]+"
#+END_SRC

#+results:

**** Texture Params
#+begin_src R

  band.for.texture.appendage = "_ratio.nir"
  window <- list(c(3,3), c(5,5))
  statistics = list("homogeneity", "contrast", "correlation")
  shift = list(c(0,1),c(1,0),c(1,1),c(-1,1))


  band.for.texture.appendage = "_ratio.nir"
  window <- list(c(3,3))
  statistics = list("homogeneity", "correlation")
  shift = list(c(0,1),c(-1,1))


  texture.params <- expand.grid(band.appendage = band.for.texture.appendage,window = window, statistics = statistics, shift = shift, stringsAsFactors = F)


#+end_src

#+results:

**** Segmentation Params
#+begin_src R
  segment.size <- c(rep(30,3),rep(60,3),rep(100,3))
  compactness <- segment.size * c(.1, .5, 3)

  segment.size <- c(rep(30,1), rep(100,1))
  compactness <- segment.size * c(.5)


  segment.params <- data.frame(compactness = compactness, segment.size = segment.size)
#+end_src

#+results:

**** Input Shapefile DSNs and Layers
#+BEGIN_SRC R

  pca.region.dsn <- "../RD_PCA_Regions/Madison_PCA_Regions"
  pca.region.layer <- "PCA_regions"

  training.region.dsn <- "../RD_Training_Regions/Madison_TrainingRegions"
  training.region.layer <- "madisonTrainingPolygons"



  grid.accuracy.region.dsn <- "../RD_Accuracy/Grids"
  grid.accuracy.region.dsn <- "../DD/reprojected.Accuracy.Regions"
  grid.accuracy.region.layer <- "All_Grids_Accuracy_Assessment_Added_pts"
  grid.accuracy.region.layer <- "madisonNAIP_All_Grids_Accuracy_Assessment_Added_pts"

  field.accuracy.region.dsn <- "../RD_Accuracy/FieldData"
  field.accuracy.region.layer <- "fieldPoints"

  accuracy.region.dsn <- c(grid.accuracy.region.dsn, field.accuracy.region.dsn)
  accuracy.region.layer <- c(grid.accuracy.region.layer, field.accuracy.region.layer)

                                          # grid.accuracy.truthFromAndy.csvpath <- str_c(grid.accuracy.region.dsn,"grid_accuracy_assessment_andy.csv")

#+END_SRC

#+results:

**** Derived Directories
#+BEGIN_SRC R
                                          # make derived data directory
  derived.dir <- "../DD"

  dd.training.dir <- str_c(derived.dir, "/Madison_Training")

  dd.pca.dir <- str_c(derived.dir, "/Madison_pca")

  dd.accuracy.dir <- str_c(derived.dir, "/Accuracy")

  Models.dir <- paste0(derived.dir,"/","Models")

  ClassifiedTilesDirName <- "ClassifiedTiles"

  dd.accuracy.classified.dir <- str_c(dd.accuracy.dir, "/", ClassifiedTilesDirName)

#+END_SRC

#+results:

**** Make Derived Directories
#+BEGIN_SRC R
  dir.create(derived.dir)
  dir.create(dd.accuracy.classified.dir)
  lapply(dd.training.dir, FUN = function(x) dir.create(x))
  lapply(dd.pca.dir, FUN = function(x) dir.create(x))
  lapply(dd.accuracy.dir, FUN = function(x) dir.create(x))
  lapply(Models.dir, FUN = function(x) dir.create(x))
#+END_SRC

#+results:
#+begin_example
Warning message:
In dir.create(derived.dir) : '../DD' already exists
Warning message:
In dir.create(dd.accuracy.classified.dir) :
  '../DD/Accuracy/ClassifiedTiles' already exists
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/Madison_Training' already exists
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/Madison_pca' already exists
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/Accuracy' already exists
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/Models' already exists
#+end_example

**** Define Derived Shapefile DSNs and Layers
#+BEGIN_SRC R
  training.region.imageCRS.dsn <- str_c(derived.dir,"/reprojected.Training_Regions")

  pca.region.imageCRS.dsn <- str_c(derived.dir,"/reprojected.PCA_Regions")

  accuracy.region.imageCRS.dsn <- str_c(derived.dir,"/reprojected.Accuracy.Regions")


  lapply(training.region.imageCRS.dsn, FUN = function(x) dir.create(x))
  lapply(pca.region.imageCRS.dsn, FUN = function(x) dir.create(x))
  lapply(accuracy.region.imageCRS.dsn, FUN = function(x) dir.create(x))
#+END_SRC

#+results:
#+begin_example
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/reprojected.Training_Regions' already exists
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/reprojected.PCA_Regions' already exists
[[1]]
[1] FALSE

Warning message:
In dir.create(x) : '../DD/reprojected.Accuracy.Regions' already exists
#+end_example

**** Calc Accuracy Inputs
#+begin_src R
     mad.grid.id.pattern = "mad.[0-9]+m.[0-9]+"
     image.pattern = "[a-zA-Z]{5}[a-zA-Z]+"
     target.pattern = "all|grass|impervious|tree"
     model.pattern = "rf_prob|rf_resp|svm_resp"
     seg.prms = "N-[0-9]+_C-[0-9]+|Pixel"

#+end_src

#+results:

**** number of cores
#+BEGIN_SRC R
  cores <- 14

#+END_SRC

#+results:

**** CRS
#+BEGIN_SRC R
  utm16 <- CRS("+init=epsg:32616")
  wtm <- CRS("+init=epsg:3071")
#+END_SRC

#+results:

**** ASCII
#+begin_src R
options(asciiType = "org")
#+end_src

#+results:

** Functions
Load functions from utc/R/utc.org
[[file:utc/R/utc.org]]
** Determine how to make best classifier for Madison : image, segmentation, model, n.classes, target, and def truth
*** make pca transformation/rotation for slic segmentation algorithm.
**** read in pca model if it exists.  If I run this, don't run rest of pca code in this subtre
#+BEGIN_SRC R :eval no
  ## pca <- foreach(i = seq_along(image.names)) %do% {
  ##    readRDS(str_c(dd.pca.dir,"/madisonNAIP_pca.rds"))
  ## }
 #+END_SRC

#+results:

**** Reproject PCA Region Shapefile to Image
#+BEGIN_SRC R
  foreach(img.pth = image.paths) %do% {

         Reproject_Shapefile_to_Image_CRS(pca.region.dsn,
                                         pca.region.layer,
                                         img.pth,
                                         pca.region.imageCRS.dsn)
#+END_SRC

#+results:
:  Error in stack(image.path) (from #5) :
:   error in evaluating the argument 'x' in selecting a method for function 'stack': Error: object 'img.pth' not found

**** Crop image to create a smaller image around each of the polygons
#+BEGIN_SRC R :results none
       Crop_image_to_each_Shapefile_polygon(pca.region.imageCRS.dsn,
                                        pca.region.layer,
                                        img.pth,
                                        cores = cores,
                                        output.dir = dd.pca.dir)
}
#+END_SRC

**** Add Features (ratios and ndvi)
#+BEGIN_SRC R
         cl <- makeCluster(cores)
         registerDoParallel(cl)

          tile.names <- list.files(dd.pca.dir) %>%
              str_extract(., pattern = ".*[0-9]+.tif") %>%
                  str_extract(., pattern = ".*[0-9]+") %>%
                      na.omit()

         ratios <- foreach (j = tile.names,
                  .packages = c("raster","stringr")) %dopar% {
                      add.features(image.dir = dd.pca.dir,
                                   image.name = j,
                                   band.names = c("blue","green","red","nir"),
                                   ratio.bands = c("blue","green","red","nir"),
                                   texture = F)
                  }

      stopCluster(cl)
 #+END_SRC

#+results:

**** Create and Save PCA model/rotation
#+BEGIN_SRC R :results none
  pca <- foreach(img.nm = image.names) %do% {
              make.and.save.pca.transformation(image.dir = dd.pca.dir,
                                               image.name = img.nm)
  }
 #+END_SRC

*** Training
**** Make Training Tiles

#+BEGIN_SRC R :results none

  foreach(img.pth = image.paths[1]) %do% {

      Reproject_Shapefile_to_Image_CRS(training.region.dsn,
                                       training.region.layer,
                                       img.pth,
                                       training.region.imageCRS.dsn)

      Crop_image_to_each_Shapefile_polygon(training.region.imageCRS.dsn,
                                           training.region.layer,
                                           img.pth,
                                           cores = cores,
                                           output.dir = dd.training.dir)
}

#+END_SRC

**** Make Feature data frames, for Each Training Tile

 #+begin_src R :results silent
  cl <- makeCluster(cores)
  registerDoParallel(cl)

  pixel.added.features.raster.list <- foreach(img.nm = image.names[1]) %do% {

                                          #img.nm <- image.names[1]

      tile.names <- list.files(dd.training.dir) %>%
          str_extract(., pattern = str_c(img.nm,".[0-9]+.tif")) %>%
          str_extract(., pattern = str_c(img.nm,".[0-9]+")) %>%
          na.omit()

      foreach (i = tile.names,
               .packages = c("glcm","raster","stringr","dplyr")) %dopar% {


      feature.dfs <- make.feature.df(image.dir = dd.training.dir,
                      image.name = i,
                      band.names = c("blue","green","red","nir"),
                      ndvi = T,
                      ratio.bands = c("blue","green","red","nir"),
                      texture.params.df = texture.params,
                      pixel.df = T,
                      segmentation = T,
                      segment.params.df = segment.params)

      }
      }
#+end_src

**** Combine Feature Dataframes
Pattern is image.name_Segmentation
#+BEGIN_SRC R :results none
  tile.dir <- dd.training.dir
  segmentation.layer.pattern
  segmentFeatureDF.appendage
  pixel.feature.df.appendage


  feature.dfs <- list.files(tile.dir, full.names = T) %>%
      str_extract(.,".*FeatureDF.rds") %>%
      na.omit()

  foreach(img.nm = image.names[1]) %do% {
      img.feature.dfs <- str_extract(feature.dfs, str_c(".*",img.nm,".*")) %>%
          na.omit()
      SegParams <- unique(str_extract(img.feature.dfs, segmentation.layer.pattern)) %>%
          na.omit()
      SegParams <- c("_Pixel", SegParams)

      foreach(seg.param.set = SegParams[1:2]) %do% {
          img.seg.feature.dfs = str_extract(img.feature.dfs, str_c(".*",seg.param.set,".*")) %>%
              na.omit()
          dfs <- lapply(img.seg.feature.dfs, readRDS)
          combined.dfs <- bind_rows(dfs)
          saveRDS(combined.dfs, file = str_c(tile.dir, "/", img.nm, seg.param.set, FeatureDF.appendage))
      }
  }
#+END_SRC

**** Create Model Building Dataframes, assign Class to feature dfs
  1) Input
     - Segmentation Layer from the Training Regions
     - Classified Training Polygons for each image (NAIP and panSPOT)
  2) Operation
     - For Pixels, extract coordinates of pixels that are inside training polygons
       - columns: x,y,class
       - join to pixel feature df
     - For Segments
       - Determine which segments fall majority within training polygons
       - Assign segments the class of the training polygon
       - columns: segment id, class
       - join to segment df

  3) Output
     - Model Building Dataframes, 1 for each image and segmentation combination

#+BEGIN_SRC R :results none

    cl <- makeCluster(cores)
    registerDoParallel(cl)


    model.building.dfs <-  foreach(img.nm = image.names[1]) %do% {

        featureDF.files <- list.files(dd.training.dir) %>%
            str_extract(., str_c(img.nm,".*", FeatureDF.appendage,"$")) %>%
            na.omit()

        training.polygon.layer <- list.files(training.region.dsn) %>%
            str_extract(.,str_c(".*",img.nm, ".*")) %>%
            na.omit() %>%
            extract.name.from.path() %>%
            unique()

        training.polygons <- readOGR(dsn = training.region.dsn, layer = training.polygon.layer)

        foreach(feature.df.rds = featureDF.files, .packages = c("mlr","foreach","doParallel", "stringr", "dplyr","sp")) %do% {

            feature.df <- readRDS(file = str_c(dd.training.dir,"/",feature.df.rds))

            if(complete.cases(str_extract(feature.df.rds, "Pixel"))) {
                model.building.df <- getPixel.Class.and.Coords.Within.Polygon(PixelFeatureDF = feature.df,
                                                                              training.sp = training.polygons)
                model.building.df <- model.building.df %>%
                    dplyr::select(-x, -y, -id)
                saveRDS(object = model.building.df, file = paste0(dd.training.dir,"/",img.nm,"_Pixel",ModelBuilding.appendage))
            }

            if(complete.cases(str_extract(feature.df.rds,   segmentation.layer.pattern))) {
                segment.parameters <- str_extract(feature.df.rds, segmentation.layer.pattern)
                model.building.df <- getSegment.class.and.features.Within.Polygon(SegmentFeatureDF = feature.df,
                    training.sp = training.polygons,
                    seg.tiles.dir = dd.training.dir,
                    seg.params = segment.parameters)
                saveRDS(model.building.df, file = str_c(dd.training.dir,"/",img.nm,segment.parameters,ModelBuilding.appendage))
            }
        }
    }

 #+END_SRC

**** Plot Model Building Dataframes?? Visualize discriminating features
#+begin_src R :exports results :results graphics :file ./figs/mod.df.check.png

    mod.df <- readRDS(paste0(dd.training.dir, "/",img.nm, segment.parameters, ModelBuilding.appendage))

    ggplot(mod.df, aes(color = factor(Class), y = ndvi_mean, x = red_sd)) + geom_point(alpha = .9)
#    ggplot(out, aes(color = factor(Class), y = ndvi_mean, x = red_sd)) + geom_point(alpha = .9)
#  ggplot(model.building.df, aes(color = factor(Class), y = ndvi_mean, x = red_sd)) + geom_point(alpha = .5)

#+end_src

#+results:
[[file:./figs/mod.df.check.png]]

#+begin_src R :exports results :results graphics :file ./figs/mod.df.pixel.check.png
  mod.df <- readRDS(paste0(dd.training.dir, "/",img.nm, "_Pixel", ModelBuilding.appendage))
  ggplot(mod.df, aes(color = factor(Class), y = ndvi, x = ratio.nir_stat.homogeneity_window.3_angle.0)) + geom_point(alpha = .5)
#+end_src

**** TODO Create and SaveModels: REMOVE NAs for SVM pixel classification

***** untuned models
#+BEGIN_SRC R :results none
  cl <- makeCluster(cores)
  registerDoParallel(cl)

  foreach(img.nm = image.names[1]) %do% {

              ModelBuildingRDSs <- list.files(dd.training.dir) %>%
                  str_extract(., str_c(img.nm,".*",ModelBuilding.appendage)) %>%
                  na.omit()

              foreach(ModelBuildingRDS = ModelBuildingRDSs,
          .packages = c("parallelMap","randomForest","kernlab","irace","mlr","stringr","dplyr","foreach","doParallel")) %dopar% {

                  Build.and.Save.models(dir = dd.training.dir,
                                        modelBuildingData = ModelBuildingRDS,
                                        models.dir = Models.dir,
                                        image.name = img.nm)
              }
          }
#+end_src
***** tuned models

for tuning see:
https://mlr-org.github.io/mlr-tutorial/release/html/nested_resampling/index.html

#+begin_src R :eval no
 Build.and.Save.Tuned.models <- function( dir = dd.training.dir,
                                    modelBuildingData = ModelBuildingRDS,
                                    models.dir = Models.dir,
                                    image.name){

      dat <- readRDS(paste0(dir,"/",modelBuildingData)) %>%
          as.data.frame()

      image.and.segmentation.stem = str_replace(modelBuildingData, ModelBuilding.appendage,"")

      names <- colnames(dat)
      names <- str_replace(names, "\\(",".")
      names <- str_replace(names, "\\)",".")
      names <- str_replace(names, "\\:",".")
      colnames(dat) <- names

                                          # Create Task
      utc.task <- makeClassifTask(id = image.name, data = dat, target = "Class")

                                          # make parameter set for tuning

      rf.ps <- makeParamSet(makeIntegerParam("ntree", lower = 1L, upper = 500L),
                            makeIntegerParam("mtry", lower = 1L, upper = 50L))

      svm.ps <- makeParamSet(makeNumericParam("C", lower = -12, upper = 12, trafo = function(x) 2^x),
                             makeDiscreteParam("kernel", values = c("vanilladot", "polydot", "rbfdot")),
                             makeNumericParam("sigma", lower = -12, upper = 12, trafo = function(x) 2^x,
                                              requires = quote(kernel == "rbfdot")),
                             makeIntegerParam("degree", lower = 2L, upper = 5L,
                                              requires = quote(kernel == "polydot")))

                                          # tune
                                          # inner

      ctrl = makeTuneControlIrace(maxExperiments = 200L)
      inner = makeResampleDesc("CV", iters = 2L)
      svm.lrn = makeTuneWrapper("classif.ksvm", resampling = inner, par.set = svm.ps, control = ctrl, show.info = T)
      rf.lrn = makeTuneWrapper("classif.randomForest", resampling = inner, par.set = rf.ps, control = ctrl, show.info = T)

                                          #outer
      lrnrs = list(svm.lrn, rf.lrn)
      outer = makeResampleDesc("CV", iters = 3L)

  #    parallelStartMulticore(cores)

      res = benchmark(lrnrs, utc.task, outer, measures = acc, show.info = FALSE)

  #   parallelStop()

      saveRDS(res, file = paste0(models.dir,"/",image.and.segmentation.stem, models.appendage))
  }



 #+END_SRC

**** Look at models

#+begin_src R :eval no
  df <- readRDS(paste0(dd.training.dir, "/madisonNAIP_N-30_C-15.ModelBuilding.rds"))
  mod <- readRDS(paste0(Models.dir, "/madisonNAIP_N-100_C-50.models.rds"))



  getBMRModels(mod)
  getBMRLearners(mod)
  getBMRPerformances(mod)
  getBMRTuneModults(mod, as.df = T)

  getBMRTuneModults(mod, as.df = T) %>%
      group_by(learner.id) %>%
      summarize_each(funs = "mean")


  mods<-getBMRModels(mod)



#+end_src

*** Testing/Accuracy
**** Make tiles at accuracy regions

make this i = 1:2 (or 1:3) to do all the accuracy regions

#+BEGIN_SRC R :results none

    foreach(i = 1) %do% {

      foreach(img.pth = image.paths[1]) %do% {

          Reproject_Shapefile_to_Image_CRS(accuracy.region.dsn[i],
                                           accuracy.region.layer[i],
                                           img.pth,
                                           accuracy.region.imageCRS.dsn)

          Crop_image_to_regions_around_points_nameBygrid(shapefile.dsn = accuracy.region.imageCRS.dsn,
                                                         shapefile.layer = accuracy.region.layer[i],
                                                         image.path = img.pth,
                                                         cores = cores,
                                                         output.dir = dd.accuracy.dir,
                                                         column.name = tile.id.col.nm.for.grid.and.field.accuracy[i])

      }
  }


#+END_SRC

**** Make Feature data frames, for each Accuracy Region tile

 #+begin_src R :results silent
   cl <- makeCluster(cores)
   registerDoParallel(cl)

   pixel.added.features.raster.list <- foreach(img.nm = image.names[1]) %do% {

                                           #img.nm <- image.names[1]

       tile.names <- list.files(dd.accuracy.dir) %>%
           str_match(., pattern = str_c("(",img.nm,".",grid.pattern,")(.tif)"))

       tile.names <- tile.names[,2] %>% na.omit()

       foreach (i = tile.names,
                .packages = c("glcm","raster","stringr","dplyr")) %dopar% {


                    feature.dfs <- make.feature.df(image.dir = dd.accuracy.dir,
                                                   image.name = i,
                                                   band.names = c("blue","green","red","nir"),
                                                   ndvi = T,
                                                   ratio.bands = c("blue","green","red","nir"),
                                                   texture.params.df = texture.params,
                                                   pixel.df = T,
                                                   segmentation = T,
                                                   segment.params.df = segment.params)

                }
   }

#+end_src

**** NEXT Classify Tiles at accuracy regions
I need to find a way to associate the class with the number. So that
it stays and doesn't reorder alphabetically.

Somehow the pixel classification does this correctly (it creates a
.xml meta datafile.)

I need to make this so that I don't have to specify the factor levels
of the classes.  The raster predict function appears smart in this
way.  I should look at it.

#+BEGIN_SRC R
     cl <- makeCluster(cores)
     registerDoParallel(cl)


     classified.grid.tiles <-
         foreach(img.nm = image.names[1]) %do% {

             models <- list.files(Models.dir) %>%
                 str_extract(., str_c(".*",img.nm,".*")) %>%
                 na.omit()

             tile.names <- list.files(dd.accuracy.dir) %>%
                 str_match(., pattern = str_c("(",img.nm,".*?)_.*\\.tif$"))

             tile.names <- tile.names[,2] %>% na.omit() %>% unique()


             foreach(tile.nm = tile.names,
                     .packages = c("dplyr","raster","stringr","mlr","foreach","doParallel")) %do% {

                 foreach(model = models) %do% {

                     segmentation.params <- str_extract(model, "N-[0-9]+_C-[0-9]+|Pixel")

                     if(grepl("N-[0-9]+_C-[0-9]+",segmentation.params)) {
                            segment.tile.name.append <- paste0("_",segmentation.params,".tif")
                            segment.feature.df.name.append <- paste0("_",segmentation.params,segmentFeatureDF.appendage)


                            classify.segmented.raster(segment.feature.df.dir = dd.accuracy.dir,
                                            model.dir = Models.dir,
                                            segment.dir = dd.accuracy.dir,
                                            classify.out.dir = dd.accuracy.dir,
                                            tile.name = tile.nm,
                                            segmentation.appendage = segment.tile.name.append,
                                            model.name.rds = model,
                                            segment.feature.appendage = segment.feature.df.name.append,
                                            segmentation.prms = segmentation.params)

                     } else {
                         classify.pixel.raster(tile.dir = dd.accuracy.dir,
                                               tile.name = tile.nm,
                                               pixelFeatureDF.appendage = pixel.feature.df.appendage,
                                               model.dir = Models.dir,
                                               model.rds = model,
                                               seg.prms = segmentation.params)
                     }
                 }
             }
         }


    stopCluster(cl)




#+END_SRC

#+results:
:  Joining by: "segment"
: [1] "../DD/Accuracy/ClassifiedTiles/madisonNAIP.mad.200m.3_N-100_C-50_madisonNAIP_all_rf_prob.tif"
: Joining by: "segment"
: [1] "../DD/Accuracy/ClassifiedTiles/madisonNAIP.mad.200m.3_N-100_C-50_madisonNAIP_all_svm_resp.tif"
: [1] "../DD/Accuracy/ClassifiedTiles/madisonNAIP.mad.200m.3_Pixel_madisonNAIP_all_rf_prob.tif"
: [1] "../DD/Accuracy/ClassifiedTiles/madisonNAIP.mad.200m.3_Pixel_madisonNAIP_all_svm_resp.tif"





**** Point-wise accuracy.  regular confusion matrix thing.  I should do this for the grids and the field plot data
#+BEGIN_SRC R
      grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer, stringsAsFactors = F)

      xy <- coordinates(grd)
      grd@data$x <- xy[,1]
      grd@data$y <- xy[,2]

  classified.tile.paths <- list.files(str_c(dd.accuracy.classified.dir), full.names = T) %>%
      str_extract(., pattern = ".*.tif$") %>%
          str_extract(., pattern = str_c(".*",grid.pattern, ".*")) %>%
          na.omit()


  grid.names <- classified.tile.paths %>%
      str_match(., paste0(".*(",grid.pattern,").*"))

  grid.names <- grid.names[,2] %>%
      unique() %>%
      na.omit()

  ## grid.name = str_extract(grid.names, ".*150m-[56].*") %>% na.omit()



      cl <- makeCluster(cores)
      registerDoParallel(cl)


      error.df <- foreach(grid.name = grid.names, .combine = "rbind") %do% {

          pts <- grd[grd@data$unq__ID== grid.name,]

          classified.tile.paths.at.grid <- str_extract(classified.tile.paths, str_c(".*",grid.name,"_.*")) %>%
              na.omit()

          classified.tile.paths.at.grid2 = classified.tile.paths.at.grid %>%
               str_extract(., ".*madisonNAIP.*N-105.*svm_.*") %>%
               na.omit()

          ## classified.tile.path.at.grid = classified.tile.paths.at.grid[4]



          foreach(classified.tile.path.at.grid = classified.tile.paths.at.grid,
                  .combine = "rbind",
                  .packages = c("plyr","raster","dplyr", "stringr","ggplot2")) %dopar% {

                      classified.tile.name.at.grid <- basename(classified.tile.path.at.grid)
                      classified.tile <- raster(classified.tile.path.at.grid)

                      tgt <- str_extract(classified.tile.name.at.grid, "tree|grass|impervious|all")
                      tgt <- mapvalues(tgt, c("tree","grass","impervious","all"), c("t","g","i","a"))

                     ##  png(str_c("figs/","ClassifiedVersusGrid","/",names(classified.tile),".png"))
                     ## print(pts.on.classified.tile.plot(pts, classified.tile, target = tgt))
                     ## dev.off()

                      PixBool <- !is.na((str_extract(classified.tile.path.at.grid, "_Pixel_")))

                      if(!is.na(str_extract(classified.tile.path.at.grid, "_all_"))) {
                          error <- calcErrorAllMultinomial(pts, classified.tile, Pixel = PixBool)
                          error <- error %>%
                              t() %>%
                              data.frame() %>%
                              mutate(grid = grid.name,
                                     image =  str_extract(classified.tile.name.at.grid, image.pattern),
                                     target.cover = str_extract(classified.tile.name.at.grid, target.pattern),
                                     model =  str_extract(classified.tile.name.at.grid, model.pattern),
                                     seg.params = str_extract(classified.tile.name.at.grid, seg.prms))
                          error
                      } else {
                          target = str_extract(classified.tile.name.at.grid, "tree|grass|impervious")
                          target <- mapvalues(target, c("tree","grass","impervious"), c("t","g","i"))
                          error <- calcErrorBinomial(pts, classified.tile, target, Pixel = PixBool)
                          error <- error %>%
                              t() %>%
                              data.frame() %>%
                              mutate(grid = grid.name,
                                     image =  str_extract(classified.tile.name.at.grid, image.pattern),
                                     target.cover = str_extract(classified.tile.name.at.grid, target.pattern),
                                     model =  str_extract(classified.tile.name.at.grid, model.pattern),
                                     seg.params = str_extract(classified.tile.name.at.grid, seg.prms))

                          error
                      }
                  }
      }



      saveRDS(error.df, str_c(derived.dir, "/point2pixel.error.df.rds"))

#+END_SRC

#+results:
#+begin_example
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.12_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.16_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.10_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.13_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.11_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.15_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.20_pca.tif', 'madisonNAIP.mad.100m.21_pca.tif', 'madisonNAIP.mad.100m.2_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.14_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.20_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.17_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.21_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.10_pca.tif', 'madisonNAIP.mad.100m.11_pca.tif', 'madisonNAIP.mad.100m.12_pca.tif', 'madisonNAIP.mad.100m.13_pca.tif', 'madisonNAIP.mad.100m.14_pca.tif', 'madisonNAIP.mad.100m.15_pca.tif', 'madisonNAIP.mad.100m.16_pca.tif', 'madisonNAIP.mad.100m.17_pca.tif', 'madisonNAIP.mad.100m.18_pca.tif', 'madisonNAIP.mad.100m.19_pca.tif', 'madisonNAIP.mad.100m.1_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.19_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.18_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.16_pca.tif']
['madisonNAIP.mad.100m.12_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.10_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.13_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.11_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.15_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.14_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.20_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.19_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.17_pca.tif']
['madisonNAIP.mad.100m.21_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.18_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.20_pca.tif', 'madisonNAIP.mad.100m.21_pca.tif', 'madisonNAIP.mad.100m.2_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.10_pca.tif', 'madisonNAIP.mad.100m.11_pca.tif', 'madisonNAIP.mad.100m.12_pca.tif', 'madisonNAIP.mad.100m.13_pca.tif', 'madisonNAIP.mad.100m.14_pca.tif', 'madisonNAIP.mad.100m.15_pca.tif', 'madisonNAIP.mad.100m.16_pca.tif', 'madisonNAIP.mad.100m.17_pca.tif', 'madisonNAIP.mad.100m.18_pca.tif', 'madisonNAIP.mad.100m.19_pca.tif', 'madisonNAIP.mad.100m.1_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.22_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.23_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.24_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.25_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.26_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.30_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.27_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.28_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.30_pca.tif', 'madisonNAIP.mad.100m.3_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.29_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.4_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.6_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.5_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.22_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.23_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.24_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.25_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.26_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.27_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.30_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.28_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.7_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.29_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.4_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.30_pca.tif', 'madisonNAIP.mad.100m.3_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.6_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.5_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.7_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.9_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.100m.8_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.100m.8_pca.tif']
['madisonNAIP.mad.100m.9_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.150m.10_pca.tif', 'madisonNAIP.mad.150m.1_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.150m.10_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.150m.2_pca.tif']
['madisonNAIP.mad.150m.4_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.150m.3_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.150m.5_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.150m.6_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.150m.7_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.150m.8_pca.tif']
['madisonNAIP.mad.150m.9_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.150m.10_pca.tif', 'madisonNAIP.mad.150m.1_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.150m.10_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.150m.4_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.150m.3_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.150m.2_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.150m.5_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.150m.7_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.150m.6_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.150m.8_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.150m.9_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.200m.1_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.200m.2_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.200m.1_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.200m.2_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.50m.1_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.50m.2_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.50m.4_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.50m.3_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.50m.5_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.50m.1_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.50m.2_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.50m.4_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.50m.3_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.50m.5_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.200m.3_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.200m.4_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.200m.3_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.200m.4_pca.tif']
average number of pixels per segment is 30.0
compactness parameter is 15
['madisonNAIP.mad.200m.5_pca.tif']
average number of pixels per segment is 100.0
compactness parameter is 50
['madisonNAIP.mad.200m.5_pca.tif']
#+end_example


*** Summarize Accuracy Assessment Results

Comparing classification to other estimates of cover.
#+begin_src R :results none
      error.df <- readRDS(str_c(derived.dir, "/point2pixel.error.df.rds"))

      error.df %>%
          arrange(overall.error) %>%
          head()

      error.df %>%
          arrange(desc(overall.error)) %>%
          head()

      error.df %>%
          filter(seg.params != "Pixel") %>%
          arrange(desc(overall.error)) %>%
          head()

  error.df <- error.df %>%
      mutate(segment.size = as.numeric(ifelse(!is.na(str_match(seg.params, "N-([0-9]+)_C-[0-9]+")[,2]), str_match(seg.params, "N-([0-9]+)_C-[0-9]+")[,2], 1)),
             segment.size = ifelse(image == "panshpSPOT", segment.size * 1.5, segment.size),
             compactness = as.numeric(str_match(seg.params, "N-[0-9]+_C-([0-9]+)")[,2]))

#+end_src

**** Random Points

***** Table showing performance of classifiers
#+begin_src R

#+end_src
***** Plots showing how image, segment size, compactness, and model affect accuracy

**** Field Data

**** Grid of Points

***** Plots of 20 best classified grids with points superimposed
For each grid, find the best classification.  Plot best 20 grids.
#+begin_src R
    best.classified.grids <- error.df %>%
        ungroup() %>%
        group_by(grid) %>%
        top_n(1, desc(overall.error)) %>%
        ungroup() %>%
        arrange(overall.error) %>%
        select(overall.error, grid,image, target.cover, model, seg.params) %>%
        mutate(path = paste0(dd.accuracy.dir,"/",ClassifiedTilesDirName,"/",image,".",grid,"_",seg.params,"_",image,"_",target.cover,"_",model,".tif")) %>%
        head(n = 20)



  best.classified.grids

#+end_src

#+begin_src R :results raw
options(warn = -1)
  best.classified.grids %>% ascii
options(warn = 1)
#+end_src


#+begin_src R

  grid.points <- readOGR(dsn = "../DD/reprojected.Accuracy.Regions",
                         layer = "madisonNAIP_All_Grids_Accuracy_Assessment_Added_pts")

  plts <- lapply(best.classified.grids$path, function(path) {
    grid.name <- str_match(path, ".*([a-z]{3}\\.[0-9]+m\\.[0-9]+)_.*")[,2]
    points <- grid.points[grid.points@data$unq__ID == grid.name,]
    points@data <- points@data %>%
        mutate(x = coordinates(points)[,1],
               y = coordinates(points)[,2])
    ras <- raster(path)
    pts.on.classified.tile.plot(fig.dir = "figs/bestgrids",points, ras, target = "a")
  })

  #+end_src

#+BEGIN_SRC R :results raw

best.grid.paths <- list.files("figs/bestgrids", full.names = T)

a <- sapply(best.grid.paths, function(x) message("[[file:",x,"]]"))

#+END_SRC

***** Plots of 20 worst classified grids with points superimposed
For each grid, find the worst classification.  Plot worst 20 grids.
#+begin_src R
    worst.classified.grids <- error.df %>%
        ungroup() %>%
        group_by(grid) %>%
        top_n(1, overall.error) %>%
        ungroup() %>%
        arrange(desc(overall.error)) %>%
        select(overall.error, grid,image, target.cover, model, seg.params) %>%
        mutate(path = paste0(dd.accuracy.dir,"/",ClassifiedTilesDirName,"/",image,".",grid,"_",seg.params,"_",image,"_",target.cover,"_",model,".tif")) %>%
        head(n = 20)



  worst.classified.grids %>% data.frame

#+end_src

#+begin_src R :results raw
options(warn = -1)
  worst.classified.grids %>% ascii
options(warn = 1)
#+end_src


#+begin_src R

  grid.points <- readOGR(dsn = "../DD/reprojected.Accuracy.Regions",
                         layer = "madisonNAIP_All_Grids_Accuracy_Assessment_Added_pts")

  plts <- lapply(worst.classified.grids$path, function(path) {
    grid.name <- str_match(path, ".*([a-z]{3}\\.[0-9]+m\\.[0-9]+)_.*")[,2]
    points <- grid.points[grid.points@data$unq__ID == grid.name,]
    points@data <- points@data %>%
        mutate(x = coordinates(points)[,1],
               y = coordinates(points)[,2])
    ras <- raster(path)
    pts.on.classified.tile.plot(fig.dir = "figs/worstgrids",points, ras, target = "a")
  })

  #+end_src

#+BEGIN_SRC R :results raw

worst.grid.paths <- list.files("figs/worstgrids", full.names = T)

a <- sapply(worst.grid.paths, function(x) message("[[file:",x,"]]"))

#+END_SRC


***** Table showing performace of classifiers, average over all grids, increasing accuracy
#+begin_src R :results raw
    error.df.avg.grids <- error.df %>%
        select(-grid) %>%
        group_by(image, target.cover, model, seg.params, segment.size, compactness) %>%
        summarize_each(funs(mean(.,na.rm = T))) %>%
        ungroup() %>%
        arrange(overall.error)


  options(warn = -1)
    error.df.avg.grids %>% ascii
  options(warn = 1)
#+end_src

#+results:
|   | image       | target.cover | model    | seg.params | segment.size | compactness | overall.error | pct.grass.classified.as.other | pct.impervious.classified.as.other | pct.tree.classified.as.other |
|---+-------------+--------------+----------+------------+--------------+-------------+---------------+-------------------------------+------------------------------------+------------------------------|
| 1 | madisonNAIP | all          | svm_resp | N-100_C-50 |       100.00 |       50.00 |          0.24 |                          0.42 |                               0.22 |                         0.35 |
| 2 | madisonNAIP | all          | svm_resp | Pixel      |         1.00 |             |          0.25 |                          0.45 |                               0.28 |                         0.22 |
| 3 | madisonNAIP | all          | rf_prob  | Pixel      |         1.00 |             |          0.27 |                          0.49 |                               0.28 |                         0.20 |
| 4 | madisonNAIP | all          | rf_prob  | N-100_C-50 |       100.00 |       50.00 |          0.28 |                          0.34 |                               0.32 |                         0.38 |


|   | image       | target.cover | model    | seg.params | segment.size | compactness | overall.error | pct.grass.classified.as.other | pct.impervious.classified.as.other | pct.tree.classified.as.other |
|---+-------------+--------------+----------+------------+--------------+-------------+---------------+-------------------------------+------------------------------------+------------------------------|
| 1 | madisonNAIP | all          | svm_resp | Pixel      | 1.00         |             | 0.26          | 0.39                          | 0.52                               | 0.10                         |
| 2 | madisonNAIP | all          | rf_prob  | Pixel      | 1.00         |             | 0.27          | 0.53                          | 0.53                               | 0.10                         |
| 3 | madisonNAIP | all          | svm_resp | N-30_C-15  | 30.00        | 15.00       | 0.83          | 0.80                          | 0.05                               | 1.00                         |
| 4 | madisonNAIP | all          | rf_prob  | N-30_C-15  | 30.00        | 15.00       | 0.84          | 0.67                          | 0.12                               | 1.00                         |
| 5 | madisonNAIP | all          | rf_prob  | N-100_C-50 | 100.00       | 50.00       | 0.84          | 0.66                          | 0.43                               | 1.00                         |
| 6 | madisonNAIP | all          | svm_resp | N-100_C-50 | 100.00       | 50.00       | 0.85          | 0.85                          | 0.01                               | 1.00                         |

***** Table showing performace of classifiers, average over all grids, decreasing accuracy
#+begin_src R :results raw
      options(warn = -1)
        error.df.avg.grids %>%
            arrange(desc(overall.error)) %>%
            ascii
      options(warn = 1)
#+end_src

#+results:
 |   | image       | target.cover | model    | seg.params | segment.size | compactness | overall.error | pct.grass.classified.as.other | pct.impervious.classified.as.other | pct.tree.classified.as.other |
 |---+-------------+--------------+----------+------------+--------------+-------------+---------------+-------------------------------+------------------------------------+------------------------------|
 | 1 | madisonNAIP | all          | rf_prob  | N-100_C-50 |       100.00 |       50.00 |          0.28 |                          0.34 |                               0.32 |                         0.38 |
 | 2 | madisonNAIP | all          | rf_prob  | Pixel      |         1.00 |             |          0.27 |                          0.49 |                               0.28 |                         0.20 |
 | 3 | madisonNAIP | all          | svm_resp | Pixel      |         1.00 |             |          0.25 |                          0.45 |                               0.28 |                         0.22 |
 | 4 | madisonNAIP | all          | svm_resp | N-100_C-50 |       100.00 |       50.00 |          0.24 |                          0.42 |                               0.22 |                         0.35 |

***** Plots of 20 *best* classified grids by *best* classifier with points superimposed
#+begin_src R :results none
  best.classif.overall <- error.df.avg.grids %>%
      arrange(overall.error) %>%
      slice(1) %>%
      data.frame()

  best.classif.best.grids <- best.classif.overall %>%
      select(image, target.cover, model, seg.params) %>%
      left_join(., error.df) %>%
      arrange(overall.error) %>%
      select(overall.error, grid,image, target.cover, model, seg.params) %>%
      mutate(path = paste0(dd.accuracy.dir,"/",ClassifiedTilesDirName,"/",image,".",grid,"_",seg.params,"_",image,"_",target.cover,"_",model,".tif")) %>%
      head(n=20)


  grid.points <- readOGR(dsn = "../DD/reprojected.Accuracy.Regions",
                         layer = "madisonNAIP_All_Grids_Accuracy_Assessment_Added_pts")


  lapply(1:nrow(best.classif.best.grids), function(i){
      pts.on.classified.tile.plot.ErrorinTitle(error = best.classif.best.grids$overall.error[i],
                                           grd.pts = grid.points,
                                           classified.tile.path = best.classif.best.grids$path[i],
                                           fig.dir = "figs/bestclassif.bestgrids",
                                           target = "a")
  })



  ## plts <- lapply(best.classif.best.grids$path, function(path) {
  ##     grid.name <- str_match(path, ".*([a-z]{3}\\.[0-9]+m\\.[0-9]+)_.*")[,2]
  ##     points <- grid.points[grid.points@data$unq__ID == grid.name,]
  ##     points@data <- points@data %>%
  ##         mutate(x = coordinates(points)[,1],
  ##                y = coordinates(points)[,2])
  ##     ras <- raster(path)
  ##     pts.on.classified.tile.plot(fig.dir = "figs/bestclassif.bestgrids",points, ras, target = "a")
  ## })


#+end_src

***** Plots of 20 *worst* classified grids by *best* classifier with points superimposed
#+begin_src R
      best.classif.overall <- error.df.avg.grids %>%
        arrange(overall.error) %>%
          slice(1) %>%
        data.frame()

  best.classif.worst.grids <- best.classif.overall %>%
    select(image, target.cover, model, seg.params) %>%
      left_join(., error.df) %>%
      arrange(desc(overall.error)) %>%
      select(overall.error, grid,image, target.cover, model, seg.params) %>%
      mutate(path = paste0(dd.accuracy.dir,"/",ClassifiedTilesDirName,"/",image,".",grid,"_",seg.params,"_",image,"_",target.cover,"_",model,".tif")) %>%
      head(n=20)


  grid.points <- readOGR(dsn = "../DD/reprojected.Accuracy.Regions",
                         layer = "madisonNAIP_All_Grids_Accuracy_Assessment_Added_pts")

  lapply(1:nrow(best.classif.worst.grids), function(i){
      pts.on.classified.tile.plot.ErrorinTitle(error = best.classif.worst.grids$overall.error[i],
                                           grd.pts = grid.points,
                                           classified.tile.path = best.classif.worst.grids$path[i],
                                           fig.dir = "figs/bestclassif.worstgrids",
                                           target = "a")
  })

  ## plts <- lapply(best.classif.worst.grids$path, function(path) {
  ##   grid.name <- str_match(path, ".*([a-z]{3}\\.[0-9]+m\\.[0-9]+)_.*")[,2]
  ##   points <- grid.points[grid.points@data$unq__ID == grid.name,]
  ##   points@data <- points@data %>%
  ##       mutate(x = coordinates(points)[,1],
  ##              y = coordinates(points)[,2])
  ##   ras <- raster(path)
  ##   pts.on.classified.tile.plot(fig.dir = "figs/bestclassif.worstgrids",points, ras, target = "a")
  ## })


#+end_src

#+results:
#+begin_example
 Joining by: c("image", "target.cover", "model", "seg.params")
 OGR data source with driver: ESRI Shapefile
Source: "../DD/reprojected.Accuracy.Regions", layer: "madisonNAIP_All_Grids_Accuracy_Assessment_Added_pts"
with 21305 features
It has 15 fields
 Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
Warning in dir.create(fig.dir) :
  'figs/bestclassif.worstgrids' already exists
[[1]]
quartz_off_screen
                2

[[2]]
quartz_off_screen
                2

[[3]]
quartz_off_screen
                2

[[4]]
quartz_off_screen
                2

[[5]]
quartz_off_screen
                2

[[6]]
quartz_off_screen
                2

[[7]]
quartz_off_screen
                2

[[8]]
quartz_off_screen
                2

[[9]]
quartz_off_screen
                2

[[10]]
quartz_off_screen
                2

[[11]]
quartz_off_screen
                2

[[12]]
quartz_off_screen
                2

[[13]]
quartz_off_screen
                2

[[14]]
quartz_off_screen
                2

[[15]]
quartz_off_screen
                2

[[16]]
quartz_off_screen
                2

[[17]]
quartz_off_screen
                2

[[18]]
quartz_off_screen
                2

[[19]]
quartz_off_screen
                2

[[20]]
quartz_off_screen
                2
#+end_example

***** Plots showing how image, segment size, compactness, and model affect accuracy

****** plot 1
#+begin_src R :exports results :results graphics :file ./figs/gridAcc.p1.png
ggplot(error.df, aes(y = overall.error, x = segment.size, color = compactness, group = model)) + geom_point() + facet_grid(model~image)
#+end_src

****** plot 2

***** Plots showing how grid characteristics (e.g. heterogeneity) affect accuracy

** Test How Madison Model performs for Wausau
*** Classify Wausau Accuracy Regions
**** Make tiles at accuracy regions
#+BEGIN_SRC R :results none


  image.names <- "wausauNAIP"
  image.paths <- str_c("../RD_NAIP/",image.names,".tif")

      foreach(i = 1:2) %do% {

        foreach(img.pth = image.paths) %do% {

            Reproject_Shapefile_to_Image_CRS(accuracy.region.dsn[i],
                                             accuracy.region.layer[i],
                                             img.pth,
                                             accuracy.region.imageCRS.dsn)

            Crop_image_to_regions_around_points_nameBygrid(shapefile.dsn = accuracy.region.imageCRS.dsn,
                                                           shapefile.layer = accuracy.region.layer[i],
                                                           image.path = img.pth,
                                                           cores = cores,
                                                           output.dir = dd.accuracy.dir,
                                                           column.name = "unq__ID")

        }
    }


#+END_SRC
**** Make PixelFeatureDFs and SegmentationFeatureDFs for Accuracy Regions
  1) Input
     - Testing Region Shapefiles
     - image
  2) Operation
     - Reproject Shapefiles to that of image
     - Crop image to each polygon in the shapefile
     - Derive PixelfeatureDFs and SegmentationFeatureDF from each tile of the image in region of each polygon
  3) Output
     - SegmentationFeatureDFs for every training polygon
     - PixelFeatureDFs for every pixel

****** Start R Loop, for every smaller image, do in parallel, :
#+BEGIN_SRC R
  cl <- makeCluster(cores)
  registerDoParallel(cl)

  pixel.added.features.raster.list <- foreach(img.nm = image.names) %do% {

      tile.names <- list.files(dd.accuracy.dir) %>%
           str_extract(., pattern = str_c(img.nm,".*-[0-9]+.tif$")) %>%
           str_extract(., pattern = str_c(img.nm,".*-[0-9]+")) %>%
           na.omit()

       foreach (i = tile.names,
                .packages = c("raster","stringr")) %dopar% {
   #+END_SRC

****** Add Ratios
#+BEGIN_SRC R
  add.ratios.ndvi(tile.dir = dd.accuracy.dir,
                  tile.name = i)


 #+END_SRC
****** Save Pixel Feature Dataframe
 #+BEGIN_SRC R

   pixel.feature.df <- Create.Pixel.Feature.df(tile.dir = dd.accuracy.dir,
                                               tile.name = i)




#+END_SRC

****** Perform PCA
#+BEGIN_SRC R :results none

# note, I copied madisonNAIP_pca to wausauNAIP_pca because we want to test if the madison pca will work for wausau

                image.pca(image.name = img.nm,
                          tile.dir = dd.accuracy.dir,
                          tile.name = i,
                          pca.dir = dd.pca.dir)
        }
  }
   #+END_SRC
****** Segmentation

#+NAME: accuracy.dir
#+BEGIN_SRC R
message(dd.accuracy.dir)
#+END_SRC


#+BEGIN_SRC sh :var dir=accuracy.dir
   cd $dir
   # pixel size
   # desired area for superpixel/segments
   # compactness value
   # imagename
   python ../../code/fia_segment_cmdArgs.py 1 60 30 wausauNAIP


#+END_SRC

#+END_SRC

****** Create Segment Feature Dataframe
 #+BEGIN_SRC R :results none
   cl <- makeCluster(cores)
   registerDoParallel(cl)

   seg.feature.dfs <- foreach(img.nm = image.names) %do% {

       tile.names <- list.files(dd.accuracy.dir) %>%
           str_extract(., pattern = str_c(img.nm,".*-[0-9]+",segmentation.layer.pattern,".tif$")) %>%
               na.omit()

       seg.params <- unique(str_extract(tile.names, segmentation.layer.pattern))

       foreach(seg.param.set = seg.params) %do% {

           tile.names.sub <- tile.names[which(complete.cases(str_extract(tile.names,seg.param.set)))]
           tile.names.sub <- str_replace(tile.names.sub, ".tif","")

           out <- foreach (i = tile.names.sub,
                           .packages = c("raster","stringr","dplyr","broom","tidyr")) %dopar% {
                               seg.df <- Create.Segment.Feature.df(tile.dir = dd.accuracy.dir,
                                                         tile.name = i)
                               saveRDS(seg.df, file = paste0(dd.accuracy.dir,"/", i, segmentFeatureDF.appendage))
                           }
           out
       }
   }

    #+END_SRC

**** Classify Tiles at accuracy regions

#+BEGIN_SRC R
   cl <- makeCluster(cores)
   registerDoParallel(cl)


# I copied the madisonNAIP model .rds file to a wausauNAIP model.rds since we want to see the performance of
# Madison models in Wausau


   classified.grid.tiles <-
       foreach(img.nm = image.names) %do% {

           models <- list.files(Models.dir) %>%
               str_extract(., str_c(".*",img.nm,".*")) %>%
               na.omit()

           tile.names <- list.files(dd.accuracy.dir) %>%
               str_extract(., pattern = str_c(img.nm,".*[0-9]+.tif$")) %>%
               str_replace(., segmentation.layer.pattern, "") %>%
               str_replace(., ".tif", "") %>%
                       na.omit() %>%
                           unique()

           foreach(tile.nm = tile.names,
                   .packages = c("dplyr","raster","stringr","mlr","foreach","doParallel")) %dopar% {

               foreach(model = models) %do% {

                   segmentation.params <- str_extract(model, "N-[0-9]+_C-[0-9]+|Pixel")

                   if(grepl("N-[0-9]+_C-[0-9]+",segmentation.params)) {
                          segment.tile.name.append <- paste0("_",segmentation.params,".tif")
                          segment.feature.df.name.append <- paste0("_",segmentation.params,segmentFeatureDF.appendage)

                          classify.segmented.raster(segment.feature.df.dir = dd.accuracy.dir,
                                          model.dir = Models.dir,
                                          segment.dir = dd.accuracy.dir,
                                          classify.out.dir = dd.accuracy.dir,
                                          tile.name = tile.nm,
                                          segmentation.appendage = segment.tile.name.append,
                                          model.name.rds = model,
                                          segment.feature.appendage = segment.feature.df.name.append,
                                          segmentation.prms = segmentation.params)

                   } else {
                       classify.pixel.raster(tile.dir = dd.accuracy.dir,
                                             tile.name = tile.nm,
                                             pixelFeatureDF.appendage = pixel.feature.df.appendage,
                                             model.dir = Models.dir,
                                             model.rds = model,
                                             seg.prms = segmentation.params)
                   }
               }
           }
       }


  stopCluster(cl)
#+END_SRC







*** Assess Accuracy of Wausau classified tiles
**** Point-wise accuracy.  regular confusion matrix thing.  I should do this for the grids and the field plot data
#+BEGIN_SRC R
        wau.grid.id.pattern = "wau-[0-9]+m-[0-9]+_"
        grid.pattern = "[a-zA-Z]{3}-[0-9]+m-[0-9]+_"
        image.pattern = "[a-zA-Z]{5}[a-zA-Z]+"
        target.pattern = "all|grass|impervious|tree"
        model.pattern = "rf_prob|rf_resp|svm_resp"
        seg.prms = "N-[0-9]+_C-[0-9]+|Pixel"


    grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer, stringsAsFactors = F)

        grd <- spTransform(grd, utm16)

        xy <- coordinates(grd)
        grd@data$x <- xy[,1]
        grd@data$y <- xy[,2]


        classified.tile.paths <- list.files(str_c(dd.accuracy.classified.dir), full.names = T) %>%
            str_extract(., pattern = ".*.tif$") %>%
            str_extract(., pattern = str_c(".*",grid.pattern, ".*")) %>%
            na.omit()

        grid.names <- list.files(str_c(dd.accuracy.classified.dir), full.names = T) %>%
            str_extract(., pattern = ".*.tif$") %>%
            str_extract(., pattern = wau.grid.id.pattern) %>%
            str_sub(.,1,-2) %>%
            unique() %>%
            na.omit()

    grid.name = grid.names[7]

    cl <- makeCluster(cores)
        registerDoParallel(cl)


        error.df <- foreach(grid.name = grid.names, .combine = "rbind") %do% {

            pts <- grd[grd@data$unq__ID== grid.name,]

            classified.tile.paths.at.grid <- str_extract(classified.tile.paths, str_c(".*",grid.name,"_.*")) %>%
                na.omit()

             classified.tile.paths.at.grid = classified.tile.paths.at.grid %>%
                  str_extract(., ".*wausauNAIP.*") %>%
                  na.omit()

             classified.tile.path.at.grid = classified.tile.paths.at.grid[11]


            foreach(classified.tile.path.at.grid = classified.tile.paths.at.grid,
                    .combine = "rbind",
                    .packages = c("plyr","raster","dplyr", "stringr","ggplot2")) %dopar% {

                        classified.tile.name.at.grid <- basename(classified.tile.path.at.grid)
                        classified.tile <- raster(classified.tile.path.at.grid)

                        tgt <- str_extract(classified.tile.name.at.grid, "tree|grass|impervious|all")
                        tgt <- mapvalues(tgt, c("tree","grass","impervious","all"), c("t","g","i","a"))

                        ## png(str_c(dd.accuracy.dir,"/ClassifiedTiles/ClassifiedVersusGrid","/",names(classified.tile),".png"))
                        ## print(pts.on.classified.tile.plot(pts, classified.tile, target = tgt))
                        ##dev.off()

                        PixBool <- !is.na((str_extract(classified.tile.path.at.grid, "_Pixel_")))

                        if(!is.na(str_extract(classified.tile.path.at.grid, "_all_"))) {
                            error <- calcErrorAllMultinomial(pts, classified.tile, Pixel = PixBool)
                            error <- error %>%
                                t() %>%
                                data.frame() %>%
                                mutate(grid = grid.name,
                                       image =  str_extract(classified.tile.name.at.grid, image.pattern),
                                       target.cover = str_extract(classified.tile.name.at.grid, target.pattern),
                                       model =  str_extract(classified.tile.name.at.grid, model.pattern),
                                       seg.params = str_extract(classified.tile.name.at.grid, seg.prms))
                            error
                        } else {
                            target = str_extract(classified.tile.name.at.grid, "tree|grass|impervious")
                            target <- mapvalues(target, c("tree","grass","impervious"), c("t","g","i"))
                            error <- calcErrorBinomial(pts, classified.tile, target, Pixel = PixBool)
                            error <- error %>%
                                t() %>%
                                data.frame() %>%
                                mutate(grid = grid.name,
                                       image =  str_extract(classified.tile.name.at.grid, image.pattern),
                                       target.cover = str_extract(classified.tile.name.at.grid, target.pattern),
                                       model =  str_extract(classified.tile.name.at.grid, model.pattern),
                                       seg.params = str_extract(classified.tile.name.at.grid, seg.prms))

                            error
                        }
                    }
        }



        saveRDS(error.df, str_c(derived.dir, /"point2pixel.error.df.Wausau.rds"))
  error.df <-readRDS(str_c(derived.dir, "/point2pixel.error.df.Wausau.rds"))

  error.df %>%
            arrange(overall.error) %>%
            head()

        error.df %>%
            arrange(desc(overall.error)) %>%
            head()

  error.df %>%
      filter(model == "rf_prob", target.cover == "tree") %>%
            arrange(desc(overall.error)) %>%
            head()



      error.df <- error.df %>%
            mutate(segment.size = ifelse(!is.na(str_extract(seg.params, ".*105.*")), 105,
                                  ifelse(!is.na(str_extract(seg.params, ".*60.*")), 60,
                                  ifelse(!is.na(str_extract(seg.params, ".*30.*")), 30,
                                  ifelse(!is.na(str_extract(seg.params, ".*70.*")), 105,
                                  ifelse(!is.na(str_extract(seg.params, ".*40.*")), 60,
                                  ifelse(!is.na(str_extract(seg.params, ".*20.*")), 30,1)))))))


#+END_SRC


#+BEGIN_SRC R :results graphics :file figs/grid.errors2.wausaufix.png :height 800 :width 600
  ggplot(error.df, aes(y = overall.error, x = grid, color = target.cover)) + geom_point() +
      facet_grid(image~seg.params)
#+END_SRC

#+BEGIN_SRC R :results graphics :file figs/grid.errors4.wausau.png :height 800 :width 600
  ggplot(error.df, aes(y = overall.error, x = grid, color = target.cover)) + geom_point() +
      facet_grid(image~segment.size)
#+END_SRC


#+BEGIN_SRC R :results graphics :file figs/grid.errors5.wausau.png :height 800 :width 600
  ggplot(error.df, aes(y = overall.error, x = segment.size)) +
      geom_point(data = error.df, aes(color = target.cover), position = position_dodge(width = 20)) +
      facet_grid(model~image)
#+END_SRC

#+BEGIN_SRC R :results graphics :file figs/grid.errors6.wausau.png :height 800 :width 800
  error.df.ssfac <- mutate(error.df, segment.size = factor(segment.size)) %>%
  filter(target.cover == "all")

      ggplot(error.df.ssfac, aes(y = overall.error, x = model)) +
          geom_boxplot(data = error.df.ssfac, aes(group = model)) +
          facet_grid(target.cover~image) +
	  geom_line(data = error.df.ssfac, aes(color = grid, group = grid), size = 1) +
	  theme_bw()
#+END_SRC

#+BEGIN_SRC R :results graphics :file figs/grid.errors6.wausau.tree.png :height 800 :width 800
  error.df.ssfac <- mutate(error.df, segment.size = factor(segment.size)) %>%
  filter(target.cover == "tree")

      ggplot(error.df.ssfac, aes(y = overall.error, x = model)) +
          geom_boxplot(data = error.df.ssfac, aes(group = model)) +
          facet_grid(target.cover~image) +
	  geom_line(data = error.df.ssfac, aes(color = grid, group = grid), size = 1) +
	  theme_bw()
#+END_SRC







#+BEGIN_SRC R :results graphics :file figs/grid.errors.tree.wausau.png :height 800 :width 800
  error.df.ssfac.tree <- filter(error.df.ssfac, target.cover == "all" | target.cover == "tree")

      ggplot(error.df.ssfac.tree, aes(y = pct.tree.classified.as.other)) +
          geom_boxplot(data = error.df.ssfac.tree, aes(color = target.cover, group = interaction(target.cover,segment.size))) +
          facet_grid(image~model)
#+END_SRC


#+BEGIN_SRC R :results graphics :file figs/grid.errors.grass.png :height 800 :width 800
  error.df.ssfac.grass <- filter(error.df.ssfac, target.cover == "all" | target.cover == "grass")

      ggplot(error.df.ssfac.grass, aes(y = pct.grass.classified.as.other, x = segment.size)) +
          geom_boxplot(data = error.df.ssfac.grass, aes(color = target.cover, group = interaction(target.cover,segment.size))) +
          facet_grid(model~image)
#+END_SRC

#+BEGIN_SRC R :results raw
  error.mod <- lm(overall.error ~ image * (target.cover + model + segment.size), data = error.df)
  tidy(error.mod) %>% ascii()
#+END_SRC

                                    term      estimate    std.error
1                             (Intercept)  0.2594736239 9.457737e-03
2                         imagepanshpSPOT  0.1727955729 1.522839e-02
3                       target.covergrass -0.0818909914 9.689578e-03
4                  target.coverimpervious -0.1373055644 9.689578e-03
5                        target.covertree -0.0611569996 9.689578e-03
6                            modelrf_resp  0.0001428180 8.391421e-03
7                           modelsvm_resp -0.0122835115 8.391421e-03
8                            segment.size -0.0001441090 8.903396e-05
9       imagepanshpSPOT:target.covergrass -0.0950710892 1.612641e-02
10 imagepanshpSPOT:target.coverimpervious  0.1013795711 1.612641e-02
11       imagepanshpSPOT:target.covertree -0.1345326137 1.612641e-02
12           imagepanshpSPOT:modelrf_resp  0.0004778158 1.396589e-02
13          imagepanshpSPOT:modelsvm_resp  0.1315548935 1.396589e-02
14           imagepanshpSPOT:segment.size -0.0008378628 1.489573e-04
      statistic       p.value
1   27.43506508 3.802666e-151
2   11.34693391  2.306554e-29
3   -8.45145037  4.066308e-17
4  -14.17043735  1.931840e-44
5   -6.31162645  3.083836e-10
6    0.01701953  9.864219e-01
7   -1.46381779  1.433277e-01
8   -1.61858472  1.056209e-01
9   -5.89536419  4.069309e-09
10   6.28655355  3.619056e-10
11  -8.34237580  1.011573e-16
12   0.03421307  9.727091e-01
13   9.41973196  7.679367e-21
14  -5.62485092  1.992621e-08

#+BEGIN_SRC R :results raw
options(asciiType = "org")
options(warn = -1)
  error.df %>%
      group_by(image, target.cover, model, seg.params) %>%
      summarize(overall.error = mean(overall.error)) %>%
      ungroup() %>%
      arrange(overall.error) %>%
      head(n=40) %>%
      ascii()
#+END_SRC



#+BEGIN_SRC R :results raw
  options(asciiType = "org")
  options(warn = -1)
    error.df %>%
        filter(target.cover == "all") %>%
        group_by(image, target.cover, model, seg.params) %>%
        summarize(overall.error = mean(overall.error)) %>%
        ungroup() %>%
        arrange(overall.error) %>%
        head(n=40) %>%
        ascii()
#+END_SRC



#+BEGIN_SRC R :results raw
  options(asciiType = "org")
  options(warn = -1)
    error.df %>%
        filter(target.cover == "all") %>%
        group_by(image, target.cover, model, seg.params) %>%
        summarize(pct.tree.classified.as.other = mean(pct.tree.classified.as.other)) %>%
        ungroup() %>%
        arrange(pct.tree.classified.as.other) %>%
        head(n=40) %>%
        ascii()

#+END_SRC


**** RMSE at grid level
***** Combine google earth grid estimates of cover with classified tile estimates of cover

 Create dataframe with structure:

 | %t.img | %g.img | %i.img | %o.img | image      | segmentation | target.cover        | target.type         | model                   | tile                   | cropped.to.n.pts | %t.goog | %g.goog | %i.goog | %o.goog |   |   |   |   |   |   |   |   |
 |--------+--------+--------+--------+------------+--------------+---------------------+---------------------+-------------------------+------------------------+------------------+---------+---------+---------+---------+---+---+---+---+---+---+---+---|
 |    0-1 |    0-1 |    0-1 |    0-1 | NAIP       | Pixel        | grass               | binomial (two)      | random forest prob      | mad-size-id (up to 50) |                4 |     0-1 |     0-1 |     0-1 |     0-1 |   |   |   |   |   |   |   |   |
 |        |        |        |        | panshpSPOT | 30 m2        | tree                | multinomial (three) | random forest resp      |                        |                9 |         |         |         |         |   |   |   |   |   |   |   |   |
 |        |        |        |        |            | 60 m2        | impervious          |                     | support vector machines |                        |               16 |         |         |         |         |   |   |   |   |   |   |   |   |
 |        |        |        |        |            |              | NA (if multinomial) |                     |                         |                        |               25 |         |         |         |         |   |   |   |   |   |   |   |   |
 |        |        |        |        |            | 105 m2       |                     |                     |                         |                        |              ... |         |         |         |         |   |   |   |   |   |   |   |   |



****** Create DF of % cover from grids cropped to different extents
 #+BEGIN_SRC R
        grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer)
        grd.df <- grd@data

   n.rows.and.columns.for.subset = c(15)

        out <- foreach(n.rows.and.columns.for.sub = n.rows.and.columns.for.subset) %do% {
            calc.pct.cvr.for.grid.subset(grd.df, n.rows.and.columns.for.sub)
        }

        Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets <- bind_rows(out)

   Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets <- Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets %>%
       rename(grid = unq__ID)

     saveRDS(Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets, str_c(derived.dir,"/","Wausau.Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets.dataframe",".rds"))
 #+END_SRC

****** Create DF of % cover from classified rasters cropped to different extents

#+BEGIN_SRC R

    grd <- readOGR(dsn = grid.accuracy.region.dsn, layer = grid.accuracy.region.layer)


    # get path of grid tiles (not interested in fieldplot classified tiles)
        classified.tile.paths <- list.files(str_c(dd.accuracy.classified.dir), full.names = T) %>%
            str_extract(., pattern = ".*.tif$") %>%
            str_extract(., pattern = str_c(".*",wau.grid.id.pattern, ".*")) %>%
              na.omit()


  n.rows.and.columns.for.subset = c(15)


  cl <- makeCluster(cores)
  registerDoParallel(cl)


      out <- foreach(n.rows.and.columns.for.sub = n.rows.and.columns.for.subset) %do% {
             pct.class.cover <- foreach(tile.path = classified.tile.paths, .packages = c("raster","dplyr","stringr")) %dopar% {
               calculate.percent.cover.in.classified.tile(pts = grd,
                                                           tile.pth = tile.path,
                                                           n.rows.and.columns.subset = n.rows.and.columns.for.sub)

            }
                saveRDS(pct.class.cover, str_c(derived.dir,"/","Wausau.Percent.Cover.Classified.Tiles.nPoints",n.rows.and.columns.for.sub, ".rds"))
      }


  class.cover.files <- list.files(derived.dir, pattern = "Wausau.Percent.Cover.Classified.Tiles.nPoints*", full.names = T)

  class.cover.dfs <- lapply(class.cover.files, readRDS)

  out <- unlist(class.cover.dfs,recursive = F)

       Percent.Cover.Classified.Tiles.dataframe <- bind_rows(out)





  # delete this line if I run it again.
  ## Percent.Cover.Classified.Tiles.dataframe <-rename(Percent.Cover.Classified.Tiles.dataframe,
  ##                                                   image = tile,
  ##                                                   pct_g_pred = pct_g,
  ##                                                   pct_i_pred = pct_i,
  ##                                                   pct_t_pred = pct_t,
  ##                                                   pct_o_pred = pct_o)

    ## saveRDS(Percent.Cover.Classified.Tiles.dataframe, str_c(derived.dir,"/","Percent.Cover.Classified.Tiles.dataframe",".rds"))

#+END_SRC




****** Join Cover from Grids with predicted Cover from images
#+BEGIN_SRC R
    Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets <- readRDS(str_c(derived.dir,"/","Wausau.Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets.dataframe",".rds"))

    str(Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets)
    str(Percent.Cover.Classified.Tiles.dataframe)

  Percent.Cover.Classified.Tiles.dataframe %>%
      filter(seg.params == "Pixel") %>%
      data.frame() %>%
      head()

    Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets %>%
        filter(n.points == 400)


  #Percent.Cover.Classified.Tiles.dataframe <- Percent.Cover.Classified.Tiles.dataframe %>%
  #    rename(pct_g_pred = pct_g, pct_t_pred = pct_t, pct_i_pred = pct_i, pct_o_pred = pct_o)


    grid.master.df <- left_join(Percent.Cover.Classified.Tiles.dataframe, Percent.Cover.Grids.with.diff.targettypes.and.diff.subsets)

    # Should join by Joining by: c("grid", "target.cover", "n.points", "target.type")

    str(grid.master.df)

    grid.master.df %>%
  #      filter(n.points == 400) %>%
        data.frame() %>%
        head(n=40)




#+END_SRC


***** Make RMSE plots

#+BEGIN_SRC R :results graphics :file figs/wausauNAIP.100m.RMSE_plot.png :height 800 :width 600

    sub.for.rmse.plot <- grid.master.df %>%
        filter(target.type == "multinomial",
               image == "wausauNAIP",
               n.points == 225)


    ggplot(sub.for.rmse.plot, aes( x = pct.t.googleEarth, y = pct_t_pred, color = model)) +
  geom_point() + geom_smooth() + theme_classic() +
  geom_line(data = data.frame(pct.t.googleEarth = c(0,1), pct_t_pred = c(0,1), seg.params = "1:1"),
  color = "black", size = 1) +
  ggtitle("NAIP, n.pts: 225")

#+END_SRC



***** Calc RMSE table

 Create dataframe with structure:

 | RMSE | image | segmentation | target | model | cropped.to.n.pts | cover_type |   |   |   |   |   |   |   |
 |------+-------+--------------+--------+-------+------------------+------------+---+---+---+---+---+---+---|
 |      |       |              |        |       |                  |            |   |   |   |   |   |   |   |


****** Calc Error Column

#+BEGIN_SRC R
  error_tree <- grid.master.df %>%
      filter(target.cover == "tree" | target.cover == "all") %>%
      select(-target.cover) %>%
      group_by(image, model, n.points, seg.params, target.type) %>%
      mutate(t_error = (pct_t_pred - pct.t.googleEarth))

  error_tree %>%
      select(image, model, n.points, seg.params, target.type, grid, t_error) %>%
      filter(n.points == 225) %>%
      ungroup() %>%
      arrange(desc(abs(t_error))) %>%
      data.frame() %>%
      head(n=50)
#+END_SRC



#+BEGIN_SRC R

    RMSE_tree <- grid.master.df %>%
        filter(target.cover == "tree" | target.cover == "all") %>%
        select(-target.cover) %>%
        group_by(image, model, n.points, seg.params, target.type) %>%
        summarize(RMSE_t = sqrt( mean( (pct_t_pred - pct.t.googleEarth)^2, na.rm =T ) ) )

  RMSE_tree <- RMSE_tree %>%
      mutate(segment.size = ifelse(!is.na(str_extract(seg.params, ".*105.*")), 105,
                            ifelse(!is.na(str_extract(seg.params, ".*60.*")), 60,
                            ifelse(!is.na(str_extract(seg.params, ".*30.*")), 30,
                            ifelse(!is.na(str_extract(seg.params, ".*70.*")), 105,
                            ifelse(!is.na(str_extract(seg.params, ".*40.*")), 60,
                            ifelse(!is.na(str_extract(seg.params, ".*20.*")), 30,1)))))))
#+END_SRC

***** RMSE analysis

Which combination of image, segmentation, target, model and n.pts
(spatial scale) minimize error for each cover_type?

#+BEGIN_SRC R :results raw
options(asciiType = "org")
options(warn = -1)
  RMSE_tree %>%
      ungroup() %>%
      arrange(RMSE_t) %>%
      head(n = 30) %>%
      ascii()
#+END_SRC



Plot:
x = cropped.to.n.pts
y = RMSE
color = model
facet(segmentation~cover_type)

#+BEGIN_SRC R :results graphics :file figs/RMSE_tree_compare_n.ptsXRMSE.png :height 800 :width 600

  ggplot(RMSE_tree, aes(x = n.points, y = RMSE_t, color = model)) + geom_point() +
      facet_grid(segment.size~image)

#+END_SRC


#+BEGIN_SRC R :results graphics :file figs/RMSE_tree_compare_AreaXRMSE_NAIP_seg60.png
  RMSE_tree.sub <- RMSE_tree%>%
      filter(segment.size == 60, image == "madisonNAIP", target.type == "binomial", model == "svm_resp") %>%
      mutate(area_meters_squared = ((sqrt(n.points) - 1) * 7)^2)


  ggplot(RMSE_tree.sub, aes(x = area_meters_squared, y = RMSE_t), color = "blue") + geom_point() +
      labs(y = "Root Mean Squared Prediction Error \n for Percent Tree Cover") +
      theme_classic() +
      theme(axis.title = element_text(size = 24),
            axis.text =  element_text(size = 22)) +
      xlim(0,45000)

#+END_SRC


#+BEGIN_SRC R :results graphics :file figs/RMSE_tree_compare_seg.sizeXRMSE.png :height 800 :width 600

  ggplot(RMSE_tree, aes(x = segment.size, y = RMSE_t, color = n.points, group = interaction(n.points,target.type))) + geom_line() +
      facet_grid(model~image)

#+END_SRC


#+BEGIN_SRC R :results raw

  m1 <-lm(RMSE_t*100 ~ image * (model +  target.type + n.points * segment.size), data = RMSE_tree)
  tidy(m1, digits = 2) %>%
ascii()
#+END_SRC

** How accurate is NAIP?
#+BEGIN_SRC R
  pts.robi <- readOGR(dsn = "../RD_Accuracy/PointsByRobi/", layer = "accuracy_cover_2500")
  proj4string(pts.robi) <- utm16
  #pts.robi <- spTransform(pts.robi, utm16)
  plot(pts.robi)

  madison <-  readOGR(dsn = "../RD_US_UrbanAreasShapefile", layer = "cb_2013_us_ua10_500k")
  madison <- madison[madison@data$NAME10 == "Madison, WI",]
  plot(madison, add = T)

  madison <- spTransform(madison, utm16)

  pts.urb <- over(pts.robi, madison) %>% na.omit()

#+END_SRC


* Classify Every Urban Area in the State
** libraries
#+BEGIN_SRC R
    library(ascii)
    library(rgeos)
    library(mlr)
    library(broom)
    library(rgdal)
  library(gdalUtils)
    library(raster)
    library(plyr)
    library(ggplot2)
    library(dplyr)
    library(tidyr)
    library(stringr)
    library(foreach)
    library(doParallel)
#+END_SRC

** Functions

*** Extract Name from path
#+BEGIN_SRC R
  extract.name.from.path <- function(path) {
      str_extract(basename(path), "[A-Za-z0-9_]*.") %>%
          str_sub(.,1,-2)
  }
#+END_SRC

*** Reproject Shapefile to Image Coordinate Reference System
#+BEGIN_SRC R
  Reproject_Shapefile_to_Image_CRS <- function(shapefile.dsn,
                                               shapefile.layer,
                                               image.path,
                                               shapefile.out.dsn) {
      r <- stack(image.path)
      shapefile <- readOGR(shapefile.dsn, shapefile.layer)
      shapefile.WimageCRS <- spTransform(shapefile, crs(r))
      image.name <- extract.name.from.path(image.path)
      shapefile.layer  <- str_c(image.name,"_",shapefile.layer)
      writeOGR(shapefile.WimageCRS, shapefile.out.dsn, shapefile.layer, driver = "ESRI Shapefile", overwrite =T)
  }
#+END_SRC

*** Crop image to each Shapefile polygon
#+BEGIN_SRC R
  Crop_image_to_each_Shapefile_polygon <- function(shapefile.dsn,
                                                   shapefile.layer,
                                                   image.path,
                                                   cores,
                                                   output.dir)  {
      image.name <- extract.name.from.path(image.path)
      shape <- readOGR(shapefile.dsn, str_c(image.name,"_",shapefile.layer))
      polygons <- as(shape, "SpatialPolygons")

      image <- stack(image.path)

      cl <- makeCluster(cores)
      registerDoParallel(cl)

      foreach (i = seq_along(polygons),
               .packages = c("raster")) %dopar% {
                   r <- image
                   r <- crop(r, polygons[i])
                   writeRaster(r, paste0(output.dir,"/",image.name,"-",i,".tif"),
                               overwrite = T)
               }
  }

#+END_SRC

*** Crop image to regions around shapefile points
#+BEGIN_SRC R

                                          # assign the polygon name to the points.
  give_polygons_attributes_of_first_point_within <- function(points,
                                                             polygons){
      if (length(points@data$row) >1) {
          points <- points[points@data$row ==1 & points@data$col ==1 ,]
      }
      po <- gIntersects(points, polygons, byid=TRUE)
      out <- foreach(polygon.number = seq_along(polygons), .combine = "rbind") %do% {
          first.point.data <- points[po[polygon.number,],]@data %>%
              slice(1)
          pd <- as(polygons[polygon.number], "SpatialPolygonsDataFrame")
          pd@data <- first.point.data
          pd
      }
  }

  Crop_image_to_regions_around_points_nameBygrid<- function(shapefile.dsn,
                                                            shapefile.layer,
                                                            image.path,
                                                            cores,
                                                            output.dir,
                                                            column.name = "unq__ID",
                                                            point.buffer.size = 4,
                                                            polygon.buffer.size = 15)  {
      image.name <- extract.name.from.path(image.path)
      points <- readOGR(shapefile.dsn,str_c(image.name,"_",shapefile.layer))
      box <- gBuffer(points, width = point.buffer.size, byid = F)
      box <- disaggregate(box)

      polygons <- as(box, "SpatialPolygons")

      polygons <- give_polygons_attributes_of_first_point_within(points,polygons)

      image <- stack(image.path)

      image.extent <- as(extent(image), "SpatialPolygons")
      proj4string(image.extent) <- proj4string(image)

      polygons.in.image <- foreach(i = seq_along(polygons),.combine = "c") %do% {
          gIntersects(polygons[i,],image.extent)
      }

      polygons <- polygons[polygons.in.image,]

      cl <- makeCluster(cores)
      registerDoParallel(cl)

      foreach (k = seq_along(polygons),
               .packages = c("raster","rgeos")) %dopar% {
                   r <- image
                   poly <- gBuffer(polygons[k,],width = polygon.buffer.size, byid = T)
                   r <- crop(r, poly)
                   tile.id <- polygons@data[k,column.name]
                   writeRaster(r, paste0(output.dir,"/",image.name,"_",tile.id,".tif"),
                               overwrite = T)
               }
  }

                                          #  shapefile.dsn = grid.accuracy.region.imageCRS.dsn
                                          #  shapefile.layer = grid.accuracy.region.layer,
                                          #  output.dir = image.cropped.to.grid.accuracy.dir


  Crop_image_to_regions_around_points <- function(shapefile.dsn,
                                                  shapefile.layer,
                                                  image.path,
                                                  cores,
                                                  output.dir)  {

      points <- readOGR(shapefile.dsn, shapefile.layer)
      box <- gBuffer(points, width = 8)
      box <- disaggregate(box)

      polygons <- as(box, "SpatialPolygons")

      image <- stack(image.path)

      cl <- makeCluster(cores)
      registerDoParallel(cl)

      foreach (i = seq_along(polygons),
               .packages = c("raster")) %dopar% {
                   r <- image
                   r <- crop(r, polygons[i])
                   writeRaster(r, paste0(output.dir,"/",i,".tif"),
                               overwrite = T)
               }
  }

#+END_SRC

*** Make new ratio bands from image
#+BEGIN_SRC R
  ratio <- function(image_w4bands, numerator_bandNumber) {
      r <- image_w4bands[,,numerator_bandNumber,drop = F] / sum(image_w4bands)
      return(r)
  }

  ndvi_nodrop <- function(image_w4bands,red_bandnumber,nir_bandnumber,...) {
      red_band <- image_w4bands[[red_bandnumber]]
      nir_band <- image_w4bands[[nir_bandnumber]]
      ndvi <- (nir_band - red_band)/(nir_band + red_band)
      return(ndvi)
  }

  add.ratios.ndvi <- function(tile.dir,
                              tile.name,
                              out.tile.name.append = ratio.tile.name.append,
                              band.names = c("blue","green","red","nir"),
                              red.band.number = 3,
                              nir.band.number = 4) {

      in.tile.path <- str_c(tile.dir, "/", tile.name, ".tif")
      tile <- stack(in.tile.path)
      names(tile) <- band.names

                                          # Create a ratio image for each band
      ratio.brick <- ratio(tile)
      ratio.brick <- ratio.brick*200 # rescale ndvi to save as 'INT1U'
      names(ratio.brick) <- paste0(band.names,rep("_ratio",times = 4))
      ndvi <- ndvi_nodrop(tile, red.band.number, nir.band.number)
      ndvi <- (ndvi+1)*100 # rescale ndvi to savep as 'INT1U'

                                          # if tile is not scaled 0-255, do it here
      if (getRasterMax(tile) > 255) {
          min <- getRasterMin(tile)
          max <- getRasterMax(tile)
          tile <- rescale.0.255(tile,min,max)
      }

      ratio.tile <- raster::stack(tile, ratio.brick, ndvi)
      writeRaster(ratio.tile,
                  filename = paste0(tile.dir,"/",tile.name,out.tile.name.append, ".tif"),
                  overwrite = T,
                  datatype = 'INT1U')
  }
#+END_SRC

*** Image PCA
#+BEGIN_SRC R
  getRasterMin <- function(t) {
      return(min(cellStats(t, stat = "min")))
  }

  getRasterMax <- function(t) {
      return(max(cellStats(t, stat = "max")))
  }

  rescale.0.255 <- function(raster,
                            min,
                            max) {
                                (raster - min)/(max-min) * 255
  }

  image.pca <- function(image.name,
                        pca.model.name.append = pca.model.name.appendage,
                        tile.dir,
                        tile.name,
                        in.image.appendage = ratio.tile.name.append,
                        out.image.appendage = pca.tile.name.append,
                        band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi"),
                        comps.to.use = c(1,2,3),
                        pca.dir = dd.pca.dir) {


      out.path <- str_c(tile.dir, "/", tile.name, out.image.appendage, ".tif")

      s <- stack(str_c(tile.dir, "/", tile.name, in.image.appendage,".tif"))
      names(s) <- band.names

      pca.model <- readRDS(str_c(pca.dir,"/",image.name,pca.model.name.append))

      r <- predict(s, pca.model, index = comps.to.use)

      min.r <- getRasterMin(r)
      max.r <- getRasterMax(r)
      rescaled.r <- rescale.0.255(r, min.r, max.r)
      writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')
  }



  make.and.save.pca.transformation <- function(tile.dir,
                                               image.name,
                                               pca.model.name.append = pca.model.name.appendage,
                                               max.sample.size = 10000,
                                               core.num = cores,
                                               band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {

      tile.paths <- list.files(str_c(tile.dir), pattern = str_c(image.name,".*_with_ratios.tif$"), full.names = T)

      tile.names <- basename(tile.paths)

      cl <- makeCluster(core.num)
      registerDoParallel(cl)

      sr <- foreach (i = seq_along(tile.names), .packages = c("raster"), .combine ="rbind") %dopar% {
          tile <- stack(tile.paths[i])
          s <- sampleRandom(tile, ifelse(ncell(tile) > max.sample.size ,max.sample.size, ncell(tile)))
      }

      colnames(sr) <- band.names

                                          # Perform PCA on sample
      pca <- prcomp(sr, scale = T)
      saveRDS(pca,paste0(tile.dir,"/",image.name,pca.model.name.append))
      return(pca)
  }


  image.pca.forWholeState <- function(pca.model.name.append = pca.model.name.appendage,
                                      tile.dir,
                                      tile.name,
                                      in.image.appendage = ratio.tile.name.append,
                                      out.image.appendage = pca.tile.name.append,
                                      band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi"),
                                      comps.to.use = c(1,2,3),
                                      pca.transform) {


      out.path <- str_c(tile.dir, "/", tile.name, out.image.appendage, ".tif")

      s <- stack(str_c(tile.dir, "/", tile.name, in.image.appendage,".tif"))
      names(s) <- band.names

      r <- predict(s, pca.transform, index = comps.to.use)

      min.r <- getRasterMin(r)
      max.r <- getRasterMax(r)
      rescaled.r <- rescale.0.255(r, min.r, max.r)
      writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')
  }



  ## image.dir <- image.cropped.to.training.dir
  ## image.name <- 9
  ##                         in.image.appendage = ratio.tile.name.append
  ##                         out.image.appendage = pca.tile.name.append
  ##                         band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")
  ##                         max.sample.size = 10000
  ##                         comps.to.use = c(1,2,3)

  ##       out.path <- str_c(image.dir, "/", image.name, out.image.appendage, ".tif")

  ##       s <- stack(str_c(image.dir, "/", image.name, in.image.appendage,".tif"))
  ##       names(s) <- band.names

  ##       sr <- sampleRandom(s, ifelse(ncell(s) > max.sample.size, max.sample.size, ncell(s)))
  ##       pca <- prcomp(sr, scale = T)

  ##       r <- predict(s, pca, index = comps.to.use)

  ##       min.r <- getRasterMin(r)
  ##       max.r <- getRasterMax(r)
  ##       rescaled.r <- rescale.0.255(r, min.r, max.r)
  ##       writeRaster(rescaled.r, filename = out.path, overwrite=TRUE, datatype = 'INT1U')









                                          # Function takes raster stack, samples data, performs pca and returns stack of first n_pcomp bands
  ## predict_pca_wSampling_parallel <- function(stack, sampleNumber, n_pcomp, nCores = detectCores()-1) {
  ##     sr <- sampleRandom(stack,sampleNumber)
  ##     pca <- prcomp(sr, scale=T)
  ##     beginCluster()
  ##     r <- clusterR(stack, predict, args = list(pca, index = 1:n_pcomp))
  ##     endCluster()
  ##     return(r)
  ## }
#+END_SRC

*** polygonize segment raster with gdal and add Class to shapefile

#+BEGIN_SRC R
  gdal_polygonizeR <- function(x, outshape=NULL, gdalformat = 'ESRI Shapefile',
                               pypath=NULL, readpoly=TRUE, quiet=TRUE) {
      if (isTRUE(readpoly)) require(rgdal)
      if (is.null(pypath)) {
          pypath <- Sys.which('gdal_polygonize.py')
      }
      if (!file.exists(pypath)) stop("Can't find gdal_polygonize.py on your system.")
      owd <- getwd()
      on.exit(setwd(owd))
      setwd(dirname(pypath))
      if (!is.null(outshape)) {
          outshape <- sub('\\.shp$', '', outshape)
          f.exists <- file.exists(paste(outshape, c('shp', 'shx', 'dbf'), sep='.'))
          if (any(f.exists))
              stop(sprintf('File already exists: %s',
                           toString(paste(outshape, c('shp', 'shx', 'dbf'),
                                          sep='.')[f.exists])), call.=FALSE)
      } else outshape <- tempfile()
      if (is(x, 'Raster')) {
          require(raster)
          writeRaster(x, {f <- tempfile(fileext='.asc')})
          rastpath <- normalizePath(f)
      } else if (is.character(x)) {
          rastpath <- normalizePath(x)
      } else stop('x must be a file path (character string), or a Raster object.')
      system2('python', args=(sprintf('"%1$s" "%2$s" -f "%3$s" "%4$s.shp"',
                                      pypath, rastpath, gdalformat, outshape)))
      if (isTRUE(readpoly)) {
          shp <- readOGR(dirname(outshape), layer = basename(outshape), verbose=!quiet)
          return(shp)
      }
      return(NULL)
  }


  polygonize.and.add.Class <- function(image.dir,
                                       image.name,
                                       segment.appendage = segment.tile.name.append,
                                       no.class = "N") {
      seg <- raster(paste0(image.dir,"/",image.name,segment.appendage,'.tif'))
      segPoly <- gdal_polygonizeR(seg)
      segPoly$Class <- no.class
      writeOGR(obj = segPoly,
               dsn = paste0(image.dir,"/",image.name),
               layer = paste0(image.name,segment.appendage),
               driver = "ESRI Shapefile",
               overwrite = T)
  }






#+END_SRC

*** other Functions
#+BEGIN_SRC R

  Water_Urban_mask <- function(tile.path, tile.name, urban, water) {
                                          # load image tile
      tile <- stack(tile.path)
                                          # get extent image and make sp object
      et <- as(extent(tile), "SpatialPolygons")
      proj4string(et) <- "+init=epsg:26916"
                                          # Mask out non-urban areas
      if(gContainsProperly(urban,et) & !gIntersects(water,et)){
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      } else if (gContainsProperly(urban,et) & gIntersects(water,et)) {
          tile <- mask(tile, water, inverse = T)
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      } else if (gIntersects(urban, et) & !gIntersects(water,et)) {
          tile <- mask(tile, urban)
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      } else if (gIntersects(urban, et) & gIntersects(water,et)) {
          tile <- mask(tile, urban)
          tile <- mask(tile, water, inverse = T)
          writeRaster(tile, filename = str_c(masked.tiles.directory,"/",tile.name), overwrite = T)
      }
  }

  Crop_mask <- function(tile.path, tile.name, CDL_stack, n_years){

      tile <- stack(tile.path)
      crops <- crop(CDL_stack, tile)

                                          # These are the values in the CDL that correspond to non crop cover types and not water
      NonCroppedValues <- c(0,63:65, 81:83, 87:88, 112, 121:124, 131, 141:143, 152, 176, 190, 195)
                                          # open water is 111

      NonCroppedValues <- c(0,63:65, 81:83, 87:88, 112, 121:124, 131, 141:143, 152, 176, 190, 195)
                                          # open water is 111. I don't include it in the above list so that it gets masked

                                          # I'm going to add 37, Other Hay/Non-alfalfa, to the non crop cover types
      NonCroppedValues <- c(NonCroppedValues, 37)
                                          # I'm going to add 36, Alfalfa, to the non crop cover types
      NonCroppedValues <- c(NonCroppedValues, 36)

                                          # find cells that have been assigned crop all three years
      crops[crops %in% NonCroppedValues] <- 0
      crops[!(crops %in% NonCroppedValues)] <- 1
      cropsum <- overlay(crops, fun = sum)

      dis.cropsum <- disaggregate(cropsum, fact = 20)
      dis.cropsum <- resample(dis.cropsum, tile, "ngb")
      masked_tile <- mask(tile, dis.cropsum, maskvalue = n_years)

                                          #               Save Image
      writeRaster(masked_tile, paste0(crop.masked.tiles.directory, "/", tile.name), overwrite = T)
  }








#+END_SRC

*** Make Pixel Feature DF
#+BEGIN_SRC R
  Create.Pixel.Feature.df <- function(tile.dir,
                                      tile.name,
                                      tile.appendage = ratio.tile.name.append,
                                      Pixel.DF.appendage = pixel.feature.df.appendage,
                                      band.names = band.names.wRatios) {
      r <- stack(paste0(tile.dir,"/",tile.name,tile.appendage,".tif"))
      names(r) <- band.names
      r.df <- as.data.frame(r, xy=T)
      saveRDS(r.df, file = paste0(tile.dir,"/", tile.name, Pixel.DF.appendage, ".rds"))
  }



  ## Create.Pixel.Feature.df<- function(raster.list,
  ##                                    band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {
  ##     r.df.list <- lapply(raster.list, function(r) {
  ##                             names(r) <- band.names
  ##                             as.data.frame(r, xy=T)
  ##            })
  ##     bind_rows(r.df.list)
  ## }

  Create.Pixel.Feature.df.noRowbind<- function(raster.list,
                                               band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {
      r.df.list <- lapply(raster.list, function(r) {
          names(r) <- band.names
          as.data.frame(r, xy=T)
      })
      r.df.list
  }


  Create.Pixel.Feature.df.foreachTile <- function(dir = image.cropped.to.grid.accuracy.dir[i],
                                                  base_pattern = "mad-[0-9]+m-[0-9]+_with_ratios.tif",
                                                  band.names = c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")) {

      file.list <- list.files(dir, full.names = T) %>%
          str_extract(., paste0(".*",base_pattern)) %>%
          na.omit() %>%
          unique()

      r.df.list <- lapply(file.list, function(r) {
          ras <- stack(r)
          names(ras) <- band.names
          ras.df <- as.data.frame(r, xy=T)

          r <- str_extract(r, base_pattern) %>%
              str_sub(., 1, -17)

          saveRDS(ras.df, file = str_c(dir,"/",r,"PixelFeatureDF",".rds"))
      })
  }

#+END_SRC

*** Make Segment Feature DF
#+BEGIN_SRC R
  fitXYlm <- function(x,y,z) {
      if(is.na(sum(z))) {
          z <- rep(0, length(z))
      }
      dat <- data.frame(x,y,z)
      mod <- lm(z ~ x * y, data = dat)
      coefs <-tidy(mod) %>%
          dplyr::select(term,estimate) %>%
          spread(key = term, value = estimate)

      error <- glance(mod) %>%
          select(sigma)

      bind_cols(coefs,error)
  }

                                          #foreach(seg.param.set = seg.param) %do% {}

  Create.Segment.Feature.df <- function(tile.dir,
                                        tile.name,
                                        ratio.appendage = ratio.tile.name.append,
                                        band.names = band.names.wRatios){

                                          #tile.name.stem everything before segmentation parameters
      tile.name.stem = str_replace(tile.name, pattern = segmentation.layer.pattern, "")

      ratio.tile.path <- str_c(tile.dir, "/", tile.name.stem, ratio.tile.name.append, ".tif")
      r.tile <- stack(ratio.tile.path)

      names(r.tile) <- band.names


      seg.tile.path <-  str_c(tile.dir, "/", tile.name,".tif")
      s.tile <- raster(seg.tile.path)

                                          # Create a data_frame where mean and variances are calculated by zone
      x <- as.data.frame(r.tile, xy = T)
      s <- as.data.frame(s.tile)
      colnames(s) <- "segment"
      r <- bind_cols(x,s)
      r2 <- r %>%
          group_by(segment) %>%
          mutate(x.center = x - quantile(x = x, probs = .5),
                 y.center = y - quantile(x = y, probs = .5))

      spatial.model.coef <- r2 %>%
          do(fitXYlm(x = .$x.center, y = .$y.center, z = .$n_ratio))

      mean.and.sd <- r2 %>%
          summarize(mean(blue),
                    mean(green),
                    mean(red),
                    mean(nir),
                    mean(b_ratio),
                    mean(g_ratio),
                    mean(r_ratio),
                    mean(n_ratio),
                    mean(ndvi),
                    sd(blue),
                    sd(green),
                    sd(red),
                    sd(nir),
                    sd(b_ratio),
                    sd(g_ratio),
                    sd(r_ratio),
                    sd(n_ratio),
                    sd(ndvi))

      tile.name = data.frame(tile.name = rep(tile.name.stem, nrow(mean.and.sd)))

      out <- left_join(spatial.model.coef, mean.and.sd) %>%
          bind_cols(., tile.name)

      names <- colnames(out)
      names <- str_replace(names, "\\(",".")
      names <- str_replace(names, "\\)",".")
      names <- str_replace(names, "\\:",".")
      colnames(out) <- names
      out
  }

  Create.Segment.Feature.df.noLM <- function(tile.dir,
                                             tile.name,
                                             ratio.appendage = ratio.tile.name.append,
                                             band.names = band.names.wRatios){

                                          #tile.name.stem everything before segmentation parameters
      tile.name.stem = str_replace(tile.name, pattern = segmentation.layer.pattern, "")

      ratio.tile.path <- str_c(tile.dir, "/", tile.name.stem, ratio.tile.name.append, ".tif")
      r.tile <- stack(ratio.tile.path)

      names(r.tile) <- band.names


      seg.tile.path <-  str_c(tile.dir, "/", tile.name,".tif")
      s.tile <- raster(seg.tile.path)

                                          # Create a data_frame where mean and variances are calculated by zone
      x <- as.data.frame(r.tile, xy = T)
      s <- as.data.frame(s.tile)
      colnames(s) <- "segment"
      r <- bind_cols(x,s)
      r2 <- r %>%
          group_by(segment)

      mean.and.sd <- r2 %>%
          summarize(mean(blue),
                    mean(green),
                    mean(red),
                    mean(nir),
                    mean(b_ratio),
                    mean(g_ratio),
                    mean(r_ratio),
                    mean(n_ratio),
                    mean(ndvi),
                    sd(blue),
                    sd(green),
                    sd(red),
                    sd(nir),
                    sd(b_ratio),
                    sd(g_ratio),
                    sd(r_ratio),
                    sd(n_ratio),
                    sd(ndvi))

      tile.name = data.frame(tile.name = rep(tile.name.stem, nrow(mean.and.sd)))

      out <- bind_cols(mean.and.sd, tile.name)

      names <- colnames(out)
      names <- str_replace(names, "\\(",".")
      names <- str_replace(names, "\\)",".")
      names <- str_replace(names, "\\:",".")
      colnames(out) <- names
      out
  }

#+END_SRC

*** Create ModelBuilding dataframe
#+BEGIN_SRC R
  getSegment.class.and.features.Within.Polygon <- function(SegmentFeatureDF,
                                                           training.sp,
                                                           seg.tiles.dir,
                                                           seg.params){
      seg.files <- list.files(seg.tiles.dir, pattern = str_c(seg.params,".tif$"), full.names = T)
                                          # find number of pixels in each segment
      n.pixels.per.seg <- foreach(seg.file = seg.files, .combine = "rbind") %do% {
          seg <- stack(seg.file)
          s.df <- as.data.frame(seg) %>%
              gather(key = tile.name, value = segment.id) %>%
              group_by(segment.id, tile.name) %>%
              summarize(n.pixels.per.seg = n())
      }
                                          # find number of pixels in each segment are in a polygon
      n.pixels.per.seg.in.polygon <- foreach(seg.file = seg.files, .combine = "rbind") %do% {
          seg <- stack(seg.file)
          a <- raster::extract(seg, as(training.sp,"SpatialPolygons"), df = T)
          if(length(a) > 1) {
              a <- a %>%
                  gather(key = tile.name, value = segment.id, -ID) %>%
                  rename(polygon.id = ID) %>%
                  group_by(polygon.id, tile.name, segment.id) %>%
                  summarize(n.pixels.per.seg.in.polygon = n())
          }
      }
                                          # get pct of segment in a polygon,
                                          # filter segments that have more than 50%,
                                          #join Class information from polygons
      if(!is.null(n.pixels.per.seg.in.polygon)) {
          n.pixels <- left_join(n.pixels.per.seg.in.polygon,n.pixels.per.seg) %>%
              mutate(pct.seg.in.polygon = n.pixels.per.seg.in.polygon/n.pixels.per.seg) %>%
              filter(pct.seg.in.polygon >= .5) %>%
              left_join(.,training.sp@data, by = c("polygon.id" = "id")) %>%
              ungroup() %>%
              mutate(tile.name = str_extract(tile.name, "X[0-9]+_"),
                     tile.name = str_sub(tile.name,2,-2)) %>%
              mutate(segment = segment.id)

          left_join(n.pixels, SegmentFeatureDF) %>%
              dplyr::select(-segment,
                            -segment.id,
                            -tile.name,
                            -polygon.id,
                            -n.pixels.per.seg,
                            -n.pixels.per.seg.in.polygon,
                            -pct.seg.in.polygon) %>%
              filter(complete.cases(.))
      }
  }

                                          # returns dataframe of values of pixels within polygon
  getPixel.Class.and.Coords.Within.Polygon <- function(PixelFeatureDF,
                                                       training.sp) {
      xy <- select(PixelFeatureDF,x,y) %>% data.frame
      PixelFeatureDF <- data.frame(PixelFeatureDF)
      coordinates(PixelFeatureDF) <- xy
      proj4string(PixelFeatureDF) <- utm16

      training.sp <- spTransform(training.sp,utm16)

      pts.in.poly <- over(PixelFeatureDF,training.sp)
      PixelFeatureDF@data <- cbind(PixelFeatureDF@data, pts.in.poly)
      PixelFeatureDF <- PixelFeatureDF[which(complete.cases(pts.in.poly)),]
      PixelFeatureDF@data
  }

                                          # this is an old way
  create.df.toBuildModel.fromTrainingPolygons.and.SegmentFeatureDFs <- function(manuallyClassifiedPolygondir,
                                                                                image.dir,
                                                                                segment.feature.df.appendage = segment.feature.df.name.append,
                                                                                modelBuildingData.name = "modelBuildingData.rds") {

      segment.feature.df.appendage = segment.feature.df.name.append

                                          # list shapefiles with manually classified polygons
      trainingShapefiles <- list.files(manuallyClassifiedPolygondir) %>%
          str_sub(.,end = nchar(.)-4) %>%
          unique()

                                          # load training data from shapefiles into memory
      shapelist.data <- lapply(trainingShapefiles, function(shp) {
          readOGR(dsn = manuallyClassifiedPolygondir, layer = shp)@data %>%
                                                                     na.omit() %>%
                                                                     rename(zone = DN) %>%
                                                                     filter(Class != "N")
      })

      names(shapelist.data) <- trainingShapefiles


                                          # list .rds segment feature dataframe files
      segmentFeatureDF.rds.files <- list.files(image.dir, full.names = T) %>%
          str_extract(pattern = str_c(".*",segment.feature.df.appendage,".rds")) %>%
          na.omit()

      trainingData <- list()

      foreach(j = seq_along(shapelist.data)) %do% {
          d <- readRDS(segmentFeatureDF.rds.files[j])
          trainingData[[j]] <- left_join(shapelist.data[[j]],d, by = c("zone" = "segment"))
      }

      trainingData <- bind_rows(trainingData) %>%
          filter(Class != "N")

      saveRDS(trainingData, file = str_c(image.dir, "/",modelBuildingData.name))

  }

#+END_SRC
*** Build and Save Models
#+BEGIN_SRC R
  Build.and.Save.models <- function(
                                    dir = dd.training.dir,
                                    modelBuildingData = ModelBuildingRDS,
                                    models.dir = Models.dir,
                                    image.name){

      dat <- readRDS(paste0(dir,"/",modelBuildingData)) %>%
          as.data.frame()

      image.and.segmentation.stem = str_replace(modelBuildingData, ModelBuilding.appendage,"")

      names <- colnames(dat)
      names <- str_replace(names, "\\(",".")
      names <- str_replace(names, "\\)",".")
      names <- str_replace(names, "\\:",".")
      colnames(dat) <- names

      dat_G <- dat %>%
          mutate(Class = as.character(Class),
                 Class = ifelse(Class == "g", Class, "o"))

      dat_I <- dat %>%
          mutate(Class = as.character(Class),
                 Class = ifelse(Class == "i", Class, "o"))

      dat_T <- dat %>%
          mutate(Class = as.character(Class),
                 Class = ifelse(Class == "t", Class, "o"))

                                          # Create Tasks
      all.task <- makeClassifTask(id = paste0(image.name,"_all"), data = dat, target = "Class")
      grass.task <- makeClassifTask(id = paste0(image.name,"_grass"), data = dat_G, target = "Class")
      impervious.task <- makeClassifTask(id = paste0(image.name,"_impervious"), data = dat_I, target = "Class")
      tree.task <- makeClassifTask(id = paste0(image.name,"_tree"), data = dat_T, target = "Class",positive = "t")

      task.list <- list(all = all.task, grass = grass.task, impervious = impervious.task, tree = tree.task)

                                          # Make Learners
      RF_prob <- makeLearner(id = "rf_prob","classif.randomForest", predict.type = "prob", fix.factors.prediction = TRUE)
      RF_response <- makeLearner(id = "rf_resp", "classif.randomForest", predict.type = "response", fix.factors.prediction = TRUE)
      SVM_response <- makeLearner(id = "svm_resp", "classif.svm", predict.type = "response", fix.factors.prediction = TRUE)

      learner.list <- list(RF_prob = RF_prob, RF_response = RF_response, SVM_response = SVM_response)

                                          # Train Learners on Tasks, Make models
                                          #         cl<-makeCluster(cores)
                                          #         registerDoParallel(cl)

      models <- foreach(tsk = task.list, .packages = "mlr") %do% {
          foreach(lnr = learner.list) %do% {
              mod <- train(lnr, tsk)
              mod
          }
      }
      saveRDS(models, file = paste0(models.dir,"/",image.and.segmentation.stem, models.appendage))
  }

#+END_SRC

*** Classify Raster
#+BEGIN_SRC R

  classify.segmented.raster <- function(segment.feature.df.dir,
                                        segment.dir,
                                        model.dir,
                                        model.name.rds = "models",
                                        segment.feature.appendage = segment.feature.df.name.append,
                                        segmentation.appendage = segment.tile.name.append,
                                        segmentation.prms,
                                        classify.out.dir,
                                        tile.name = i) {
      df <- readRDS(paste0(segment.feature.df.dir,"/",tile.name,segment.feature.appendage))
      models <-readRDS(paste0(model.dir,"/",model.name.rds))
      umod <- unlist(models, recursive = F)
      seg.path <- paste0(segment.dir,"/",tile.name,segment.tile.name.append)
      seg <- raster(seg.path)
                                          #       dfRowsWithNA <- which(is.na(df[,2]))
      complete.df <- df[complete.cases(df),] # svm can't predict with NAs
      lapply(umod, function(mod) {
          pred <- predict(mod, newdata = complete.df)
          response <- factor(as.character(pred$data$response), levels = c("g","i","t","o"))
          m <- cbind(zone = complete.df$segment, response)
          m <- left_join(as.data.frame(df["segment"]), as.data.frame(m), by = c("segment" = "zone"))
          r <- reclassify(seg, m)
                                          #        x <- data.frame(ID = 1:4, LandCover = c("G","I","T","O")) %>%
                                          #            filter(LandCover %in% levels(factor(response)))
                                          #        levels(r) <- x
          if (ncol(pred$data) > 2) {
              prob <- (pred$data[,grep("prob.*", x = colnames(pred$data))]) # get columns that contain probabilities
              ProbOfClass <- apply(prob, MARGIN = 1, FUN = max)
              m <- cbind(segment = df$segment, ProbOfClass)
              m <- left_join(as.data.frame(df["segment"]), as.data.frame(m))
              p <- reclassify(seg, m)
              r <- stack(r,p)
          }
          path <- paste0(segment.dir,"/",ClassifiedTilesDirName,"/",tile.name,"_",segmentation.prms,"_",mod$task.desc$id,"_",mod$learner$id,".tif")
          writeRaster(r, path, overwrite=TRUE)
          print(path)
      })
  }


  classify.pixel.raster <- function(tile.dir = dd.accuracy.dir,
                                    tile.name,
                                    pixelFeatureDF.appendage = pixel.feature.df.appendage,
                                    model.dir = Models.dir,
                                    model.rds,
                                    seg.prms = "Pixel") {
      ras <- stack(str_c(tile.dir,"/",tile.name,".tif"))
      pix.mods <- readRDS(str_c(model.dir,"/",model.rds))
      pix.umods <- unlist(pix.mods, recursive = F)

      pix.feature.df <- readRDS(str_c(tile.dir,"/",tile.name,pixelFeatureDF.appendage,".rds"))

      if(!is.null(pix.feature.df$y)) {
          pix.feature.df <- dplyr::select(pix.feature.df, -x, -y)
      }

                                          # I set NA's to 0 here.  Not the best choice.  Not sure why they exist.
                                          # imputing to mean would probably be better

      pix.feature.df <- as.matrix(pix.feature.df)

      pix.feature.df[which(is.na(pix.feature.df))] <- 0

      pix.feature.df <- as.data.frame(pix.feature.df)


      lapply(pix.umods, function(pix.mod) {
          pred <- predict(pix.mod, newdata = pix.feature.df)
          a <- ras[[1]]
          values(a) <- pred$data$response
          path <- paste0(tile.dir,"/",ClassifiedTilesDirName,"/",tile.name,"_",seg.prms,"_",pix.mod$task.desc$id,"_",pix.mod$learner$id,".tif")
          writeRaster(a, path, overwrite = T)
          print(path)
      })
  }








#+END_SRC

#+BEGIN_SRC R :results graphics :file figs/pixClss.png
                                          #plot(a)
#+END_SRC

*** Calculate Percent Cover in Classified Tiles
#+BEGIN_SRC R

  get.prcnt.class <- function(points,r) {
      r <- crop(r,points)  # should I do a mask instead??
      g <- cellStats(r == 1, stat = sum)
      im <- cellStats(r == 2, stat = sum)
      tr <- cellStats(r == 3, stat = sum)
      o <-  cellStats(r == 4, stat = sum)
      totC <- ncell(r)
      return(c(pct_g_pred = g/totC, pct_i_pred = im/totC, pct_t_pred = tr/totC, pct_o_pred = o/totC))
  }


  get_area_convexHull <- function(points) {
      ch <- chull(coordinates(points))
      coords <- coordinates(points)[c(ch,ch[1]),]
      poly <- SpatialPolygons(list(Polygons(list(Polygon(coords)),ID = 1)))
      gArea(poly)
  }



  calculate.percent.cover.in.classified.tile <- function(pts,
                                                         tile.dir = dd.accuracy.classified.dir,
                                                         tile.pth,
                                                         n.rows.and.columns.subset,
                                                         mod = 1,
                                                         mad.grid.id.pattern = "mad-[0-9]+m-[0-9]+",
                                                         grid.pattern = "[a-zA-Z]{3}-[0-9]+m-[0-9]+_",
                                                         image.pattern = "[a-zA-Z]{5}[a-zA-Z]+",
                                                         target.pattern = "all|grass|impervious|tree",
                                                         model.pattern = "rf_prob|rf_resp|svm_resp",
                                                         seg.prms = "N-[0-9]+_C-[0-9]+|Pixel"
                                                         ) {
      tile.nm <- basename(tile.pth)


      pts.sub <- pts@data  %>%
          filter.by.row.and.col(.,n.rows.and.columns.subset, mod = mod)

      coordinates(pts.sub) <- ~ crds_x1 + crds_x2

      proj4string(pts.sub) <- utm16
      tile.unique.name <- str_extract(tile.pth, mad.grid.id.pattern)
      pts.at.grid <- pts.sub[which(pts.sub@data$unq__ID == tile.unique.name),]
      tile <- raster(tile.pth, proj4string = "+init:epsg=32616")

      area.pts <- get_area_convexHull(pts.at.grid)

      if(!is.null(raster::intersect(extent(tile),bbox(pts.at.grid)))) {

          get.prcnt.class(pts.at.grid,tile) %>%
              t() %>%
              as.data.frame() %>%
              mutate(grid.tile.target.model = tile.nm,
                     grid = str_sub(str_extract(grid.tile.target.model, grid.pattern),1,-2),
                     image =  str_extract(grid.tile.target.model, image.pattern),
                     target.cover = str_extract(grid.tile.target.model, target.pattern),
                     model =  str_extract(grid.tile.target.model, model.pattern),
                     n.points = n.rows.and.columns.subset * n.rows.and.columns.subset,
                     area = area.pts,
                     seg.params = str_extract(grid.tile.target.model, seg.prms),
                     target.type = ifelse(target.cover == "all", "multinomial", "binomial"))
      }
  }

#+END_SRC

*** Calculate Percent Cover of Grids, subsetted
#+BEGIN_SRC R
  filter.by.row.and.col <- function(df,nrow.and.col, mod) {
      nrow <-df %>%
          group_by(unq__ID) %>%
          summarize(nrow = max(row))

      df <- left_join(df,nrow)

      df %>%
          filter(nrow >= nrow.and.col,   # remove grids that have fewer than the number of rows & columns
                 row <= nrow.and.col,    # remove rows greater than the number we are interested in
                 col <=nrow.and.col,   # same for columns as rows
                 row %% mod == 0,
                 col %% mod == 0)
  }

  add.n.pts.per.grid <- function(df){
      n.pts<-df %>%
          group_by(unq__ID) %>%
          summarize(n.points = n())

      left_join(df,n.pts)
  }


  get.pct.cvr.typ <- function(df) {
      df %>%
          group_by(unq__ID, cvr_typ,n.points, area) %>%
          summarize(number = n()) %>%
          ungroup() %>%
          mutate(google.truth.pct.cover = number/n.points) %>%
          dplyr::select(-number)
  }

  combine.classes.to.g.i.t.o <- function(df) {

      df %>%
          mutate(cvr_typ = as.character(cvr_typ),
                 cvr_typ = ifelse(cvr_typ == "s",
                                  "i",
                                  cvr_typ),
                 cvr_typ = ifelse(cvr_typ != "g" &
                                  cvr_typ != "i" &
                                  cvr_typ != "t", "o", cvr_typ)) %>%
          group_by(unq__ID, cvr_typ, n.points, area) %>%
          summarize(google.truth.pct.cover = sum(google.truth.pct.cover))

  }


  calc.binomial.pct.cvrs <- function(df) {

      out <- foreach(target.cvr.type = c("g","i","t")) %do%{
          df %>%
              mutate(cvr_typ = ifelse(cvr_typ == target.cvr.type, cvr_typ, "o")) %>%
              group_by(unq__ID, n.points, cvr_typ) %>%
              summarize(pct.cover = sum(pct.cover)) %>%
              mutate(target.type = "binomial",
                     target.cover = target.cvr.type,
                     target.cover = ifelse(target.cover == "g", "grass",
                                    ifelse(target.cover == "t", "tree",
                                           "impervious"))) %>%
              spread(key = cvr_typ, value = pct.cover)
      }
      out <- bind_rows(out)
      out %>%
          rename(pct.g.googleEarth = g, pct.i.googleEarth = i, pct.t.googleEarth = t, pct.o.googleEarth = o)
  }



  get.area.convexHull <- function(x_coord, y_coord) {
      m <- matrix(c(x_coord, y_coord), ncol = 2)
      ch <- chull(m)
      coords <- m[c(ch,ch[1]),]
      poly <- SpatialPolygons(list(Polygons(list(Polygon(coords)),ID = 1)))
      gArea(poly)
  }



  calc.pct.cvr.for.grid.subset <- function(df,
                                           n.rows.and.columns.for.subset=20,
                                           mod,
                                           gridID = "unq__ID") {


      df <- filter.by.row.and.col(df, n.rows.and.columns.for.subset, mod) %>%
          add.n.pts.per.grid() %>%
          group_by_(gridID)


      area.df <- df %>%
          summarize(area = get.area.convexHull(crds_x1, crds_x2))

      df <- left_join(df, area.df)


      df <- df %>%
          get.pct.cvr.typ() %>%
          combine.classes.to.g.i.t.o() %>%
                                          #               ungroup() %>%
                                          #               dplyr::select(-n.points) %>%
          spread(., key = cvr_typ, value = google.truth.pct.cover, fill = 0)

                                          #         df[is.na(df)] <- 0

      df.multnm <- df %>%
          mutate(target.type = "multinomial") %>%
          rename(pct.g.googleEarth = g, pct.i.googleEarth = i, pct.t.googleEarth = t) %>%
          mutate(target.cover = "all")

      if(!is.null(df.multnm$o)) { df.multnm <- rename(df.multnm, pct.o.googleEarth = o)}

      df <- df %>%
          gather(key = cvr_typ, value = pct.cover, -unq__ID, -n.points)

      df.binm <- df %>%
          calc.binomial.pct.cvrs()


      df.out <- bind_rows(df.binm, df.multnm)
      return(df.out)
  }



#+END_SRC

*** Point-wise error functions
#+BEGIN_SRC R
  calcErrorAllMultinomial <-  function(pts, tile, Pixel = F) {
      classification <- raster::extract(classified.tile, pts)
      if(Pixel == T) {
          lvls <- levels(classified.tile)[[1]]
          classification <- mapvalues(classification, from = lvls[,1], to = as.character(lvls[,2]))
      } else {
          classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
      }
      google = pts@data$cvr_typ
      overall.error <- 1 - mean(classification == google)
      pct.grass.classified.as.other <- 1 - mean(classification[which(google == "g")] == google[which(google == "g")])
      pct.impervious.classified.as.other <- 1 - mean(classification[which(google == "i")] == google[which(google == "i")])
      pct.tree.classified.as.other <- 1 - mean(classification[which(google == "t")] == google[which(google == "t")])
      error <- c(overall.error = overall.error,
                 pct.grass.classified.as.other = pct.grass.classified.as.other,
                 pct.impervious.classified.as.other = pct.impervious.classified.as.other,
                 pct.tree.classified.as.other = pct.tree.classified.as.other)
      return(error)
  }

  calcErrorBinomial <-  function(pts, tile, target, Pixel = F) {
      classification <- raster::extract(classified.tile, pts)
      if(Pixel == T) {
          lvls <- levels(classified.tile)[[1]]
          classification <- mapvalues(classification, from = lvls[,1], to = as.character(lvls[,2]))
      } else {
          classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
      }
      classification <- ifelse(classification == target, classification, "o")
      google <- pts@data$cvr_typ
      google <- ifelse(google == target, google, "o")
      overall.error <- 1 - mean(classification == google)
      pct.grass.classified.as.other <- 1 - mean(classification[which(google == "g")] == google[which(google == "g")])
      pct.impervious.classified.as.other <- 1 - mean(classification[which(google == "i")] == google[which(google == "i")])
      pct.tree.classified.as.other <- 1 - mean(classification[which(google == "t")] == google[which(google == "t")])
      error <- c(overall.error = overall.error,
                 pct.grass.classified.as.other = pct.grass.classified.as.other,
                 pct.impervious.classified.as.other = pct.impervious.classified.as.other,
                 pct.tree.classified.as.other = pct.tree.classified.as.other)
      return(error)
  }




  calcConfusionMat <- function(pts, tile) {
      classification <- raster::extract(classified.tile, pts)
      classification <- mapvalues(classification, from = c(1,2,3,4), to = c("g","i","t","o"))
      table(classification, google = pts@data$cvr_typ)
  }


#+END_SRC
*** Plot points on classifed tile

#+BEGIN_SRC R
      pts.on.classified.tile.plot <- function(pts, classified.tile, target = NULL) {
          if(target == "a") {
              pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
              pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, fill = cvr_typ), shape = 21, color = "black", size =2, stroke = .2)
          } else {
              pts@data <- pts@data %>%
                  mutate(cvr_typ = ifelse(cvr_typ == target, cvr_typ, "o"))
                  pts.plot <- geom_point(data = pts@data, aes(x = x, y = y, color = cvr_typ))
          }
          r.df <- as.data.frame(classified.tile, xy = T)
          names(r.df) <- c("x","y","cvr_typ")
          r.df <- r.df %>%
              mutate(cvr_typ = mapvalues(cvr_typ, from = c(1,2,3,4), to = c("g","i","t","o")))
          pxls.plot <- ggplot() + geom_raster(data = r.df, aes(x = x, y = y, fill = cvr_typ))
          title <- ggtitle(label = names(classified.tile))
          UTC_pal <- c(g = "#ffff99", i = "#f0027f", t = "#7fc97f", o = "#666666")
          pxls.plot + pts.plot + title + scale_fill_manual(values = UTC_pal)+ scale_color_manual(values = UTC_pal) +
  coord_equal()
      }



#+END_SRC
** inputs

*** Raster Temp Dir
#+BEGIN_SRC R
R_raster_temp <- "../R_raster_temp"
dir.create(R_raster_temp)
rasterOptions(tmpdir=R_raster_temp)
#+END_SRC

*** Projections
#+BEGIN_SRC R
wtm <- CRS("+init=epsg:3070")
#+END_SRC

*** cores
#+BEGIN_SRC R
cores <- detectCores() - 2
#+END_SRC

#+results:
: Error: could not find function "detectCores"

*** Urban, Water, and Wetland shapefiles
#+BEGIN_SRC R
  urban.areas.dsn <- "../RD_merged_WIurbanAreas_and_incorporatedAreas"
  urban.areas.layer <- "Dissolve_Merge_WI_census_inc"

  ## urban.areas.dsn <- "../RD_US_UrbanAreasShapefile"
  ## urban.areas.layer <- "cb_2013_us_ua10_500k"


  water.dsn <- "../RD_WI-waterbody-24k"
  water.layer <- "WD-Hydro-Waterbody-WBIC-AR-24K"

  wetlands.dsn <- "../RD_Wetland"
  wetlands.layer <- "WI_Wetlands"

#+END_SRC

*** Cropland Data Layer
#+BEGIN_SRC R
  crop.directory <- "../RD_CroplandDataLayer/"
  crop2010.name <- "CDL_2010_clip_20160128162252_788770535"
  crop2011.name <- "CDL_2011_clip_20160106190244_1504737741"
  crop2012.name <- "CDL_2012_clip_20151229124713_1037776543"
  crop2013.name <- "CDL_2013_clip_20151229123327_86558742"
  crop2014.name <- "CDL_2014_clip_20151229123327_86558742"

  n_croplandLayers <- 5

#+END_SRC

*** NAIP tiles directory
#+BEGIN_SRC R
naip.dir <- "../../../../home/erker/NAIP_mount/NAIP13_WTM_TIFs"
#+END_SRC

*** Model
#+BEGIN_SRC R
model.path <- "../DD/Models/best_mad_model.rds"
#+END_SRC

*** PCA
#+BEGIN_SRC R
madison.naip.pca.path <- "../DD/Madison_pca/madisonNAIP_pca.rds"
#+END_SRC

*** Output Directories
#+BEGIN_SRC R
derived.dir <- "../DD/"
classified.urban.areas.dir <- paste0(derived.dir, "ClassifiedUrbanAreas/")
dir.create(classified.urban.areas.dir)
#+END_SRC

*** Segmentation Parameters
#+BEGIN_SRC R
pixel_size  <- 1 # m^2
segment_size <- 30 # m^2
compactness <- 15
#+END_SRC

*** filename appendages
#+BEGIN_SRC R
  ratio.tile.name.append = "_ratio"
  pca.tile.name.append = "_pca"
  seg.tile.name.append = paste0("_N-",segment_size,"_C-",compactness)
  segmentFeatureDF.append = "_SegFeatureDF"
#+END_SRC

** Reproject shapefiles to be wtm, the same as the images
#+BEGIN_SRC R
  urban <- readOGR(dsn = urban.areas.dsn, layer = urban.areas.layer)
#  water <- readOGR(dsn = water.dsn, layer = water.layer)

  # Both are already in wtm, no need to transform
#+END_SRC

** Disaggregate Urban Area Polygons

#+BEGIN_SRC R
  urb.polys <- disaggregate(as(urban, "SpatialPolygons"))
#+END_SRC

** Load NAIP tifs
#+BEGIN_SRC R
  naip.tif.names <- list.files(naip.dir, recursive = T, full.names = T) %>%
    str_extract(pattern = ".*tif$") %>%
    na.omit()
#+END_SRC

#+BEGIN_SRC R
  naip.stacks <- lapply(naip.tif.names, function(tif) {
      r <- stack(tif)
  })
#+END_SRC

#+BEGIN_SRC R
naip.extents <- lapply(naip.stacks, function(naip.stack) {
extent(naip.stack)
})
#+END_SRC

*** For every urban area in the state
  Eventually Parallelize at this step in the process

#+begin_src R
  areas <- foreach(i = 1:length(urb.polys), .combine = "rbind") %do% gArea(urb.polys[i])
  quant.85 <- quantile(areas[,1],probs = .85)
  i_areas_less_85quant <- which(areas[,1] < quant.85)
#+end_src

 #+BEGIN_SRC R
           cl <- makeCluster(cores)
           registerDoParallel(cl)

#      out <- foreach(i = 1:length(urb.polys)) %do% {

      out <- foreach(i = i_areas_less_85quant) %do% {
           urb.poly <- urb.polys[i]


      ## out <- foreach(i = 1:length(urb.polys),
      ##               .packages = c("sp","raster","rgdal","rgeos", "stringr","doParallel","gdalUtils","plyr","dplyr","mlr")) %dopar% {

#+END_SRC

**** Set temp dir for this urban area
#+BEGIN_SRC R
temp_i <- paste0(R_raster_temp,"/",i)
dir.create(temp_i)
rasterOptions(tmpdir=temp_i)
#+END_SRC

**** Make output dir for this urban area
#+BEGIN_SRC R
urb.path <- paste0(classified.urban.areas.dir, i)
dir.create(urb.path)
#+END_SRC

**** Get names of NAIP tiles that intersect with Urban Area
#+BEGIN_SRC R
       tiles.in.urban <-  lapply(naip.extents, function(naip.extent) {
           inter <- raster::intersect(naip.extent, extent(urb.poly))
           ifelse(is.null(inter), F, T)
         })

  tile.index <- which(unlist(tiles.in.urban))

  tiles.names.at.urb.poly <- naip.tif.names[tile.index]

#+END_SRC

**** For each NAIP tile that intersects with Urban Area
#+BEGIN_SRC R

      foreach(tile.name.at.urb.poly = tiles.names.at.urb.poly,
                     .packages = c("sp","raster","rgdal","rgeos", "stringr","doParallel","gdalUtils","plyr","dplyr","mlr")) %dopar% {

    ## }

  ##   tile.name.at.urb.poly <- tiles.names.at.urb.poly[[1]]
#+END_SRC

***** Make output dir for this tile
#+BEGIN_SRC R
  tile.name <- basename(tile.name.at.urb.poly) %>%
    str_sub(start = 1, end = -5)  # remove .tif
  tile.urb.path <- paste0(urb.path,"/",tile.name)
  dir.create(tile.urb.path)
paste("make tile output dir", tile.urb.path)
#+END_SRC

***** Crop to intersection of image and Urban Extent
#+BEGIN_SRC R
                                          # Crop image
  eu <- extent(urb.poly)
  ei <- extent(raster(tile.name.at.urb.poly))
  e <- raster::intersect(ei,eu)

  inFile <- tile.name.at.urb.poly
  outFile <- str_c(tile.urb.path,"/urbanExtent.tif")

  gdal_translate(inFile, outFile,
                 projwin = c(xmin(e), ymax(e), xmax(e), ymin(e)))


  message("Crop to Urban Extent")
#+END_SRC

***** Generate Feature data frame

****** Add ratios
#+BEGIN_SRC R

  add.ratios.ndvi(tile.dir = tile.urb.path,
                  tile.name = "urbanExtent",
                  out.tile.name.append = ratio.tile.name.append)
"Ratios Added"
#+END_SRC

****** Perform PCA
Apply the pca transformation from Madison area

******* read in madison pca
#+BEGIN_SRC R
pca <- readRDS(madison.naip.pca.path)
#+END_SRC

******* Apply pca transformation
#+BEGIN_SRC R
  image.pca.forWholeState(tile.dir = tile.urb.path,
                          tile.name = "urbanExtent",
                          pca.transform = pca)
"PCA tranform applied"
#+END_SRC
****** Segment image

#+BEGIN_SRC R
o.wd <- getwd()
setwd(tile.urb.path)
system(paste0("python ../../../../code/fia_segment_cmdArgs.py ",pixel_size," ",segment_size," ",compactness," urbanExtent"))
setwd(o.wd)
"Image Segmented"
#+END_SRC

****** Create Segment Feature Data frame
#+BEGIN_SRC R

   Create.Segment.Feature.df.forWholeState <- function(tile.dir,
                                                       tile.name,
                                                       ratio.appendage = ratio.tile.name.append,
                                                       band.names = band.names.wRatios,
                                                       seg.appendage = seg.tile.name.append){


       ratio.tile.path <- str_c(tile.dir, "/", tile.name, ratio.tile.name.append, ".tif")
       r.tile <- stack(ratio.tile.path)

       names(r.tile) <- band.names

       seg.tile.path <-  str_c(tile.dir, "/", tile.name,seg.tile.name.append,".tif")
       s.tile <- raster(seg.tile.path)

                                           # Create a data_frame where mean and variances are calculated by zone
       x <- as.data.frame(r.tile, xy = T)
       s <- as.data.frame(s.tile)
       colnames(s) <- "segment"
       r <- bind_cols(x,s)
       r2 <- r %>%
           group_by(segment)
  ## %>%
  ##          mutate(x.center = x - quantile(x = x, probs = .5),
  ##                 y.center = y - quantile(x = y, probs = .5))

       ## spatial.model.coef <- r2 %>%
       ##     do(fitXYlm(x = .$x.center, y = .$y.center, z = .$n_ratio))

       mean.and.sd <- r2 %>%
           summarize(mean(blue),
                     mean(green),
                     mean(red),
                     mean(nir),
                     mean(b_ratio),
                     mean(g_ratio),
                     mean(r_ratio),
                     mean(n_ratio),
                     mean(ndvi),
                     sd(blue),
                     sd(green),
                     sd(red),
                     sd(nir),
                     sd(b_ratio),
                     sd(g_ratio),
                     sd(r_ratio),
                     sd(n_ratio),
                     sd(ndvi))

       tile.name = data.frame(tile.name = rep(tile.name, nrow(mean.and.sd)))

       ## out <- left_join(spatial.model.coef, mean.and.sd) %>%
       ##     bind_cols(., tile.name)

                                       out <- bind_cols(mean.and.sd, tile.name)

       names <- colnames(out)
       names <- str_replace(names, "\\(",".")
       names <- str_replace(names, "\\)",".")
       names <- str_replace(names, "\\:",".")
       colnames(out) <- names
       out
   }



   band.names.wRatios <- c("blue","green","red","nir","b_ratio","g_ratio","r_ratio","n_ratio","ndvi")
   seg.tile.name.append = paste0("_N-",segment_size,"_C-",compactness)

   seg.df <-  Create.Segment.Feature.df.forWholeState(
       tile.dir = tile.urb.path,
       tile.name = "urbanExtent"
   )

   saveRDS(seg.df, file = paste0(tile.urb.path,"/", "urbanExtent",segmentFeatureDF.append,".rds"))

"Segment Feature DF Created"
#+END_SRC

***** Classify

****** Read in Model
#+BEGIN_SRC R
model.path <- "../DD/Models/madisonNAIP_N-30_C-15.models.rds"
model <- readRDS(model.path)
#+END_SRC

****** Select Random Forest with Target of Tree, Grass, and impervious
#+BEGIN_SRC R
model <- model[[1]][[1]]
#+END_SRC

****** Apply model to Segment Feature data frame and generate classified raster
#+BEGIN_SRC R

  classify.segmented.raster.forWholeState <- function(segment.feature.df.dir,
                                                      segment.dir,
                                                      model = model,
                                                      segment.feature.appendage = segment.feature.df.name.append,
                                                      segmentation.appendage = segment.tile.name.append,
                                                      segmentation.prms,
                                                      classify.out.dir,
                                                      tile.name) {

      df <- readRDS(paste0(segment.feature.df.dir,"/",tile.name,segment.feature.appendage,".rds"))
      seg.path <- paste0(segment.dir,"/",tile.name,segmentation.appendage,".tif")
      seg <- raster(seg.path)
                                          #       dfRowsWithNA <- which(is.na(df[,2]))
      complete.df <- df[complete.cases(df),] # svm can't predict with NAs

      mod <- model
      pred <- predict(mod, newdata = complete.df)
      response <- factor(as.character(pred$data$response), levels = c("g","i","t","o"))
      m <- cbind(zone = complete.df$segment, response)
      m <- left_join(as.data.frame(df["segment"]), as.data.frame(m), by = c("segment" = "zone"))

      seg.df <- as.data.frame(seg, xy = T)

      colnames(seg.df) <- c("x","y","segID")
      seg.df1 <- mutate(seg.df, class = plyr::mapvalues(segID, from = m$segment, to = m$response))

      r <- setValues(seg, values = seg.df1$class)
      names(r) <- "class"

      if (ncol(pred$data) > 2) {
          prob <- (pred$data[,grep("prob.*", x = colnames(pred$data))]) # get columns that contain probabilities
          ProbOfClass <- apply(prob, MARGIN = 1, FUN = max)
          m <- cbind(segment = complete.df$segment, ProbOfClass)
          m <- left_join(as.data.frame(df["segment"]), as.data.frame(m))

          seg.df2 <- mutate(seg.df, ProbOfClass = plyr::mapvalues(segID, from = m$segment, to = m$ProbOfClass))
          p <- setValues(seg, values = seg.df2$ProbOfClass)
          r <- stack(r,p)
          names(r) <- c("class","prob")
      }

          path <- paste0(segment.dir,"/classified_",tile.name,"_",seg.tile.name.append,"_",mod$task.desc$id,"_",mod$learner$id,".tif")
          writeRaster(r, path, overwrite=TRUE)
          print(path)

  }

  classify.segmented.raster.forWholeState(segment.feature.df.dir = tile.urb.path,
                                          segment.dir = tile.urb.path,
                                          classify.out.dir = tile.urb.path,
                                          tile.name = "urbanExtent",
                                          segmentation.appendage = seg.tile.name.append,
                                          model = model,
                                          segment.feature.appendage = segmentFeatureDF.append)

message("Image Classified")


#+END_SRC

#+BEGIN_SRC R
  message("Done with",tile.urb.path)
  }
#+END_SRC

**** Merge NAIP Tiles if there is more than one over an urban area and Save Classified image as <UrbanArea>.tif
#+BEGIN_SRC R
    classified.tiles <- list.files(urb.path, recursive = T, full.names = T)  %>%
      str_extract(pattern = ".*classified_urbanExtent.*tif$") %>%
  na.omit()




  rlist <- lapply(classified.tiles, stack)

  out <- do.call(mosaic, c(rlist,list(fun = mean, tolerance = 0.5)))

  writeRaster(x = out, filename = paste0(urb.path,"/ClassifiedUrbanArea_",i,".tif"), overwrite = T)
  paste0("Wrote ","ClassifiedUrbanArea_",i,".tif")

#+END_SRC



**** Delete intermediate steps
#+BEGIN_SRC R
  intermediate.work <- list.files(urb.path, full.names = T)
  intermediate.work <- intermediate.work[!grepl(intermediate.work,pattern = ".*(tif)$", perl = T)]
  unlink(intermediate.work, recursive = T)

  unlink(temp_i, recursive = T)

#+END_SRC

**** End Loop for all urban areas
#+BEGIN_SRC R
}
#+END_SRC

**** Mask Classified image, Post Processing
***** Mask Out Wetlands Post Processing
***** Mask out water
***** Mask out croplands






